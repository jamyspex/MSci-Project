# This is a diff between the cleaned-up MPI version and the original MPI+GMCF version
diff -ruBbw MPI-LES/src/adam.f95 LES-WRF-MPI/LES/src/GMCF/Models/adam.f95
--- MPI-LES/src/adam.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/adam.f95	2015-06-22 16:04:29.000000000 +0100
@@ -17,7 +17,10 @@
     integer, intent(In) :: km
     integer, intent(In) :: n
     integer, intent(In) :: nmax
-#if !defined(NO_IO) && !defined(MPI)
+! 
+!
+#ifndef NO_IO
+#if !defined(MPI) && !defined(GMCF)
     if (mod(n,1000) == 0.or.n == nmax) then
         open(unit=21,file=data21,form='unformatted',status='unknown')
         write(21) (((fold(i,j,k),i=1,im),j=1,jm),k=1,km)
@@ -27,6 +30,7 @@
         close(unit=21)
     end if
 #endif
+#endif
     do k = 1,km
         do j = 1,jm
             do i = 1,im
@@ -42,6 +46,7 @@
             end do
         end do
     end do
+! 
 #ifdef WV_DEBUG
     print *, 'F95 FGHSUM after adam:',sum(f)+sum(g)+sum(h)
     print *, 'F95 FSUM after adam:',sum(f)
@@ -47,7 +52,14 @@
     print *, 'F95 FSUM after adam:',sum(f)
     print *, 'F95 GSUM after adam:',sum(g)
     print *, 'F95 HSUM after adam:',sum(h)
+
 #endif
+
+      return
 end subroutine adam
 
+
+
+
 end module module_adam
+
diff -ruBbw MPI-LES/src/anime.f95 LES-WRF-MPI/LES/src/GMCF/Models/anime.f95
--- MPI-LES/src/anime.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/anime.f95	2015-06-22 16:04:29.000000000 +0100
@@ -1,13 +1,10 @@
 module module_anime
 
-use communication_helper_mpi
 contains
 
-!subroutine anime(n,n0,nmax,km,jm,im,dxl,dx1,dyl,dy1,z2,data22,data23,u,w,v,amask1,zbm1)
-subroutine anime(n,n0,nmax,km,jm,im,dxl,dx1,dyl,dy1,z2,data22,data23,u,w,v,amask1,zbm)
-
+      subroutine anime(n,n0,nmax,km,jm,im,dxl,dx1,dyl,dy1,z2,data22,data23,u,w,v,amask1)
     use common_sn ! create_new_include_statements() line 102
-    real(kind=4), dimension(0:ip+1,0:jp+1,0:kp+1) , intent(InOut) :: amask1
+        real(kind=4), dimension(0:ip+1,0:jp+1,0:kp+1) , intent(In) :: amask1
     character(len=70), intent(In) :: data22
     character(len=70), intent(In) :: data23
     real(kind=4), dimension(-1:ip+1) , intent(In) :: dx1
@@ -24,21 +21,8 @@
     real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: v
     real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) , intent(In) :: w
     real(kind=4), dimension(kp+2) , intent(In) :: z2
-    real(kind=4), dimension(-1:ipmax+1,-1:jpmax+1) , intent(In)  :: zbm
-!average_out
-    real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1)  :: uani
-    real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1)  :: vani
-    real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) :: wani
-!mpi_out
-
-    real(kind=4),allocatable :: ua(:,:,:)
-    real(kind=4),allocatable :: va(:,:,:)
-    real(kind=4),allocatable :: wa(:,:,:)
-    real(kind=4),allocatable :: amask1a(:,:,:)
-
-
-
-
+! 
+! 
     if(n == n0.or.n == nmax.or.mod(n,1000) == 0.) then
         do k = 1,km
             do j = 1,jm
@@ -49,777 +33,26 @@
                 end do
             end do
         end do
+
         open(unit=22,file=data22,form='unformatted',status='unknown')
         write(22) im,jm,km
-        write(22) (((real(a1(i,j,k)),i=1,im),j=1,jm),k=1,km), &
-                  (((real(a3(i,j,k)),i=1,im),j=1,jm),k=1,km), &
-                  (((real(a2(i,j,k)),i=1,im),j=1,jm),k=1,km)
+        write(22) (((real(a1(i,j,k)),i=1,im),j=1,jm),k=1,km), (((real(a3(i,j,k)),i=1,im),j=1,jm), &
+      k=1,km), (((real(a2(i,j,k)),i=1,im),j=1,jm),k=1,km)
         close(unit=22)
-   end if
-#ifdef MPI
-
-
-
-
-
-
-!for_average_out
-      do k=0,km
-      do j=0,jm
-      do i=0,im
-      uani(i,j,k)=uani(i,j,k)+u(i,j,k)
-      vani(i,j,k)=vani(i,j,k)+v(i,j,k)
-      wani(i,j,k)=wani(i,j,k)+w(i,j,k)
-      end do
-      end do
-      end do
-
-!reset
-!      if(n.eq.40000) then
-!      do k=0,km
-!      do j=0,jm
-!      do i=0,im
-!      uani(i,j,k)=0.
-!      vani(i,j,k)=0.
-!      wani(i,j,k)=0.
-!      end do
-!      end do
-!      end do
-!      end if
-
-
-!       if(n.gt.40001.and.mod(n,50).eq.0) then
-       if(mod(n,50).eq.0) then ! for outputing every 50 timesteps
-
-
-       if (isMaster()) then
-       write(filename, '("../out/data23",i6.6, ".dat")') n
-       open(unit=23,file=filename,form='unformatted',access='direct',recl=4*ipmax*jpmax) !for gfortran, recl=4*ipmax*jpmax
-       end if
-
-       allocate(ua(0:ipmax+1,-1:jpmax+1,0:kp+1))
-        call distributeu(ua, uani, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                 ua(i,j,k) = uani(i,j,k)
-                end do
-            end do
-          end do
-
-       do k=1,km
-        do j=1,jpmax
-         do i=1,ipmax
-            ua(i,j,k)=ua(i,j,k)/50.
-         end do
-        end do
-       end do
-
-!boundary
-       do k = 1,km
-         do j = 1,jpmax
-            ua(0,j,k) = ua(1,j,k)
-         end do
-       end do
-
-       irec = 1
-       do  k=1,km
-       write(23,rec=irec) ((real(0.5*(ua(i-1,j,k)+ua(i,j,k))),i=1,ipmax),j=1,jpmax)
-       irec = irec + 1
-       end do
-       end if
-
-
-       deallocate(ua)
-
-
-       allocate(wa(0:ipmax+1,-1:jpmax+1,-1:kp+1))
-        call distributew(wa, wani, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                 wa(i,j,k) = wani(i,j,k)
-                end do
-            end do
-          end do
-
-       do k=1,km
-        do j=1,jpmax
-         do i=1,ipmax
-            wa(i,j,k)=wa(i,j,k)/50.
-         end do
-        end do
-       end do
-
-!boundary
-            do j = 1,jpmax
-                do i = 1,ipmax
-                    wa(i,j,0) = 0.0
-                end do
-            end do
-
-       do  k=1,km
-       write(23,rec=irec) ((real(0.5*(wa(i,j,k-1)+wa(i,j,k))),i=1,ipmax),j=1,jpmax)
-       irec = irec + 1
-       end do
-       end if
-       deallocate(wa)
-
-
-       allocate(va(0:ipmax+1,-1:jpmax+1,0:kp+1))
-        call distributev(va, vani, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                 va(i,j,k) = vani(i,j,k)
-                end do
-            end do
-          end do
-
-       do k=1,km
-        do j=1,jpmax
-         do i=1,ipmax
-            va(i,j,k)=va(i,j,k)/50.
-         end do
-        end do
-       end do
-
-!boundary
-            do k = 1,km
-                do i = 1,ipmax
-                    va(i,0,k) = va(i,jpmax,k)
-                end do
-            end do
-
-
-       do  k=1,km
-       write(23,rec=irec) ((real(0.5*(va(i,j-1,k)+va(i,j,k))),i=1,ipmax),j=1,jpmax)
-       irec = irec + 1
-       end do
-       end if
-       deallocate(va)
-
-
-       allocate(amask1a(0:ipmax+1,0:jpmax+1,0:kp+1))
-        call distributeamask(amask1a, amask1, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                 amask1a(i,j,k) = amask1(i,j,k)
-                end do
-            end do
-          end do
-
-
-
-
-       do  k=1,km
-       write(23,rec=irec) ((real(amask1a(i,j,k)),i=1,ipmax),j=1,jpmax)
-       irec = irec + 1
-       end do
-       end if
-       deallocate(amask1a)
-
-
-       if (isMaster()) then
-       write(23,rec=irec) ((real(zbm(i,j)),i=1,ipmax),j=1,jpmax)
-       irec= irec + 1
-
 
+       open(unit=23,file=data23,form='unformatted',status='unknown')
+        write(23) im,jm,km,4
+        write(23) (((real(0.5*(u(i-1,j,k)+u(i,j,k))), i=1,im),j=1,jm),k=1,km), (((real(0.5*(w(i,j, &
+      k-1)+w(i,j,k))), i=1,im),j=1,jm),k=1,km), (((real(0.5*(v(i,j-1,k)+v(i,j,k))), i=1,im),j=1, &
+      jm),k=1,km), (((real(amask1(i,j,k)),i=1,im),j=1,jm),k=1,km)
        close(unit=23)
        end if
-
-      do k=0,km
-      do j=0,jm
-      do i=0,im
-      uani(i,j,k)=0.
-      vani(i,j,k)=0.
-      wani(i,j,k)=0.
-      end do
-      end do
-      end do
-
-      end if
-
-#endif
-
+! 
+      return
 end subroutine anime
 
 
 
-subroutine anime_bond(n,n0,nmax,km,jm,im,dxl,dx1,dyl,dy1,z2,data22,data23,u,w,v,amask1,zbm)
-
-    use common_sn ! create_new_include_statements() line 102
-    real(kind=4), dimension(0:ip+1,0:jp+1,0:kp+1) , intent(InOut) :: amask1
-    character(len=70), intent(In) :: data22
-    character(len=70), intent(In) :: data23
-    real(kind=4), dimension(-1:ip+1) , intent(In) :: dx1
-    real(kind=4), dimension(0:ip) , intent(In) :: dxl
-    real(kind=4), dimension(0:jp+1) , intent(In) :: dy1
-    real(kind=4), dimension(0:jp) , intent(In) :: dyl
-    integer, intent(In) :: im
-    integer, intent(In) :: jm
-    integer, intent(In) :: km
-    integer, intent(In) :: n
-    integer, intent(In) :: n0
-    integer, intent(In) :: nmax
-    real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: u
-    real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: v
-    real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) , intent(In) :: w
-    real(kind=4), dimension(kp+2) , intent(In) :: z2
-    real(kind=4), dimension(-1:ipmax+1,-1:jpmax+1) , intent(In)  :: zbm
-
-!bond_out
-    real(kind=4), dimension(1,jpmax,kp)  :: ubonda
-    real(kind=4), dimension(1,jpmax,kp)  :: vbonda
-    real(kind=4), dimension(1,jpmax,kp)  :: wbonda
-
-
-#ifdef MPI
-
-
-
-       call distributebondoutu(ubonda, u, ip, jp, kp, ipmax, jpmax, procPerRow)
-       call distributebondoutu(vbonda, v, ip, jp, kp, ipmax, jpmax, procPerRow)
-       call distributebondoutw(wbonda, w, ip, jp, kp, ipmax, jpmax, procPerRow)
-
-
-
-       if (isMaster()) then
-
-
-       write(filename, '("data24",i6.6, ".dat")') n
-
-       open(unit=24,file=filename,form='unformatted',status='replace',access='direct',recl=4*jpmax)
-       irec = 1
-        do k=1,km
-        write(24,rec=irec) (ubonda(1,j,k),j=1,jpmax)
-      irec=irec+1
-        end do
-
-        do k=1,km
-        write(24,rec=irec) (wbonda(1,j,k),j=1,jpmax)
-      irec=irec+1
-        end do
-
-        do k=1,km
-        write(24,rec=irec) (vbonda(1,j,k),j=1,jpmax)
-      irec=irec+1
-        end do
-
-       close(unit=24)
-
-
-       end if
-#endif
-
-end subroutine anime_bond
-
-
-
-
-!data30,31
-subroutine ifdata_out(n,n0,n1,nmax,time,km,jm,im,u,w,v,p,usum,vsum,wsum,f,g,h,fold,gold,hold)
-
-
-    use common_sn ! create_new_include_statements() line 102
-    integer, intent(In) :: im
-    integer, intent(In) :: jm
-    integer, intent(In) :: km
-    integer, intent(In) :: n
-    integer, intent(In) :: n0
-    integer, intent(In) :: nmax
-    real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: u
-    real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: v
-    real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) , intent(In) :: w
-    integer, intent(In) :: n1
-    real, intent(In) :: time
-!ifdata
-    real(kind=4), dimension(0:ip,0:jp,0:kp), intent(In)  :: usum
-    real(kind=4), dimension(0:ip,0:jp,0:kp), intent(In)  :: vsum
-    real(kind=4), dimension(0:ip,0:jp,0:kp), intent(In)  :: wsum
-    real(kind=4), dimension(0:ip+2,0:jp+2,0:kp+1),intent(In)  :: p
-
-    real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(In)  :: f
-    real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(In)  :: g
-    real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(In)  :: h
-
-    real(kind=4), dimension(ip,jp,kp) , intent(In)  :: fold
-    real(kind=4), dimension(ip,jp,kp) , intent(In)  :: gold
-    real(kind=4), dimension(ip,jp,kp) , intent(In)  :: hold
-
-!mpi_out
-    real(kind=4),allocatable :: ua(:,:,:)
-    real(kind=4),allocatable :: va(:,:,:)
-    real(kind=4),allocatable :: wa(:,:,:)
-    real(kind=4),allocatable :: usuma(:,:,:)
-    real(kind=4),allocatable :: vsuma(:,:,:)
-    real(kind=4),allocatable :: wsuma(:,:,:)
-    real(kind=4),allocatable :: pa(:,:,:)
-    real(kind=4),allocatable :: fa(:,:,:)
-    real(kind=4),allocatable :: ga(:,:,:)
-    real(kind=4),allocatable :: ha(:,:,:)
-    real(kind=4),allocatable :: folda(:,:,:)
-    real(kind=4),allocatable :: golda(:,:,:)
-    real(kind=4),allocatable :: holda(:,:,:)
-
-
-
-       if((n.eq.n1-1).or.(n.eq.nmax))  then      
-
-        if (isMaster()) then
-        write(filename, '("data30",i6.6, ".dat")') n
-
-        open(unit=30,file=filename,form='unformatted',status='replace')
-
-        write(30) n,time
-        end if
-
-       allocate(ua(0:ipmax+1,-1:jpmax+1,0:kp+1))
-        call distributeu(ua, u, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    ua(i,j,k) = u(i,j,k)
-                end do
-            end do
-          end do
-        write(30) (((ua(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-        deallocate(ua)
-
-
-       allocate(va(0:ipmax+1,-1:jpmax+1,0:kp+1))
-        call distributev(va, v, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im 
-                    va(i,j,k) = v(i,j,k)
-                end do
-            end do
-          end do
-        write(30) (((va(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-        deallocate(va)
-
-
-       allocate(wa(0:ipmax+1,-1:jpmax+1,-1:kp+1))
-        call distributew(wa, w, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im 
-                    wa(i,j,k) = w(i,j,k)
-                end do
-            end do
-          end do
-        write(30) (((wa(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-        deallocate(wa)
-
-
-       allocate(pa(0:ipmax+2,0:jpmax+2,0:kp+1))
-        call distributep(pa, p, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im 
-                    pa(i,j,k) = p(i,j,k)
-                end do
-            end do
-          end do
-        write(30) (((pa(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-        deallocate(pa)
-
-
-       allocate(usuma(0:ipmax,0:jpmax,0:kp))
-        call distributeusum(usuma, usum, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im 
-                    usuma(i,j,k) = usum(i,j,k)
-                end do
-            end do
-          end do
-        write(30) (((usuma(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-        deallocate(usuma)
-
-
-      allocate(vsuma(0:ipmax,0:jpmax,0:kp))
-        call distributeusum(vsuma, vsum, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    vsuma(i,j,k) = vsum(i,j,k)
-                end do
-            end do
-          end do
-        write(30) (((vsuma(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-        deallocate(vsuma)
-
-
-     allocate(wsuma(0:ipmax,0:jpmax,0:kp))
-        call distributeusum(wsuma, wsum, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    wsuma(i,j,k) = wsum(i,j,k)
-                end do
-            end do
-          end do
-        write(30) (((wsuma(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        close(30)
- 
-        end if
-        deallocate(wsuma)
-
-
-
-
-        if (isMaster()) then
-        write(filename, '("data31",i6.6, ".dat")') n
-        open(unit=31,file=filename,form='unformatted',status='replace')
-
-        end if
-
-
-     allocate(fa(0:ipmax,0:jpmax,0:kp))
-        call distributef(fa, f, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    fa(i,j,k) = f(i,j,k)
-                end do
-            end do
-          end do
-        write(31) (((fa(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-        deallocate(fa)
-
-
-     allocate(ga(0:ipmax,0:jpmax,0:kp))
-        call distributef(ga, g, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    ga(i,j,k) = g(i,j,k)
-                end do
-            end do
-          end do
-        write(31) (((ga(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-        deallocate(ga)
-
-
-     allocate(ha(0:ipmax,0:jpmax,0:kp))
-        call distributef(ha, h, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    ha(i,j,k) = h(i,j,k)
-                end do
-            end do
-          end do
-        write(31) (((ha(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-        deallocate(ha)
-
-
-     allocate(folda(ipmax,jpmax,kp))
-        call distributefold(folda, fold, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    folda(i,j,k) = fold(i,j,k)
-                end do
-            end do
-          end do
-        write(31) (((folda(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-        deallocate(folda)
-
-
-     allocate(golda(ipmax,jpmax,kp))
-        call distributefold(golda, gold, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    golda(i,j,k) = gold(i,j,k)
-                end do
-            end do
-          end do
-        write(31) (((golda(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-        deallocate(golda)
-
-
-     allocate(holda(ipmax,jpmax,kp))
-        call distributefold(holda, fold, ip, jp, kp, ipmax, jpmax, procPerRow)
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    holda(i,j,k) = hold(i,j,k)
-                end do
-            end do
-          end do
-        write(31) (((holda(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        close(31)
-
-        end if
-        deallocate(holda)
-
- 
-
-        end if
-
-
-
-end subroutine ifdata_out
-
-
-
-subroutine timestep_out_all_k(n,n0,n1,nmax,km,jm,im,z2,data22,data23,u,w,v,amask1,ut_x1,vt_x1,wt_x1,ut_x2,vt_x2,wt_x2,nspec&
-,u_spany2,v_spany2,w_spany2,u_spany3,v_spany3,w_spany3&
-,u_x1_19_spany2,v_x1_19_spany2,w_x1_19_spany2,u_x1_19_spany3,v_x1_19_spany3,w_x1_19_spany3)
-
-    use common_sn ! create_new_include_statements() line 102
-    real(kind=4), dimension(0:ip+1,0:jp+1,0:kp+1) , intent(InOut) :: amask1
-    character(len=70), intent(In) :: data22
-    character(len=70), intent(In) :: data23
-    integer, intent(In) :: im
-    integer, intent(In) :: jm
-    integer, intent(In) :: km
-    integer, intent(In) :: n
-    integer, intent(In) :: n0
-    integer, intent(In) :: nmax
-
-    integer, intent(In) ::  nspec
-
-    real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: u
-    real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: v
-    real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) , intent(In) :: w
-    real(kind=4), dimension(kp+2) , intent(In) :: z2
-
-    real(kind=4), dimension(1,1,nspec+1,kp),intent(out)  :: ut_x1
-    real(kind=4), dimension(1,1,nspec+1,kp),intent(out)  :: ut_x2
-    real(kind=4), dimension(1,1,nspec+1,kp),intent(out)  :: vt_x1
-    real(kind=4), dimension(1,1,nspec+1,kp),intent(out)  :: vt_x2
-    real(kind=4), dimension(1,1,nspec+1,kp),intent(out)  :: wt_x1
-    real(kind=4), dimension(1,1,nspec+1,kp),intent(out)  :: wt_x2
-
-
-    real(kind=4), dimension(1,kp,nspec+1),intent(out)  :: u_spany2
-    real(kind=4), dimension(1,kp,nspec+1),intent(out)  :: v_spany2
-    real(kind=4), dimension(1,kp,nspec+1),intent(out)  :: w_spany2
-    real(kind=4), dimension(1,kp,nspec+1),intent(out)  :: u_spany3
-    real(kind=4), dimension(1,kp,nspec+1),intent(out)  :: v_spany3
-    real(kind=4), dimension(1,kp,nspec+1),intent(out)  :: w_spany3
-
-    real(kind=4), dimension(19,kp,nspec+1),intent(out)  :: u_x1_19_spany2
-    real(kind=4), dimension(19,kp,nspec+1),intent(out)  :: v_x1_19_spany2
-    real(kind=4), dimension(19,kp,nspec+1),intent(out)  :: w_x1_19_spany2
-    real(kind=4), dimension(19,kp,nspec+1),intent(out)  :: u_x1_19_spany3
-    real(kind=4), dimension(19,kp,nspec+1),intent(out)  :: v_x1_19_spany3
-    real(kind=4), dimension(19,kp,nspec+1),intent(out)  :: w_x1_19_spany3
-
-    integer :: x1,x2,x3,y1,y2,y3,t,nsta
-
-
-      x1=20
-      x2=60
-      x3=80
-!      y1=1  
-      y2=25
-      y3=50
-!spanwise timestep output,   
-     if(n.ge.n1) then
-     if(rank.ge.54.and.rank.le.59) then !for using outflow boundary value and this case is procPerRow=6 procPerCol=10
-
-     do k=1,kp
-     u_spany2(1,k,n-n1+1) = real(0.5*(u(x3-1,y2,k)+u(x3,y2,k)))
-     v_spany2(1,k,n-n1+1) = real(0.5*(v(x3,y2-1,k)+v(x3,y2,k)))
-     w_spany2(1,k,n-n1+1) = real(0.5*(w(x3,y2,k-1)+w(x3,y2,k)))
-     u_spany3(1,k,n-n1+1) = real(0.5*(u(x3-1,y3,k)+u(x3,y3,k)))
-     v_spany3(1,k,n-n1+1) = real(0.5*(v(x3,y3-1,k)+v(x3,y3,k)))
-     w_spany3(1,k,n-n1+1) = real(0.5*(w(x3,y3,k-1)+w(x3,y3,k)))
-     end do
-
-      if(n.eq.nmax) then
-
-       write(filename, '("uvw_y2_spanwise",i3.3,"_outflow.dat")') rank
-
-!       do t=1,nspec
-!        write(*,*) 'u_spany2=',u_spany2(1,10,t)
-!        write(*,*) 'v_spany2=',v_spany2(1,10,t)
-!        write(*,*) 'w_spany2=',w_spany2(1,10,t)
-!       end do
-
-       open(unit=15,file=filename,form='unformatted',status='unknown')
-       write(15) ((real(u_spany2(1,k,t)),k=1,kp),t=1,nspec)
-       write(15) ((real(v_spany2(1,k,t)),k=1,kp),t=1,nspec)
-       write(15) ((real(w_spany2(1,k,t)),k=1,kp),t=1,nspec)
-
-      close(15)
-
-
-       write(filename, '("uvw_y3_spanwise",i3.3,"_outflow.dat")') rank
-
-!       do t=1,nspec
-!        write(*,*) 'u_spany3=',u_spany3(1,10,t)
-!        write(*,*) 'v_spany3=',v_spany3(1,10,t)
-!        write(*,*) 'w_spany3=',w_spany3(1,10,t)
-!       end do
-
-       open(unit=15,file=filename,form='unformatted',status='unknown')
-       write(15) ((real(u_spany3(1,k,t)),k=1,kp),t=1,nspec)
-       write(15) ((real(v_spany3(1,k,t)),k=1,kp),t=1,nspec)
-       write(15) ((real(w_spany3(1,k,t)),k=1,kp),t=1,nspec)
-
-       close(15)
-
-
-
-     end if
-     end if
-     end if
-
-
-
-! near-input timestep output
-     if(n.ge.n1) then
-     if(rank.ge.0.and.rank.le.5) then !for using value near to inflow boundary and this case is procPerRow=6 procPerCol=10
-
-     do k=1,kp
-     do i=1,19
-     u_x1_19_spany2(i,k,n-n1+1) = real(0.5*(u(i-1,y2,k)+u(i,y2,k)))
-     v_x1_19_spany2(i,k,n-n1+1) = real(0.5*(v(i,y2-1,k)+v(i,y2,k)))
-     w_x1_19_spany2(i,k,n-n1+1) = real(0.5*(w(i,y2,k-1)+w(i,y2,k)))
-     u_x1_19_spany3(i,k,n-n1+1) = real(0.5*(u(i-1,y3,k)+u(i,y3,k)))
-     v_x1_19_spany3(i,k,n-n1+1) = real(0.5*(v(i,y3-1,k)+v(i,y3,k)))
-     w_x1_19_spany3(i,k,n-n1+1) = real(0.5*(w(i,y3,k-1)+w(i,y3,k)))
-     end do
-     end do
-
-      if(n.eq.nmax) then
-
-       write(filename, '("uvw_x1_19_y2_spanwise",i3.3,".dat")') rank
-
-!       do t=1,nspec
-!        write(*,*) 'u_x1_19_spany2=',u_x1_19_spany2(1,10,t)
-!        write(*,*) 'v_x1_19_spany2=',v_x1_19_spany2(1,10,t)
-!        write(*,*) 'w_x1_19_spany2=',w_x1_19_spany2(1,10,t)
-!       end do
-
-       open(unit=15,file=filename,form='unformatted',status='unknown')
-       write(15) (((real(u_x1_19_spany2(i,k,t)),i=1,19),k=1,kp),t=1,nspec)
-       write(15) (((real(v_x1_19_spany2(i,k,t)),i=1,19),k=1,kp),t=1,nspec)
-       write(15) (((real(w_x1_19_spany2(i,k,t)),i=1,19),k=1,kp),t=1,nspec)
-
-       close(15)
-
-
-       write(filename, '("uvw_x1_19_y3_spanwise",i3.3,".dat")') rank
-
-!       do t=1,nspec
-!        write(*,*) 'u_x1_19_spany3=',u_x1_19_spany3(1,10,t)
-!        write(*,*) 'v_x1_19_spany3=',v_x1_19_spany3(1,10,t)
-!        write(*,*) 'w_x1_19_spany3=',w_x1_19_spany3(1,10,t)
-!       end do
-
-       open(unit=15,file=filename,form='unformatted',status='unknown')
-       write(15) (((real(u_x1_19_spany3(i,k,t)),i=1,19),k=1,kp),t=1,nspec)
-       write(15) (((real(v_x1_19_spany3(i,k,t)),i=1,19),k=1,kp),t=1,nspec)
-       write(15) (((real(w_x1_19_spany3(i,k,t)),i=1,19),k=1,kp),t=1,nspec)
-
-       close(15)
-
-     end if
-     end if
-     end if
-
-
-
-!streamwise timestep output
-
-      if(n.ge.n1) then
-
-      if(mod(rank,6).eq.3) then !for using middle value in domain and this case is procPerRow=6 procPerCol=10
-      call MPI_COMM_Rank(communicator, rank, ierror)
-      call checkMPIError()
-      write(*,*) 'rank=',rank
-
-
-      nsta = n - n1 + 1
-
-      
-      do k=1,kp
-
-! u&v&w are outputed at scalar point
-
-      ut_x1(1,1,nsta,k)=real(0.5*(u(x1-1,y3,k)+u(x1,y3,k)))
-
-      ut_x2(1,1,nsta,k)=real(0.5*(u(x2-1,y3,k)+u(x2,y3,k)))
-
-      vt_x1(1,1,nsta,k)=real(0.5*(v(x1,y3-1,k)+v(x1,y3,k)))
-
-      vt_x2(1,1,nsta,k)=real(0.5*(v(x2,y3-1,k)+v(x2,y3,k)))
-
-      wt_x1(1,1,nsta,k)=real(0.5*(w(x1,y3,k-1)+w(x1,y3,k)))
-
-      wt_x2(1,1,nsta,k)=real(0.5*(w(x2,y3,k-1)+w(x1,y3,k)))
-
-
-      end do
-
-
-      if(n.eq.nmax) then
-
-       write(filename, '("uvwt_x1","_",i3.3,"_",i6.6,".dat")') rank,nmax
-
-       open(unit=25,file=filename,form='unformatted',status='unknown')
-       write(25) ((real(ut_x1(1,1,t,k)),t=1,nspec),k=1,kp)
-       write(25) ((real(vt_x1(1,1,t,k)),t=1,nspec),k=1,kp)
-       write(25) ((real(wt_x1(1,1,t,k)),t=1,nspec),k=1,kp)
-       
- 
-       close(25)
-
-
-       write(filename, '("uvwt_x2","_",i3.3,"_",i6.6,".dat")') rank,nmax
-
-       open(unit=26,file=filename,form='unformatted',status='unknown')
-       write(26) ((real(ut_x2(1,1,t,k)),t=1,nspec),k=1,kp)
-       write(26) ((real(vt_x2(1,1,t,k)),t=1,nspec),k=1,kp)
-       write(26) ((real(wt_x2(1,1,t,k)),t=1,nspec),k=1,kp)
-
-
-       close(26)
-
-       
-    
-      end if
-      end if
-      end if
-end subroutine timestep_out_all_k
-
-
 
 end module module_anime
+
diff -ruBbw MPI-LES/src/aveflow.f95 LES-WRF-MPI/LES/src/GMCF/Models/aveflow.f95
--- MPI-LES/src/aveflow.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/aveflow.f95	2015-06-22 16:04:29.000000000 +0100
@@ -3,7 +4,7 @@
 contains
 
 subroutine aveflow(n,n1,km,jm,im,aveu,avev,avew,avep,avel,aveuu,avevv,aveww,avesm,avesmsm, &
-      uwfx,avesu,avesv,avesw,avesuu,avesvv,avesww,u,v,w,p,sm,nmax,uwfxs,data10,time,data11,data13,data14,amask1)
+      uwfx,avesu,avesv,avesw,avesuu,avesvv,avesww,u,v,w,p,sm,nmax,uwfxs,data10,time,data11)
     use common_sn ! create_new_include_statements() line 102
     real(kind=4), dimension(ip,jp,kp) , intent(Out) :: avel
     real(kind=4), dimension(ip,jp,kp) , intent(Out) :: avep
@@ -15,16 +16,14 @@
     real(kind=4), dimension(ip,kp) , intent(Out) :: avesvv
     real(kind=4), dimension(ip,kp) , intent(Out) :: avesw
     real(kind=4), dimension(ip,kp) , intent(Out) :: avesww
-    real(kind=4), dimension(ip,jp,0:kp) , intent(Out) :: aveu
+        real(kind=4), dimension(ip,jp,kp) , intent(Out) :: aveu
     real(kind=4), dimension(ip,jp,kp) , intent(Out) :: aveuu
-    real(kind=4), dimension(ip,jp,0:kp) , intent(Out) :: avev
+        real(kind=4), dimension(ip,jp,kp) , intent(Out) :: avev
     real(kind=4), dimension(ip,jp,kp) , intent(Out) :: avevv
-    real(kind=4), dimension(ip+1,jp,0:kp+2) , intent(Out) :: avew
+        real(kind=4), dimension(ip,jp,kp) , intent(Out) :: avew
     real(kind=4), dimension(ip,jp,kp) , intent(Out) :: aveww
     character(len=70), intent(In) :: data10
     character(len=70), intent(In) :: data11
-    character(len=70), intent(In) :: data13
-    character(len=70), intent(In) :: data14
     integer, intent(In) :: im
     integer, intent(In) :: jm
     integer, intent(In) :: km
@@ -39,49 +38,15 @@
     real(kind=4), dimension(ip,kp) , intent(InOut) :: uwfxs
     real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: v
     real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) , intent(In) :: w
-
-    real(kind=4), dimension(0:ip+1,0:jp+1,0:kp+1)  , intent(In)  :: amask1
-    real(kind=4), dimension(0:ipmax+1,0:jpmax+1,0:kp+1)   :: amask1a
-
-!output
-!    real(kind=4), dimension(0:ipmax,0:jpmax,0:kp)  :: aveua
- !   real(kind=4), dimension(0:ipmax,0:jpmax,0:kp)  :: aveva
- !   real(kind=4), dimension(ipmax+1,jpmax,0:kp+2)  :: avewa
- !   real(kind=4), dimension(0:ipmax,0:jpmax,0:kp)  :: aveuua
- !   real(kind=4), dimension(0:ipmax,0:jpmax,0:kp)  :: avevva
- !   real(kind=4), dimension(0:ipmax,0:jpmax,0:kp)  :: avewwa
- !   real(kind=4), dimension(0:ipmax,0:jpmax,0:kp)  :: uwfxa
- !   integer, dimension(ip,kp) :: js
- !   integer, dimension(kp) :: ijs
- !   real(kind=4), dimension(ip,kp) :: avesssu
- !   real(kind=4), dimension(ip,kp) :: avesssv
- !   real(kind=4), dimension(ip,kp) :: avesssw
- !   real(kind=4), dimension(ip,kp) :: avesssuu
- !   real(kind=4), dimension(ip,kp) :: avesssvv
- !   real(kind=4), dimension(ip,kp) :: avesssww
- !   real(kind=4), dimension(ip,kp) :: uwfxsss
- !   real(kind=4), dimension(kp) :: avessu
- !   real(kind=4), dimension(kp) :: avessv
- !   real(kind=4), dimension(kp) :: avessw
- !   real(kind=4), dimension(kp) :: avessuu
- !   real(kind=4), dimension(kp) :: avessvv
- !   real(kind=4), dimension(kp) :: avessww
- !   real(kind=4), dimension(kp) :: uwfxss
-
-    real(kind=4),allocatable :: aveua(:,:,:)
-    real(kind=4),allocatable :: aveva(:,:,:)
-    real(kind=4),allocatable :: avewa(:,:,:)
-    real(kind=4),allocatable :: aveuua(:,:,:)
-    real(kind=4),allocatable :: avevva(:,:,:)
-    real(kind=4),allocatable :: avewwa(:,:,:)
-    real(kind=4),allocatable :: uwfxa(:,:,:)
-
-
+! 
+! 
     if(n == n1) then
         do k = 1,km
             do j = 1,jm
                 do i = 1,im
+          aveu(i,j,k) = 0.0
                     avev(i,j,k) = 0.0
+          avew(i,j,k) = 0.0
                     avep(i,j,k) = 0.0
                     avel(i,j,k) = 0.0
                     aveuu(i,j,k) = 0.0
@@ -93,68 +58,45 @@
                 end do
             end do
         end do
-
-        do k = 0,km
-            do j = 1,jm
+        do k = 1,km
                 do i = 1,im
-                    aveu(i,j,k) = 0.0
-                end do
+          avesu(i,k) = 0.0
+          avesv(i,k) = 0.0
+          avesw(i,k) = 0.0
+          avesuu(i,k) = 0.0
+          avesvv(i,k) = 0.0
+          avesww(i,k) = 0.0
             end do
         end do
-        do k = 0,km
-            do j = 1,jm
-                do i = 1,im+1
-                    avew(i,j,k) = 0.0
-                end do
-            end do
-        end do
-
-
     end if
-
-
+! 
     if(n >= n1) then
         do k = 1,km
             do j = 1,jm
                 do i = 1,im
+        aveu(i,j,k) = aveu(i,j,k)+u(i,j,k)
                     avev(i,j,k) = avev(i,j,k)+v(i,j,k)
+        avew(i,j,k) = avew(i,j,k)+w(i,j,k)
                     avep(i,j,k) = avep(i,j,k)+p(i,j,k)
                     aveuu(i,j,k) = aveuu(i,j,k)+u(i,j,k)**2
                     avevv(i,j,k) = avevv(i,j,k)+v(i,j,k)**2
                     aveww(i,j,k) = aveww(i,j,k)+w(i,j,k)**2
                     avesm(i,j,k) = avesm(i,j,k)+sm(i,j,k)
                     avesmsm(i,j,k) = avesmsm(i,j,k)+sm(i,j,k)**2
-                    uwfx(i,j,k) = uwfx(i,j,k)+0.5*(u(i,j,k-1)+u(i,j,k)) * &
-                                  0.5*(w(i,j,k-1)+w(i+1,j,k-1))
+        uwfx(i,j,k) = uwfx(i,j,k)+0.5*(u(i,j,k-1)+u(i,j,k)) *0.5*(w(i,j,k-1)+w(i+1,j,k-1))
                 end do
             end do
         end do
-
-
-        do k = 0,km
-            do j = 1,jm
-                do i = 1,im
-                    aveu(i,j,k) = aveu(i,j,k)+u(i,j,k)
-                end do
-            end do
-        end do
-        do k = 0,km
-            do j = 1,jm
-                do i = 1,im+1
-                    avew(i,j,k) = avew(i,j,k)+w(i,j,k)
-                end do
-            end do
-        end do
-
-
+! 
   endif
+! 
   if(n == nmax) then
       do k = 1,km
           do j = 1,jm
               do i = 1,im
-!                  aveu(i,j,k) = aveu(i,j,k)/float(nmax-n1+1)
+        aveu(i,j,k) = aveu(i,j,k)/float(nmax-n1+1)
                   avev(i,j,k) = avev(i,j,k)/float(nmax-n1+1)
-!                  avew(i,j,k) = avew(i,j,k)/float(nmax-n1+1)
+        avew(i,j,k) = avew(i,j,k)/float(nmax-n1+1)
                   avep(i,j,k) = avep(i,j,k)/float(nmax-n1+1)
                   avel(i,j,k) = avel(i,j,k)/float(nmax-n1+1)
                   aveuu(i,j,k) = aveuu(i,j,k)/float(nmax-n1+1)
@@ -165,29 +107,11 @@
               end do
       end do
     end do
-
-        do k = 0,km
-            do j = 1,jm
-                do i = 1,im
-                    aveu(i,j,k) = aveu(i,j,k)/float(nmax-n1+1)
-                end do
-            end do
-        end do
-        do k = 0,km
-            do j = 1,jm
-                do i = 1,im+1
-                    avew(i,j,k) = avew(i,j,k)/float(nmax-n1+1)
-                end do
-            end do
-        end do
-
-
     do k = 1,km
         do j = 1,jm
             do i = 1,im
-                uwfx(i,j,k) = uwfx(i,j,k)/float(nmax-n1+1) - &
-                              0.5*(aveu(i,j,k-1)+aveu(i,j,k)) * &
-                              0.5*(avew(i,j, k-1)+avew(i+1,j,k-1))
+        uwfx(i,j,k) = uwfx(i,j,k)/float(nmax-n1+1) -0.5*(aveu(i,j,k-1)+aveu(i,j,k)) *0.5*(avew(i,j, &
+      k-1)+avew(i+1,j,k-1))
             end do
         end do
     end do
@@ -196,161 +118,67 @@
       do k = 1,km
         do j = 1,jm
             do i = 1,im
-                aveuu(i,j,k) = sqrt(abs(aveuu(i,j,k)-aveu(i,j,k)**2))
-                avevv(i,j,k) = sqrt(abs(avevv(i,j,k)-avev(i,j,k)**2))
-                aveww(i,j,k) = sqrt(abs(aveww(i,j,k)-avew(i,j,k)**2))
+        avesu(i,k) = avesu(i,k)+aveu(i,j,k)
+        avesv(i,k) = avesv(i,k)+avev(i,j,k)
+        avesw(i,k) = avesw(i,k)+avew(i,j,k)
+        avesuu(i,k) = avesuu(i,k)+aveuu(i,j,k)
+        avesvv(i,k) = avesvv(i,k)+avevv(i,j,k)
+        avesww(i,k) = avesww(i,k)+aveww(i,j,k)
+        uwfxs(i,k) = uwfxs(i,k)+uwfx(i,j,k)
             end do
         end do
         end do
-
-
-
-       if (isMaster()) then
-    open(unit=10,file=data10,form='unformatted',status='unknown')
-
-       end if
-      allocate(aveua(0:ipmax,0:jpmax,0:kp))
-      call distributeaveu(aveua, aveu, ip, jp, kp, ipmax, jpmax, procPerRow)
-
-       if (isMaster()) then
           do k = 1,km
-            do j = 1,jm
                 do i = 1,im
-                    aveua(i,j,k) = aveu(i,j,k)
-                end do
+        avesu(i,k) = avesu(i,k)/float(jm)
+        avesv(i,k) = avesv(i,k)/float(jm)
+        avesw(i,k) = avesw(i,k)/float(jm)
+        avesuu(i,k) = avesuu(i,k)/float(jm)
+        avesvv(i,k) = avesvv(i,k)/float(jm)
+        avesww(i,k) = avesww(i,k)/float(jm)
+        uwfxs(i,k) = uwfxs(i,k)/float(jm)
             end do
         end do
-
-        write(10) (((aveua(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-
-       end if
-       deallocate(aveua)
-
-
-      allocate(avewa(ipmax+1,jpmax,0:kp+2))
-      call distributeavew(avewa, avew, ip, jp, kp, ipmax, jpmax, procPerRow)
-
-       if (isMaster()) then
+! 
           do k = 1,km
             do j = 1,jm
                 do i = 1,im
-                    avewa(i,j,k) = avew(i,j,k)
+          aveuu(i,j,k) = sqrt(abs(aveuu(i,j,k)-aveu(i,j,k)**2))
+          avevv(i,j,k) = sqrt(abs(avevv(i,j,k)-avev(i,j,k)**2))
+          aveww(i,j,k) = sqrt(abs(aveww(i,j,k)-avew(i,j,k)**2))
                 end do
             end do
         end do
-
-        write(10) (((avewa(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-
-       end if
-       deallocate(avewa)
-
-
-      allocate(aveva(0:ipmax,0:jpmax,0:kp))
-      call distributeaveu(aveva, avev, ip, jp, kp, ipmax, jpmax, procPerRow)
-
-       if (isMaster()) then
           do k = 1,km
-            do j = 1,jm
                 do i = 1,im
-                    aveva(i,j,k) = avev(i,j,k)
+          avesuu(i,k) = sqrt(abs(avesuu(i,k)-avesu(i,k)**2))
+          avesvv(i,k) = sqrt(abs(avesvv(i,k)-avesv(i,k)**2))
+          avesww(i,k) = sqrt(abs(avesww(i,k)-avesw(i,k)**2))
                 end do
             end do
-        end do
-
-
-        write(10) (((aveva(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-
-       close(10)
-
-       end if
-       deallocate(aveva)
-
-   
-
-
-
-       if (isMaster()) then
+! 
+#ifndef NO_IO
+#if !defined(MPI) && !defined(GMCF)
+        open(unit=10,file=data10,form='unformatted',status='unknown')
+          write(10) n,time
+          write(10) (((aveu(i,j,k),i=1,im),j=1,jm),k=1,km)
+          write(10) (((avew(i,j,k),i=1,im),j=1,jm),k=1,km)
+          write(10) (((avev(i,j,k),i=1,im),j=1,jm),k=1,km)
+        close(unit=10)
+! 
        open(unit=11,file=data11,form='unformatted',status='unknown')
+          write(11) n,time
+          write(11) (((aveuu(i,j,k),i=1,im),j=1,jm),k=1,km)
+          write(11) (((aveww(i,j,k),i=1,im),j=1,jm),k=1,km)
+          write(11) (((avevv(i,j,k),i=1,im),j=1,jm),k=1,km)
+          write(11) (((uwfx(i,j,k),i=1,im),j=1,jm),k=1,km)
+        close(unit=11)
+#endif
+#endif
        end if
-      allocate(aveuua(0:ipmax,0:jpmax,0:kp))
-      call distributeaveuu(aveuua, aveuu, ip, jp, kp, ipmax, jpmax, procPerRow)
-
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    aveuua(i,j,k) = aveuu(i,j,k)
-                end do
-            end do
-        end do
-
-        write(11) (((aveuua(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-
-       end if
-       deallocate(aveuua)
-
-
-
-      allocate(avewwa(0:ipmax,0:jpmax,0:kp))
-      call distributeaveuu(avewwa, aveww, ip, jp, kp, ipmax, jpmax, procPerRow)
-
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    avewwa(i,j,k) = aveww(i,j,k)
-                end do
-            end do
-        end do
-
-        write(11) (((avewwa(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-
-       end if
-       deallocate(avewwa)
-
-
-      allocate(avevva(0:ipmax,0:jpmax,0:kp))
-      call distributeaveuu(avevva, avevv, ip, jp, kp, ipmax, jpmax, procPerRow)
+! 
 
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    avevva(i,j,k) = avevv(i,j,k)
-                end do
-            end do
-        end do
-
-        write(11) (((avevva(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-
-       end if
-       deallocate(avevva)
-
-
-      allocate(uwfxa(0:ipmax,0:jpmax,0:kp))
-      call distributeaveuu(uwfxa, uwfx, ip, jp, kp, ipmax, jpmax, procPerRow)
-
-       if (isMaster()) then
-          do k = 1,km
-            do j = 1,jm
-                do i = 1,im
-                    uwfxa(i,j,k) = uwfx(i,j,k)
-                end do
-            end do
-        end do
-
-        write(11) (((uwfxa(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-     
-       close(11) 
- 
-       end if
-       deallocate(uwfxa)
-
-    
-
-!#endif
-!#endif
-    endif
+      return
 end subroutine aveflow
 
 end module module_aveflow
diff -ruBbw MPI-LES/src/bondFG.f95 LES-WRF-MPI/LES/src/GMCF/Models/bondFG.f95
--- MPI-LES/src/bondFG.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/bondFG.f95	2015-06-22 16:04:29.000000000 +0100
@@ -12,7 +12,7 @@
     integer :: i, j, k
 !
 ! --inflow condition
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isTopRow(procPerRow)) then
 #endif
         do k = 1,km
@@ -20,11 +20,11 @@
                 f( 0,j,k) = f(1  ,j,k)
             end do
         end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     end if
 #endif
 ! --sideflow condition
-#if !defined(MPI) || (PROC_PER_ROW==1)
+#if !defined(MPI) && !defined(GMCF) || (PROC_PER_ROW==1)
     do k = 1,km
         do i = 1,im
             g(i, 0,k) = g(i,jm  ,k) ! GR: Why only right->left? What about left->right?
@@ -40,11 +40,17 @@
             h(i,j,km) = 0.0
         end do
     end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
 ! --halo exchanges
     call exchangeRealHalos(f, procPerRow, neighbours, 1, 0, 1, 0)
     call exchangeRealHalos(g, procPerRow, neighbours, 1, 0, 1, 0)
     call exchangeRealHalos(h, procPerRow, neighbours, 1, 0, 1, 0)
+#else
+#ifdef ESTIMATE_CORNERS
+    call calculateCornersNonMPI(f, 1, 0, 1, 0)
+    call calculateCornersNonMPI(g, 1, 0, 1, 0)
+    call calculateCornersNonMPI(h, 1, 0, 1, 0)
+#endif
 #endif
 end subroutine bondFG
 
diff -ruBbw MPI-LES/src/bondv1.f95 LES-WRF-MPI/LES/src/GMCF/Models/bondv1.f95
--- MPI-LES/src/bondv1.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/bondv1.f95	2015-06-22 16:04:29.000000000 +0100
@@ -12,13 +12,11 @@
     real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(InOut) :: u
     real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(InOut) :: v
     real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) , intent(InOut) :: w
-    real(kind=4), dimension(0:kp+2) , intent(In) :: z2
+    real(kind=4), dimension(kp+2) , intent(In) :: z2
     real(kind=4) :: u_val
     integer :: i, j, k
     real(kind=4) :: aaa, bbb, uout
-!    integer, intent(In) :: ical
-
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     integer :: a
 #endif
 !
@@ -27,16 +25,15 @@
 !
 !      Setup for initial wind profile
 !
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isTopRow(procPerRow)) then
 #endif
         do i = 0,1
             do k = 1,78 ! kp = 90 so OK
                 do j = 1,jm
-!                    u_val = 5.*((z2(k)+0.5*dzn(k))/600.)**0.2
+                    u_val = 5.*((z2(k)+0.5*dzn(k))/600.)**0.2
                     !print *, u_val
-!                    u(i,j,k) = u_val
-                    u(i,j,k) = 5.0
+                    u(i,j,k) = u_val
                     v(i,j,k) = 0.0
                     w(i,j,k) = 0.0
                 end do
@@ -52,14 +49,14 @@
                 end do
             end do
         end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     end if
 #endif
 
 #if ICAL == 0
     !if(ical == 0.and.n == 1) then
     if(n == 1) then
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
         ! GR: Actually make this distributed rather than this awful mess
         do a=1, procPerCol
             do k = 1,km
@@ -103,7 +100,7 @@
             bbb = amin1(bbb,u(im,j,k))
         end do
     end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     call getGlobalMaxOf(aaa)
     call getGlobalMinOf(bbb)
 #endif
@@ -132,7 +129,7 @@
             w(im+1,j,k) = w(im+1,j,k)-dt*uout *(w(im+1,j,k)-w(im,j,k))/dxs(im)
         end do
     end do
-#if !defined(MPI) || (PROC_PER_ROW==1)
+#if !defined(MPI) && !defined(GMCF) || (PROC_PER_ROW==1)
 ! --side flow condition; periodic
     do k = 0,km+1
         do i = 0,im+1
@@ -165,11 +162,17 @@
 #endif
 
 ! =================================
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
 ! --halo exchanges
     call exchangeRealHalos(u, procPerRow, neighbours, 2, 1, 1, 1)
     call exchangeRealHalos(v, procPerRow, neighbours, 2, 1, 1, 1)
     call exchangeRealHalos(w, procPerRow, neighbours, 2, 1, 1, 1)
+#else
+#ifdef ESTIMATE_CORNERS
+    call calculateCornersNonMPI(u, 2, 1, 1, 1)
+    call calculateCornersNonMPI(v, 2, 1, 1, 1)
+    call calculateCornersNonMPI(w, 2, 1, 1, 1)
+#endif
 #endif
 
 ! -------top and underground condition
@@ -188,7 +191,7 @@
     end do
 
     do j = -1,jm+1 ! 2 !WV: I think this is wrong: j = jm+2 is not allocated!
-        do i = 0,im+1
+        do i = -1,im+1
             w(i,j, 0) = 0.0
             w(i,j,km) = 0.0
         end do
Only in MPI-LES/src/: bondv1_data24.f95
diff -ruBbw MPI-LES/src/boundp.f95 LES-WRF-MPI/LES/src/GMCF/Models/boundp.f95
--- MPI-LES/src/boundp.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/boundp.f95	2015-06-22 16:04:29.000000000 +0100
@@ -1,11 +1,14 @@
 module module_boundp
 
-implicit none
+! GR: Ignore boundp for halo exchange. This would kill performance!
+! GR: Actually, we need this for correctness (UrbanFlow = NaN... is due to
+! non-convergence).
 
 contains
 
 subroutine boundp2(jm,im,p,km)
     use common_sn ! create_new_include_statements() line 102
+    implicit none
     integer, intent(In) :: im
     integer, intent(In) :: jm
     integer, intent(In) :: km
@@ -19,48 +22,53 @@
             p(i,j,km+1) = p(i,j,km)
         end do
     end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
 ! --halo exchanges
     call exchangeRealHalos(p, procPerRow, neighbours, 1, 2, 1, 2)
+#else
+#ifdef ESTIMATE_CORNERS
+    call calculateCornersNonMPI(p, 1, 2, 1, 2)
+#endif
 #endif
 end subroutine boundp2
 
 subroutine boundp1(km,jm,p,im)
     use common_sn ! create_new_include_statements() line 102
+    implicit none
     integer, intent(In) :: im
     integer, intent(In) :: jm
     integer, intent(In) :: km
     real(kind=4), dimension(0:ip+2,0:jp+2,0:kp+1) , intent(InOut) :: p
-#if !defined(MPI) || (PROC_PER_ROW==1)
+#if !defined(MPI) && !defined(GMCF) || (PROC_PER_ROW==1)
     integer :: i, j, k
 #else
     integer :: j, k
 #endif
 !
 ! --computational boundary(neumann condition)
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isTopRow(procPerRow) .or. isBottomRow(procPerRow)) then
 #endif
         do k = 0,km+1
             do j = 0,jm+1
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
                 if (isTopRow(procPerRow)) then
 #endif
                     p(   0,j,k) = p(1 ,j,k)
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
                 else
 #endif
                     p(im+1,j,k) = p(im,j,k)
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
                 end if
 #endif
             end do
         end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     end if
 #endif
 ! --side flow exchanges
-#if !defined(MPI) || (PROC_PER_ROW==1)
+#if !defined(MPI) && !defined(GMCF) || (PROC_PER_ROW==1)
     do k = 0,km+1
         do i = 0,im+1
             p(i,   0,k) = p(i,jm,k) ! right to left
@@ -71,9 +79,13 @@
     call sideflowRightLeft(p, procPerRow, jp+1, 1, 0, 1, 0, 0)
     call sideflowLeftRight(p, procPerRow, 2, jp+2, 0, 1, 0, 0)
 #endif
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
 ! --halo exchanges
     call exchangeRealHalos(p, procPerRow, neighbours, 1, 2, 1, 2)
+#else
+#ifdef ESTIMATE_CORNERS
+    call calculateCornersNonMPI(p, 1, 2, 1, 2)
+#endif
 #endif
 end subroutine boundp1
 
diff -ruBbw MPI-LES/src/boundsm.f95 LES-WRF-MPI/LES/src/GMCF/Models/boundsm.f95
--- MPI-LES/src/boundsm.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/boundsm.f95	2015-06-22 16:04:29.000000000 +0100
@@ -12,47 +12,47 @@
     integer :: i, j, k
 !
 ! =================================
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isTopRow(procPerRow) .or. isBottomRow(procPerRow)) then
 #endif
         do k = 0,km+1
             do j = -1,jm+1
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
                 if (isTopRow(procPerRow)) then
 #endif
                     sm(   0,j,k) = sm(1 ,j,k) ! GR: Why not sm(-1,,) = sm(0,,)?
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
                 else
 #endif
                     sm(im+1,j,k) = sm(im,j,k)
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
                 end if
 #endif
             end do
         end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     end if
 #endif
 ! --side flow condition
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isLeftmostColumn(procPerRow) .or. isRightmostColumn(procPerRow)) then
 #endif
         do k = 0,km+1
             do i = 0,im+1
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
                 if (isRightmostColumn(procPerRow)) then
 #endif
                     sm(i,jm+1,k) = sm(i,jm  ,k)
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
                 else
 #endif
                     sm(i,0,k) = sm(i,1   ,k) ! GR: Why not sm(,-1,) = sm(,0,)?
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
                 end if
 #endif
             end do
         end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     end if
 #endif
 ! --underground condition
@@ -62,9 +62,13 @@
             sm(i,j,km+1) = sm(i,j,km)
         end do
     end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
 ! --halo exchanges
     call exchangeRealHalos(sm, procPerRow, neighbours, 2, 1, 2, 1)
+#else
+#ifdef ESTIMATE_CORNERS
+    call calculateCornersNonMPI(sm, 2, 1, 2, 1)
+#endif
 #endif
 end subroutine boundsm
 
diff -ruBbw MPI-LES/src/common_sn.f95 LES-WRF-MPI/LES/src/GMCF/Models/common_sn.f95
--- MPI-LES/src/common_sn.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/common_sn.f95	2015-06-22 16:04:29.000000000 +0100
@@ -24,6 +25,52 @@
 ! --stretch
 !
     real a1(1:ip,1:jp+1,1:kp+1),a2(1:ip,1:jp+1,1:kp+1) ,a3(1:ip,1:jp+1,1:kp+1)
-    integer irec
-   character(len=70) :: filename 
+contains
+
+subroutine calculateCornersNonMPI(array, leftThickness, rightThickness, &
+                            topThickness, bottomThickness)
+    implicit none
+    integer, intent(in) :: leftThickness, rightThickness, &
+                           topThickness, bottomThickness
+    real(kind=4), dimension(:,:,:), intent(inout) :: array
+    integer :: i
+    do i=1, size(array, 3)
+        call calculateCornersNonMPIHelper(array(:,:,i), leftThickness, rightThickness, &
+                            topThickness, bottomThickness)
+    end do
+end subroutine calculateCornersNonMPI
+
+subroutine calculateCornersNonMPIHelper(array, leftThickness, rightThickness, &
+                            topThickness, bottomThickness)
+    implicit none
+    integer, intent(in) :: leftThickness, rightThickness, &
+                           topThickness, bottomThickness
+    real(kind=4), dimension(:,:), intent(inout) :: array
+    integer :: r, c
+    ! There is a top left corner to specify
+    do r=topThickness,1,-1
+        do c=leftThickness,1,-1
+            array(r, c) = (array(r+1, c) + array(r, c+1) - array(r+1, c+1)) / 2.0
+        end do
+    end do
+    ! There is a top right corner to specify
+    do r=topThickness,1,-1
+        do c=size(array,2)-rightThickness+1,size(array,2)
+            array(r, c) = (array(r+1, c) + array(r, c-1) - array(r+1, c-1)) / 2.0
+        end do
+    end do
+    ! There is a bottom left corner to specify
+    do r=size(array,1)-bottomThickness+1,size(array,1)
+        do c=leftThickness,1,-1
+            array(r, c) = (array(r-1, c) + array(r, c+1) - array(r-1, c+1)) / 2.0
+        end do
+    end do
+    ! There is a bottom right corner to specify
+    do r=size(array,1)-bottomThickness+1,size(array,1)
+        do c=size(array,2)-rightThickness+1,size(array,2)
+            array(r, c) = (array(r, c-1) + array(r-1, c) - array(r-1, c-1)) / 2.0
+        end do
+   end do
+end subroutine calculateCornersNonMPIHelper
+
 end module common_sn
Only in LES-WRF-MPI/LES/src/GMCF/Models/: communication_common.mod
Only in LES-WRF-MPI/LES/src/GMCF/Models/: communication_common.o
diff -ruBbw MPI-LES/src/communication_helper.f95 LES-WRF-MPI/LES/src/GMCF/Models/communication_helper.f95
--- MPI-LES/src/communication_helper.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/communication_helper.f95	2015-06-22 16:04:29.000000000 +0100
@@ -1,4 +1,7 @@
 module communication_helper
+#ifndef GMCF
+use communication_helper_integer
+#endif
 use communication_helper_real
 implicit none
 
Only in LES-WRF-MPI/LES/src/GMCF/Models/: communication_helper_gmcf.f95
Only in LES-WRF-MPI/LES/src/GMCF/Models/: communication_helper_integer.f95
diff -ruBbw MPI-LES/src/communication_helper_mpi.f95 LES-WRF-MPI/LES/src/GMCF/Models/communication_helper_mpi.f95
--- MPI-LES/src/communication_helper_mpi.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/communication_helper_mpi.f95	2015-06-22 16:04:29.000000000 +0100
@@ -9,6 +9,7 @@
 contains
 
 subroutine initialise_mpi()
+    implicit none
     logical :: alreadyInitialised
     communicator = MPI_COMM_WORLD
     call MPI_Initialized(alreadyInitialised, ierror)
@@ -24,11 +25,13 @@
 end subroutine initialise_mpi
 
 subroutine finalise_mpi()
+    implicit none
     call MPI_Finalize(ierror)
     call checkMPIError()
 end subroutine
 
 subroutine checkMPIError()
+    implicit none
     integer :: abortError
     if (ierror .ne. MPI_SUCCESS) then
         print*, ierror, " MPI error!"
@@ -37,6 +40,7 @@
 end subroutine checkMPIError
 
 subroutine setupCartesianVirtualTopology(dimensions, dimensionSizes, periodicDimensions, coordinates, neighbours, reorder)
+    implicit none
     integer, intent(in) :: dimensions
     integer, intent(in) :: dimensionSizes(dimensions)
     logical, intent(in) :: periodicDimensions(dimensions)
@@ -56,55 +60,66 @@
 end subroutine setupCartesianVirtualTopology
 
 logical function isMaster()
+    implicit none
     isMaster = rank .eq. 0
 end function isMaster
 
 logical function isTopRow(procPerRow)
+    implicit none
     integer, intent(in) :: procPerRow
     isTopRow = rank .lt. procPerRow
 end function isTopRow
 
 logical function isTopRowNeighbours(neighbours)
+    implicit none
     integer, dimension(:), intent(in) :: neighbours
     isTopRowNeighbours = neighbours(topNeighbour) .eq. -1
 end function isTopRowNeighbours
 
 logical function isBottomRow(procPerRow)
+    implicit none
     integer, intent(in) :: procPerRow
     isBottomRow = rank .gt. (mpi_size - procPerRow - 1)
 end function isBottomRow
 
 logical function isBottomRowNeighbours(neighbours)
+    implicit none
     integer, dimension(:), intent(in) :: neighbours
     isBottomRowNeighbours = neighbours(bottomNeighbour) .eq. -1
 end function isBottomRowNeighbours
 
 logical function isLeftmostColumn(procPerRow)
+    implicit none
     integer, intent(in) :: procPerRow
     isLeftmostColumn = modulo(rank, procPerRow) .eq. 0
 end function isLeftmostColumn
 
 logical function isLeftmostColumnNeighbours(neighbours)
+    implicit none
     integer, dimension(:), intent(in) :: neighbours
     isLeftmostColumnNeighbours = neighbours(leftNeighbour) .eq. -1
 end function isLeftmostColumnNeighbours
 
 logical function isRightmostColumn(procPerRow)
+    implicit none
     integer, intent(in) :: procPerRow
     isRightmostColumn = modulo(rank, procPerRow) .eq. (procPerRow - 1)
 end function isRightmostColumn
 
 logical function isRightmostColumnNeighbours(neighbours)
+    implicit none
     integer, dimension(:), intent(in) :: neighbours
     isRightmostColumnNeighbours = neighbours(rightNeighbour) .eq. -1
 end function isRightmostColumnNeighbours
 
 integer function topLeftRowValue(process, procPerRow, rowCount)
+    implicit none
     integer, intent(in) :: process, procPerRow, rowCount
     topLeftRowValue = process / procPerRow * rowCount
 end function topLeftRowValue
 
 integer function topLeftColValue(process, procPerRow, colCount)
+    implicit none
     integer, intent(in) :: process, procPerRow, colCount
     topLeftColValue = modulo(process, procPerRow) * colCount
 end function topLeftColValue
diff -ruBbw MPI-LES/src/communication_helper_real.f95 LES-WRF-MPI/LES/src/GMCF/Models/communication_helper_real.f95
--- MPI-LES/src/communication_helper_real.f95	2016-08-09 14:34:13.000000000 +0100
+++ LES-WRF-MPI/LES/src/GMCF/Models/communication_helper_real.f95	2015-06-22 16:04:29.000000000 +0100
@@ -2,15 +2,29 @@
 #ifdef MPI
 use communication_helper_mpi
 #endif
+#ifdef GMCF
+use communication_helper_gmcf
+#endif
+
+implicit none
 
 contains
 
 subroutine getGlobalSumOf(value)
+    implicit none
     real(kind=4), intent(inout) :: value
+#ifdef GMCF
+    integer :: rank
+    call gmcfGetModelId(rank)
+#endif
 #ifdef GR_DEBUG
     print*, 'Rank: ', rank, ' before sum: ', value
 #endif
+#ifdef GMCF
+    call getGlobalSumOfGMCF(value)
+#else
     call MPI_AllReduce(MPI_IN_PLACE, value, 1, MPI_REAL, MPI_SUM, communicator, ierror)
+#endif
 #ifdef GR_DEBUG
     print*, 'Rank: ', rank, ' after sum: ', value
 #endif
@@ -20,11 +34,20 @@
 end subroutine getGlobalSumOf
 
 subroutine getGlobalMaxOf(value)
+    implicit none
     real(kind=4), intent(inout) :: value
+#ifdef GMCF
+    integer :: rank
+    call gmcfGetModelId(rank)
+#endif
 #ifdef GR_DEBUG
     print*, 'Rank: ', rank, ' before max: ', value
 #endif
+#ifdef GMCF
+    call getGlobalMaxOfGMCF(value)
+#else
     call MPI_AllReduce(MPI_IN_PLACE, value, 1, MPI_REAL, MPI_MAX, communicator, ierror)
+#endif
 #ifdef GR_DEBUG
     print*, 'Rank: ', rank, ' after max: ', value
 #endif
@@ -34,11 +57,20 @@
 end subroutine getGlobalMaxOf
 
 subroutine getGlobalMinOf(value)
+    implicit none
     real(kind=4), intent(inout) :: value
+#ifdef GMCF
+    integer :: rank
+    call gmcfGetModelId(rank)
+#endif
 #ifdef GR_DEBUG
     print*, 'Rank: ', rank, ' before min: ', value
 #endif
+#ifdef GMCF
+    call getGlobalMinOfGMCF(value)
+#else
     call MPI_AllReduce(MPI_IN_PLACE, value, 1, MPI_REAL, MPI_MIN, communicator, ierror)
+#endif
 #ifdef GR_DEBUG
     print*, 'Rank: ', rank, ' after min: ', value
 #endif
@@ -47,18 +79,67 @@
 #endif
 end subroutine getGlobalMinOf
 
+subroutine calculateCornersReal(array, procPerRow, leftThickness, rightThickness, &
+                            topThickness, bottomThickness)
+    implicit none
+    integer, intent(in) :: procPerRow, leftThickness, rightThickness, &
+                           topThickness, bottomThickness
+    real(kind=4), dimension(:,:), intent(inout) :: array
+    integer :: r, c
+    if (.not. isTopRow(procPerRow) .and. .not. isLeftmostColumn(procPerRow)) then
+        ! There is a top left corner to specify
+        do r=topThickness,1,-1
+            do c=leftThickness,1,-1
+                array(r, c) = (array(r+1, c) + array(r, c+1) + array(r+1, c+1)) / 3.0
+            end do
+        end do
+    end if
+    if (.not. isTopRow(procPerRow) .and. .not. isRightmostColumn(procPerRow)) then
+        ! There is a top right corner to specify
+        do r=topThickness,1,-1
+            do c=size(array,2)-rightThickness+1,size(array,2)
+                array(r, c) = (array(r+1, c) + array(r, c-1) + array(r+1, c-1)) / 3.0
+            end do
+        end do
+    end if
+    if (.not. isBottomRow(procPerRow) .and. .not. isLeftmostColumn(procPerRow)) then
+        ! There is a bottom left corner to specify
+        do r=size(array,1)-bottomThickness+1,size(array,1)
+            do c=leftThickness,1,-1
+                array(r, c) = (array(r-1, c) + array(r, c+1) + array(r-1, c+1)) / 3.0
+            end do
+        end do
+    end if
+    if (.not. isBottomRow(procPerRow) .and. .not. isRightmostColumn(procPerRow)) then
+        ! There is a bottom right corner to specify
+        do r=size(array,1)-bottomThickness+1,size(array,1)
+            do c=size(array,2)-rightThickness+1,size(array,2)
+                array(r, c) = (array(r, c-1) + array(r-1, c) + array(r-1, c-1)) / 3.0
+            end do
+       end do
+    end if
+end subroutine calculateCornersReal
+
 subroutine exchangeRealHalos(array, procPerRow, neighbours, leftThickness, &
                                 rightThickness, topThickness, &
                                 bottomThickness)
+    implicit none
     real(kind=4), dimension(:,:,:), intent(inout) :: array
     integer, dimension(:), intent(in) :: neighbours
     integer, intent(in) :: procPerRow, leftThickness, rightThickness, topThickness, bottomThickness
     integer :: i, commWith, r, c, d, rowCount, colCount, depthSize
+#ifdef GMCF
+    integer :: rank
+#endif
 #ifdef MPI
     integer :: requests(8)
 #endif
     real(kind=4), dimension(:,:,:), allocatable :: leftRecv, leftSend, rightSend, rightRecv
     real(kind=4), dimension(:,:,:), allocatable :: topRecv, topSend, bottomSend, bottomRecv
+#ifdef GMCF
+    call gmcfGetModelId(rank)
+#endif
+
 #ifdef MPI
     if (size(neighbours, 1) .lt. 4) then
         print*, "Error: cannot have a 4-way halo exchange with less than 4 neighbours"
@@ -82,9 +163,14 @@
         requests(i)= MPI_REQUEST_NULL
     end do
 #endif
-    ! Top edge to send, bottom edge to receive. 
+    ! Top edge to send, bottom edge to receive
+#ifdef GMCF
+    if (.not. isTopRow(procPerRow)) then
+        commWith = rank - procPerRow
+#else
     commWith = neighbours(topNeighbour)
     if (commWith .ne. -1) then
+#endif
         !print*, 'rank ', rank, ' communicating with top neighbour ', commWith
         do r=1, bottomThickness
             do c=1, colCount
@@ -93,16 +179,25 @@
                 end do
             end do
         end do
+#ifdef GMCF
+        call gmcfSend3DFloatArray(rank, topSend, shape(topSend), topTag, commWith, PRE, 1)
+#else
         call MPI_ISend(topSend, bottomThickness*colCount*depthSize, MPI_REAL, commWith, topTag, &
                       cartTopComm, requests(1), ierror) 
         call checkMPIError()
         call MPI_IRecv(bottomRecv, topThickness*colCount*depthSize, MPI_REAL, commWith, bottomTag, &
                       communicator, requests(2), ierror)  
         call checkMPIError()
+#endif
     end if
     ! Bottom edge to send, top edge to receive
+#ifdef GMCF
+    if (.not. isBottomRow(procPerRow)) then
+        commWith = rank + procPerRow
+#else
     commWith = neighbours(bottomNeighbour)
     if (commWith .ne. -1) then
+#endif
         !print*, 'rank ', rank, ' communicating with bottom neighbour ', commWith
         do r=1, topThickness 
             do c=1, colCount
@@ -114,16 +208,25 @@
                 end do
             end do
         end do
+#ifdef GMCF
+        call gmcfSend3DFloatArray(rank, bottomSend, shape(bottomSend), bottomTag, commWith, PRE, 1)
+#else
         call MPI_IRecv(topRecv, bottomThickness*colCount*depthSize, MPI_REAL, commWith, topTag, &
                       cartTopComm, requests(3), ierror) 
         call checkMPIError()
         call MPI_ISend(bottomSend, topThickness*colCount*depthSize, MPI_REAL, commWith, bottomTag, &
                       communicator, requests(4), ierror) 
         call checkMPIError()
+#endif
     end if
     ! Left edge to send, right edge to receive
+#ifdef GMCF
+    if (.not. isLeftmostColumn(procPerRow)) then
+        commWith = rank - 1
+#else
     commWith = neighbours(leftNeighbour)
     if (commWith .ne. -1) then
+#endif
         !print*, 'rank ', rank, ' communicating with left neighbour ', commWith
         do r=1, rowCount
             do c=1, rightThickness
@@ -132,16 +235,25 @@
                 end do
             end do
         end do
+#ifdef GMCF
+        call gmcfSend3DFloatArray(rank, leftSend, shape(leftSend), leftTag, commWith, PRE, 1)
+#else
         call MPI_ISend(leftSend, rightThickness*rowCount*depthSize, MPI_REAL, commWith, leftTag, &
                       communicator, requests(5), ierror)
         call checkMPIError()
         call MPI_IRecv(rightRecv, leftThickness*rowCount*depthSize, MPI_REAL, commWith, rightTag, &
                       communicator, requests(6), ierror)
         call checkMPIError()
+#endif
     end if
     ! Right edge to send, left edge to receive
+#ifdef GMCF
+    if (.not. isRightmostColumn(procPerRow)) then
+        commWith = rank + 1
+#else
     commWith = neighbours(rightNeighbour)
     if (commWith .ne. -1) then
+#endif
         !print*, 'rank ', rank, ' communicating with right neighbour ', commWith
         do r=1, rowCount
             do c=1, leftThickness
@@ -152,19 +264,27 @@
                 end do
             end do
         end do
+#ifdef GMCF
+        call gmcfSend3DFloatArray(rank, rightSend, shape(rightSend), rightTag, commWith, PRE, 1)
+#else
         call MPI_IRecv(leftRecv, rightThickness*rowCount*depthSize, MPI_REAL, commWith, leftTag, &
                       communicator, requests(7), ierror)
         call checkMPIError()
         call MPI_ISend(rightSend, leftThickness*rowCount*depthSize, MPI_REAL, commWith, rightTag, &
                       communicator, requests(8), ierror)
         call checkMPIError()
+#endif
     end if
+#ifdef GMCF
+    call recvHaloBoundaries(leftRecv, rightRecv, topRecv, bottomRecv, procPerRow)
+#else
     do i=1,8
         if (requests(i) .ne. MPI_REQUEST_NULL) then
             call MPI_Wait(requests(i), status, ierror)
             call checkMPIError()
         end if
     end do
+#endif
     if (.not. isTopRow(procPerRow)) then
         do r=1, topThickness
             do c=1, colCount
@@ -187,7 +307,7 @@
         do r=1, rowCount
             do c=1, leftThickness
                 do d=1, depthSize
-                    array(r+topThickness, c, d) = rightRecv(r, c, d) ! OK
+                    array(r+topThickness, c, d) = rightRecv(r, c, d)
                 end do
             end do
         end do
@@ -201,7 +321,17 @@
             end do
         end do
     end if
+#ifdef GMCF
+    call waitForHaloAcks(procPerRow)
+#endif
+#ifdef EXACT_CORNERS
     call exchangeRealCorners(array, procPerRow, leftThickness, rightThickness, topThickness, bottomThickness)
+#else
+    do i=1, depthSize
+        call calculateCornersReal(array(:,:,i), procPerRow, leftThickness, &
+                              rightThickness, topThickness, bottomThickness)
+    end do
+#endif
     deallocate(leftRecv)
     deallocate(leftSend)
     deallocate(rightSend)
@@ -213,6 +343,7 @@
 end subroutine exchangeRealHalos
 
 subroutine exchangeRealCorners(array, procPerRow, leftThickness, rightThickness, topThickness, bottomThickness)
+    implicit none
     integer, intent(in) :: procPerRow, leftThickness, rightThickness, topThickness, bottomThickness
     real(kind=4), dimension(:,:,:), intent(inout) :: array
     real(kind=4), dimension(:,:,:), allocatable :: topLeftRecv, topRightRecv, bottomLeftRecv, bottomRightRecv
@@ -221,6 +352,10 @@
 #ifdef MPI
     integer :: i, requests(8)
 #endif
+#ifdef GMCF
+    integer :: rank
+    call gmcfGetModelId(rank)
+#endif
     depthSize = size(array, 3)
     allocate(topLeftRecv(bottomThickness, rightThickness, depthSize))
     allocate(topLeftSend(bottomThickness, rightThickness, depthSize))
@@ -245,6 +380,9 @@
                 end do
             end do
         end do
+#ifdef GMCF
+        call gmcfSend3DFloatArray(rank, topLeftSend, shape(topLeftSend), topLeftTag, commWith, PRE, 1)
+#endif
 #ifdef MPI
         call MPI_ISend(topLeftSend, bottomThickness*rightThickness*depthSize, MPI_REAL, &
                        commWith, topLeftTag, communicator, requests(1), ierror)
@@ -264,6 +402,9 @@
                 end do
             end do
         end do
+#ifdef GMCF
+        call gmcfSend3DFloatArray(rank, topRightSend, shape(topRightSend), topRightTag, commWith, PRE, 1)
+#endif
 #ifdef MPI
         call MPI_ISend(topRightSend, bottomThickness*leftThickness*depthSize, MPI_REAL, &
                        commWith, topRightTag, communicator, requests(3), ierror)
@@ -284,6 +425,9 @@
                 end do
             end do
         end do
+#ifdef GMCF
+        call gmcfSend3DFloatArray(rank, bottomLeftSend, shape(bottomLeftSend), bottomLeftTag, commWith, PRE, 1)
+#endif
 #ifdef MPI
         call MPI_ISend(bottomLeftSend, topThickness*rightThickness*depthSize, MPI_REAL, &
                       commWith, bottomLeftTag, communicator, requests(5), ierror)
@@ -304,6 +448,9 @@
                 end do
             end do
         end do
+#ifdef GMCF
+        call gmcfSend3DFloatArray(rank, bottomRightSend, shape(bottomRightSend), bottomRightTag, commWith, PRE, 1)
+#endif
 #ifdef MPI
         call MPI_ISend(bottomRightSend, topThickness*leftThickness*depthSize, MPI_REAL, &
                        commWith, bottomRightTag, communicator, requests(7), ierror)
@@ -313,6 +460,9 @@
         call checkMPIError()
 #endif
     end if
+#ifdef GMCF
+    call recvExactCorners(topLeftRecv, topRightRecv, bottomLeftRecv, bottomRightRecv, procPerRow)
+#endif
 #ifdef MPI
     do i=1,8
         if (requests(i) .ne. MPI_REQUEST_NULL) then
@@ -357,6 +507,9 @@
             end do
         end do
     end if
+#ifdef GMCF
+    call waitForExactCornersAcks(procPerRow)
+#endif
     deallocate(topLeftRecv)
     deallocate(topLeftSend)
     deallocate(topRightRecv)
@@ -369,18 +522,30 @@
 
 subroutine sideflowRightLeft(array, procPerRow, colToSend, colToRecv, &
                              topThickness, bottomThickness, ignoreFirstK, ignoreLastK)
+    implicit none
     integer, intent(in) :: procPerRow, colToSend, colToRecv, topThickness, bottomThickness
     real(kind=4), dimension(:,:,:), intent(inout) :: array
     real(kind=4), dimension(:,:), allocatable :: leftRecv, rightSend
     integer :: r, d, commWith, rowCount, depthSize, ignoreFirstK, ignoreLastK
+#ifdef GMCF
+    integer :: rank
+    call gmcfGetModelId(rank)
+#endif
+#ifdef GR_DEBUG
+    !print*, 'GR: rank ', rank, ' is starting sideflowRightLeft'
+#endif
     rowCount = size(array, 1) - topThickness - bottomThickness
     depthSize = size(array, 3) - ignoreFirstK - ignoreLastK
     if (isLeftmostColumn(procPerRow)) then
         allocate(leftRecv(rowCount, depthSize))
         commWith = rank + procPerRow - 1
+#ifdef GMCF
+        call recvRightLeftSideflow(leftRecv, procPerRow)
+#else
         call MPI_Recv(leftRecv, rowCount*depthSize, MPI_REAL, commWith, rightSideTag, &
                       communicator, status, ierror)
         call checkMPIError()
+#endif
         do r=1, rowCount
             do d=1+ignoreFirstK, size(array,3) - ignoreLastK
                 array(r+topThickness, colToRecv, d) = leftRecv(r, d-ignoreFirstK)
@@ -395,9 +560,14 @@
                 rightSend(r, d-ignoreFirstK) = array(r+topThickness, colToSend, d)
             end do
         end do
+#ifdef GMCF
+        call gmcfSend2DFloatArray(rank, rightSend, shape(rightSend), rightSideTag, commWith, PRE, 1)
+        call waitForRightLeftSideflowAcks(procPerRow)
+#else
         call MPI_Send(rightSend, rowCount*depthSize, MPI_REAL, commWith, rightSideTag, &
                       communicator, ierror)
         call checkMPIError()
+#endif
         deallocate(rightSend)
     end if
 #ifdef GR_DEBUG
@@ -407,10 +577,18 @@
 
 subroutine sideflowLeftRight(array, procPerRow, colToSend, colToRecv, &
                              topThickness, bottomThickness, ignoreFirstK, ignoreLastK)
+    implicit none
     integer, intent(in) :: procPerRow, colToSend, colToRecv, topThickness, bottomThickness
     real(kind=4), dimension(:,:,:), intent(inout) :: array
     real(kind=4), dimension(:,:), allocatable :: leftSend, rightRecv
     integer :: r, d, commWith, rowCount, depthSize, ignoreFirstK, ignoreLastK
+#ifdef GMCF
+    integer :: rank
+    call gmcfGetModelId(rank)
+#endif
+#ifdef GR_DEBUG
+    !print*, 'GR: rank ', rank, ' is starting sideflowLeftRight'
+#endif
     rowCount = size(array, 1) - topThickness - bottomThickness
     depthSize = size(array, 3) - ignoreFirstK - ignoreLastK
     if (isLeftmostColumn(procPerRow)) then
@@ -421,16 +599,25 @@
                 leftSend(r, d-ignoreFirstK) = array(r+topThickness, colToSend, d)
             end do
         end do
+#ifdef GMCF
+        call gmcfSend2DFloatArray(rank, leftSend, shape(leftSend), leftSideTag, commWith, PRE, 1)
+        call waitForLeftRightSideflowAcks(procPerRow)
+#else
         call MPI_Send(leftSend, rowCount*depthSize, MPI_REAL, commWith, leftSideTag, &
                       communicator, ierror)
         call checkMPIError()
+#endif
         deallocate(leftSend)
     else if (isRightmostColumn(procPerRow)) then
         allocate(rightRecv(rowCount, depthSize))
         commWith = rank - procPerRow + 1
+#ifdef GMCF
+        call recvLeftRightSideflow(rightRecv, procPerRow)
+#else
         call MPI_Recv(rightRecv, rowCount*depthSize, MPI_REAL, commWith, leftSideTag, &
                       communicator, status, ierror)
         call checkMPIError()
+#endif
         do r=1, rowCount
             do d=1+ignoreFirstK, size(array,3) - ignoreLastK
                 array(r+topThickness, colToRecv, d) = rightRecv(r, d-ignoreFirstK)
@@ -438,16 +625,32 @@
         end do
         deallocate(rightRecv)
     end if
+#ifdef GR_DEBUG
+    !print*, 'GR: rank ', rank, ' has finished sideflowLeftRight'
+#endif
+
 end subroutine sideflowLeftRight
 
 subroutine distributeZBM(zbm, ip, jp, ipmax, jpmax, procPerRow)
+    implicit none
     integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow
     real(kind=4), dimension(-1:ipmax+1,-1:jpmax+1) , intent(InOut) :: zbm
     integer :: startRow, startCol, i, r, c
     real(kind=4), dimension(ip, jp) :: sendBuffer, recvBuffer
+#ifdef GMCF
+    integer :: rank
+    call gmcfGetModelId(rank)
+#endif
+#ifdef GR_DEBUG
+    print*, 'GR: rank ', rank, ' is starting distributeZBM'
+#endif
     if (isMaster()) then
         ! Send appropriate 2D section to the other ranks
+#ifdef GMCF
+        do i = 2, mpi_size
+#else
         do i = 1, mpi_size - 1
+#endif
             startRow = topLeftRowValue(i, procPerRow, ip)
             startCol = topLeftColValue(i, procPerRow, jp)
 #ifdef GR_DEBUG
@@ -460,15 +663,23 @@
                 end do
             end do
             print*, 'GR: sendBuffer zbm sum: ', sum(sendBuffer)
+#ifdef GMCF
+            call gmcfSend2DArray(sendBuffer, rank, i, zbmTag)
+#else
             call MPI_Send(sendBuffer, (ip*jp), MPI_REAL, i, zbmTag, &
                           communicator, ierror)
             call checkMPIError()
+#endif
         end do
     else
         ! Receive appropriate 2D section from master
+#ifdef GMCF
+        call gmcfRecv2DArray(recvBuffer, ip*jp, rank, zbmTag)
+#else
         call MPI_Recv(recvBuffer, (ip*jp), MPI_REAL, 0, zbmTag, communicator, &
                       status, ierror)
         call checkMPIError()
+#endif
         print*, 'GR: recvBuffer zbm sum: ', sum(recvBuffer)
         do r=1, ip
             do c=1, jp
@@ -476,14 +687,22 @@
             end do
         end do
     end if
+#ifdef GR_DEBUG
+    print*, 'GR: rank ', rank, ' has finished distributeZBM'
+#endif
 end subroutine distributeZBM
 
 subroutine distribute1DRealRowWiseArray(arrayToBeSent, receivingArray, leftBoundary, rightBoundary, procPerRow)
+    implicit none
     real(kind=4), dimension(:), intent(in) :: arrayToBeSent
     real(kind=4), dimension(:), intent(out) :: receivingArray
     real(kind=4), dimension(:), allocatable :: sendBuffer
     integer, intent(in) :: leftBoundary, rightBoundary, procPerRow
     integer :: totalSize, receivingSize, i, startI, endI, currentI
+#ifdef GMCF
+    integer :: rank
+    call gmcfGetModelId(rank)
+#endif
     totalSize = size(arrayToBeSent, 1)
     receivingSize = size(receivingArray, 1)
     if (isMaster()) then
@@ -495,10 +714,18 @@
                 rightBoundary
 #endif
         ! Master needs to memory copy its required portion
-        receivingArray = arrayToBeSent(1:receivingSize)
+        receivingArray = arrayToBeSent(1:receivingSize+1)
+#ifdef GMCF
+        do i=2, mpi_size
+#else
         do i=1, mpi_size-1
+#endif
             ! MPI_Send
+#ifdef GMCF
+            startI = 1 + (((i-1) / procPerRow) * (receivingSize - leftBoundary - rightBoundary))
+#else
             startI = 1 + ((i / procPerRow) * (receivingSize - leftBoundary - rightBoundary))
+#endif
             endI = startI + receivingSize - 1
 #ifdef VERBOSE
             print*, ' Rank ', i, ' is getting values row wise, (', startI, ',', endI, ')'
@@ -506,26 +733,40 @@
             do currentI=startI,endI
                 sendBuffer(currentI-startI+1) = arrayToBeSent(currentI)
             end do
+#ifdef GMCF
+            print*, 'GR: rank ', i, ' is getting a sum of: ', sum(sendBuffer)
+            call gmcfSend1DArray(sendBuffer, rank, i, dxTag)
+#else
             call MPI_Send(sendBuffer, receivingSize, MPI_Real, i, dxTag, communicator, &
                           ierror)
             call checkMPIError()
+#endif
         end do
         deallocate(sendBuffer)
     else
         ! Receive receivingSize reals
+#ifdef GMCF
+        call gmcfRecv1DArray(receivingArray, receivingSize, rank, dxTag)
+#else
         call MPI_Recv(receivingArray, receivingSize, MPI_REAL, 0, dxTag, communicator, &
                       status, ierror)
         call checkMPIError()
+#endif
     end if
     print*, 'GR: rank ', rank, ' row wise sum ', sum(receivingArray)
 end subroutine distribute1DRealRowWiseArray
 
 subroutine distribute1DRealColumnWiseArray(arrayToBeSent, receivingArray, leftBoundary, rightBoundary, procPerRow)
+    implicit none
     real(kind=4), dimension(:), intent(in) :: arrayToBeSent
     real(kind=4), dimension(:), intent(out) :: receivingArray
     real(kind=4), dimension(:), allocatable :: sendBuffer
     integer, intent(in) :: leftBoundary, rightBoundary, procPerRow
     integer :: totalSize, receivingSize, i, startI, endI, currentI
+#ifdef GMCF
+    integer :: rank
+    call gmcfGetModelId(rank)
+#endif
     totalSize = size(arrayToBeSent, 1)
     receivingSize = size(receivingArray, 1)
     if (isMaster()) then
@@ -537,10 +778,18 @@
                 rightBoundary
 #endif
         ! Master needs to memory copy its required portion
-        receivingArray = arrayToBeSent(1:receivingSize)
+        receivingArray = arrayToBeSent(1:receivingSize+1)
+#ifdef GMCF
+        do i=2, mpi_size
+#else
         do i=1, mpi_size-1
+#endif
             ! MPI_Send
+#ifdef GMCF
+            startI = 1 + (modulo(i - 1, procPerRow) * (receivingSize - leftBoundary - rightBoundary))
+#else
             startI = 1 + (modulo(i, procPerRow) * (receivingSize - leftBoundary - rightBoundary))
+#endif
             endI = startI + receivingSize - 1
 #ifdef VERBOSE
             print*, ' Rank ', i, ' is getting values column wise, (', startI, ',', endI, ')'
@@ -548,27 +797,40 @@
             do currentI=startI,endI
                 sendBuffer(currentI-startI+1) = arrayToBeSent(currentI)
             end do
+#ifdef GMCF
+            call gmcfSend1DArray(sendBuffer, rank, i, dyTag)
+#else
             call MPI_Send(sendBuffer, receivingSize, MPI_Real, i, dyTag, communicator, &
                           ierror)
             call checkMPIError()
+#endif
         end do
         deallocate(sendBuffer)
     else
         ! Receive receivingSize reals
+#ifdef GMCF
+        call gmcfRecv1DArray(receivingArray, receivingSize, rank, dyTag)
+#else
         call MPI_Recv(receivingArray, receivingSize, MPI_REAL, 0, dyTag, communicator, &
                       status, ierror)
         call checkMPIError()
+#endif
     end if
 end subroutine distribute1DRealColumnWiseArray
 
 subroutine collect3DReal4Array(array, arrayTot, leftBoundary, rightBoundary, &
                                topBoundary, bottomBoundary, ip, jp, kp, procPerRow)
+    implicit none
     real(kind=4), dimension(:,:,:), intent(in) :: array
     real(kind=4), dimension(:,:,:), intent(out) :: arrayTot
     integer, intent(in) :: leftBoundary, rightBoundary, topBoundary, bottomBoundary
     integer, intent(in) :: ip, jp, kp, procPerRow
     integer :: i, startRow, startCol, r, c, d, bufferSize
     real(kind=4), dimension(:,:,:), allocatable :: recvBuffer
+#ifdef GMCF
+    integer :: rank
+    call gmcfGetModelId(rank)
+#endif
     bufferSize = size(array, 1) * size(array, 2) * size(array, 3)
     if (isMaster()) then
         allocate(recvBuffer(size(array, 1), size(array, 2), size(array, 3)))
@@ -579,9 +841,18 @@
                 end do
             end do
         end do
+#ifdef GMCF
+        do i=2, mpi_size
+            startRow = (ip) * ((i-1) / procPerRow)
+            startCol = (jp) * (modulo(i-1, procPerRow))
+#else
         do i=1, mpi_size-1
             startRow = (ip) * (i / procPerRow)
             startCol = (jp) * (modulo(i, procPerRow))
+#endif
+#ifdef GMCF
+            call recv3DReal4Array(rank, i, recvBuffer, bufferSize)
+#endif
 #ifdef MPI
             call MPI_Recv(recvBuffer, bufferSize, MPI_Real, i, collect3DReal4Tag, &
                           communicator, status, ierror)
@@ -597,6 +868,9 @@
         end do
         deallocate(recvBuffer)
     else
+#ifdef GMCF
+        call send3DReal4Array(array, rank)
+#endif
 #ifdef MPI
         call MPI_Send(array, bufferSize, MPI_Real, 0, collect3DReal4Tag, &
                       communicator, ierror)
@@ -605,1267 +879,4 @@
     end if
 end subroutine collect3DReal4Array
 
-
-
-
-subroutine distributeamask(ua, u,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow
-    real(kind=4), dimension(0:ipmax+1,0:jpmax+1,0:kp+1) , intent(InOut) :: ua
-    real(kind=4), dimension(0:ip+1,0:jp+1,0:kp+1) , intent(In) :: u
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension(ip, jp, kp) :: sendBuffer, recvBuffer
-
-    if (.not.isMaster()) then
-
-            do k=1, kp
-                do c=1, jp
-                   do r=1, ip
-                    sendBuffer(r, c, k) = u(r, c, k)
-                   end do
-                end do
-            end do
-            print*, 'GR: sendBuffer  sum: ', sum(sendBuffer)
-         
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'send_rank=',rank
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-
-    else
-  
-        do i = 1, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, i, zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-
-        print*, 'GR: recvBuffer  sum: ', sum(recvBuffer)
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-        do k=1, kp
-             do c=1, jp
-               do r=1, ip
-                ua(startRow +r, startCol + c, k) = recvBuffer(r, c, k)
-               end do
-            end do
-        end do
-   
-       
-        end do
-       end if
-    
-            
-
-end subroutine distributeamask
-
-
-subroutine distributeu(ua, u,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow
-    real(kind=4), dimension(0:ipmax+1,-1:jpmax+1,0:kp+1) , intent(InOut) :: ua
-    real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: u
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension(ip, jp, kp) :: sendBuffer,recvBuffer
-    if (.not.isMaster()) then
-
-            do k=1, kp
-                do c=1, jp
-                   do r=1, ip
-                    sendBuffer(r, c, k) = u(r, c, k)
-                   end do
-                end do
-            end do
-            print*, 'GR: sendBuffer  sum: ', sum(sendBuffer)
-
-
-!       call MPI_COMM_Rank(communicator, rank, ierror)
-!      call checkMPIError()
-
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-
-    else
-  
-        do i = 1, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, i,zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-
-        print*, 'GR: recvBuffer  sum: ', sum(recvBuffer)
-
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-
-        do k=1, kp
-             do c=1, jp
-               do r=1, ip
-                ua(startRow +r, startCol + c, k) = recvBuffer(r, c, k)
-               end do
-            end do
-        end do
-
-
-        end do
-       end if
-    
-            
-
-end subroutine distributeu
-
-
-
-subroutine distributev(ua, u,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow
-    real(kind=4), dimension(0:ipmax+1,-1:jpmax+1,0:kp+1) , intent(InOut) :: ua
-    real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: u
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension(ip, jp, kp) :: sendBuffer, recvBuffer
-    if (.not.isMaster()) then
-
-            do k=1, kp
-                do c=1, jp
-                   do r=1, ip
-                    sendBuffer(r, c, k) = u(r, c, k)
-                   end do
-                end do
-            end do
-            print*, 'GR: sendBuffer  sum: ', sum(sendBuffer)
-
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'send_rank=',rank
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-
-    else
-  
-        do i = 1, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, i,zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-        do k=1, kp
-             do c=1, jp
-               do r=1, ip
-                ua(startRow +r, startCol + c, k) = recvBuffer(r, c, k)
-               end do
-            end do
-        end do
-   
-
-        end do
-       end if
-    
-            
-
-end subroutine distributev
-
-
-
-subroutine distributew(ua, u,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow
-    real(kind=4), dimension(0:ipmax+1,-1:jpmax+1,-1:kp+1) , intent(InOut) :: ua
-    real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) , intent(In) :: u
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension(ip,jp, kp) :: sendBuffer, recvBuffer
-    if (.not.isMaster()) then
-
-            do k=1, kp
-                do c=1, jp
-                   do r=1, ip
-                    sendBuffer(r, c, k) = u(r, c, k)
-                   end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-         
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'send_rank=',rank
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-
-    else
-  
-        do i = 1, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, i,zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-        do k=1, kp
-             do c=1, jp
-               do r=1, ip
-                ua(startRow +r, startCol + c, k) = recvBuffer(r, c, k)
-               end do
-            end do
-        end do
-   
-       
-        end do
-       end if
-    
-            
-
-end subroutine distributew
-
-
-subroutine distributebondu(u, ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow, kp
-    real(kind=4), dimension(1,-1:jpmax+1,0:kp+1) , intent(InOut) :: u
-    integer :: startRow, startCol, i, r, c, k
-    real(kind=4), dimension(1, jp, kp) :: sendBuffer, recvBuffer
-
-    if (isMaster()) then
-        ! Send appropriate 2D section to the other ranks
-        do i = 1, procPerRow - 1
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-
-            do k=1, kp
-                do c=1, jp
-                    sendBuffer(1, c, k) = u(1, startCol + c, k)
-                end do
-            end do
-            print*, 'GR: sendBuffer  sum: ', sum(sendBuffer)
-
-
-            call MPI_Send(sendBuffer, (jp*kp), MPI_REAL, i, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-        end do
-    else
-        ! Receive appropriate 2D section from master
-        call MPI_Recv(recvBuffer, (jp*kp), MPI_REAL, 0, zbmTag, communicator, &
-                      status, ierror)
-        call checkMPIError()
-
-
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'recv_rank=',rank
-
-
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-        do k=1, kp
-            do c=1, jp
-                u(1, c, k) = recvBuffer(1, c, k)
-            end do
-        end do
-    end if
-end subroutine distributebondu
-
-
-subroutine distributebondv(u, ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow, kp
-    real(kind=4), dimension(1,-1:jpmax+1,0:kp+1) , intent(InOut) :: u
-    integer :: startRow, startCol, i, r, c, k
-    real(kind=4), dimension(1, jp, kp) :: sendBuffer, recvBuffer
-    if (isMaster()) then
-        ! Send appropriate 2D section to the other ranks
-        do i = 1, procPerRow - 1
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-
-            do k=1, kp
-                do c=1, jp
-                    sendBuffer(1, c, k) = u(1, startCol + c, k)
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-            call MPI_Send(sendBuffer, (jp*kp), MPI_REAL, i, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-        end do
-
-
-    else
-        ! Receive appropriate 2D section from master
-        call MPI_Recv(recvBuffer, (jp*kp), MPI_REAL, 0, zbmTag ,communicator, &
-                      status, ierror)
-        call checkMPIError()
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-        do k=1, kp
-            do c=1, jp
-                u(1, c, k) = recvBuffer(1, c, k)
-            end do
-        end do
-    end if
-end subroutine distributebondv
-
-
-
-
-
-
-subroutine distributebondw(u, ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow, kp
-    real(kind=4), dimension(1,-1:jpmax+1,-1:kp+1) , intent(InOut) :: u
-    integer :: startRow, startCol, i, r, c, k
-    real(kind=4), dimension(1, jp, kp) :: sendBuffer, recvBuffer
-
-    if (isMaster()) then
-        ! Send appropriate 2D section to the other ranks
-        do i = 1, procPerRow - 1
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-
-            do k=1, kp
-                do c=1, jp
-                    sendBuffer(1, c, k) = u(1, startCol + c, k)
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-
-
-            call MPI_Send(sendBuffer, (jp*kp), MPI_REAL, i, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-        end do
-    else
-        ! Receive appropriate 2D section from master
-        call MPI_Recv(recvBuffer, (jp*kp), MPI_REAL, 0, zbmTag, communicator, &
-                      status, ierror)
-        call checkMPIError()
-
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'recv_rank=',rank
-
-
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-        do k=1, kp
-            do c=1, jp
-                u(1, c, k) = recvBuffer(1, c, k)
-            end do
-        end do
-    end if
-end subroutine distributebondw
-
-
-subroutine distributeusum(usuma, usum,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow
-    real(kind=4), dimension(0:ipmax,0:jpmax,0:kp) , intent(InOut) :: usuma
-    real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(In) :: usum
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension(ip,jp, kp) :: sendBuffer, recvBuffer
-    if (.not.isMaster()) then
-
-            do k=1, kp
-                do c=1, jp
-                   do r=1, ip
-                    sendBuffer(r, c, k) = usum(r, c, k)
-                   end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-        
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'send_rank=',rank
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-
-    else
-  
-        do i = 1, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, i,zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-
-        do k=1, kp
-             do c=1, jp
-               do r=1, ip
-                usuma(startRow +r, startCol + c, k) = recvBuffer(r, c, k)
-               end do
-            end do
-        end do
-   
-       
-        end do
-       end if
-    
-            
-
-end subroutine distributeusum
-
-
-subroutine distributep(pa, p,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow
-    real(kind=4), dimension(0:ipmax+2,0:jpmax+2,0:kp+1) , intent(InOut) :: pa
-    real(kind=4), dimension(0:ip+2,0:jp+2,0:kp+1) , intent(In) :: p
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension(ip,jp, kp) :: sendBuffer, recvBuffer
-    if (.not.isMaster()) then
-
-            do k=1, kp
-                do c=1, jp
-                   do r=1, ip
-                    sendBuffer(r, c, k) = p(r, c, k)
-                   end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-         
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'send_rank=',rank
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-
-    else
-  
-        do i = 1, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, i,zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-        do k=1, kp
-             do c=1, jp
-               do r=1, ip
-                pa(startRow +r, startCol + c, k) = recvBuffer(r, c, k)
-               end do
-            end do
-        end do
-   
-       
-        end do
-       end if
-             
-
-end subroutine distributep
-
-
-subroutine distributef(fa, f,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow
-    real(kind=4), dimension(0:ipmax,0:jpmax,0:kp) , intent(InOut) :: fa
-    real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(In) :: f
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension(ip,jp, kp) :: sendBuffer, recvBuffer
-    if (.not.isMaster()) then
-
-            do k=1, kp
-                do c=1, jp
-                   do r=1, ip
-                    sendBuffer(r, c, k) = f(r, c, k)
-                   end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-         
-
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'send_rank=',rank
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-
-    else
-  
-        do i = 1, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, i,zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-        do k=1, kp
-             do c=1, jp
-               do r=1, ip
-                fa(startRow +r, startCol + c, k) = recvBuffer(r, c, k)
-               end do
-            end do
-        end do
-   
-       
-        end do
-       end if
-    
-            
-
-end subroutine distributef
-
-
-subroutine distributefold(folda, fold,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow
-    real(kind=4), dimension(ipmax,jpmax,kp) , intent(InOut) :: folda
-    real(kind=4), dimension(ip,jp,kp) , intent(In) :: fold
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension(ip,jp, kp) :: sendBuffer, recvBuffer
-    if (.not.isMaster()) then
-
-            do k=1, kp
-                do c=1, jp
-                   do r=1, ip
-                    sendBuffer(r, c, k) = fold(r, c, k)
-                   end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-
-         
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'send_rank=',rank
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-
-    else
-  
-        do i = 1, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, i,zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-        call MPI_COMM_Rank(communicator, rank, ierror)
-        call checkMPIError()
-
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-        do k=1, kp
-             do c=1, jp
-               do r=1, ip
-                folda(startRow +r, startCol + c, k) = recvBuffer(r, c, k)
-               end do
-            end do
-        end do
-   
-       
-        end do
-       end if
-    
-            
-
-end subroutine distributefold
-
-
-subroutine distributeifu(ua, ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow, kp
-    real(kind=4), dimension(0:ipmax+1,-1:jpmax+1,0:kp+1), intent(InOut) :: ua
-    integer :: startRow, startCol, i, r, c, k
-    real(kind=4), dimension(ip, jp, kp) :: sendBuffer, recvBuffer
-
-    if (isMaster()) then
-        ! Send appropriate 2D section to the other ranks
-        do i = 1, mpi_size - 1
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-
-            do k=1, kp
-                do c=1, jp
-                 do r=1,ip
-                    sendBuffer(r, c, k) = ua(startRow + r, startCol + c, k)
-                  end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, i, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-        end do
-    else
-        ! Receive appropriate 2D section from master
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, communicator, &
-                      status, ierror)
-        call checkMPIError()
-
-
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'recv_rank=',rank
-
-
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-        do k=1, kp
-            do c=1, jp
-             do r=1, ip
-                ua(r, c, k) = recvBuffer(r, c, k)
-             end do
-            end do
-        end do
-    end if
-end subroutine distributeifu
-
-
-subroutine distributeifw(wa, ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow, kp
-    real(kind=4), dimension(0:ipmax+1,-1:jpmax+1,-1:kp+1), intent(InOut) :: wa
-    integer :: startRow, startCol, i, r, c, k
-    real(kind=4), dimension(ip, jp, kp) :: sendBuffer, recvBuffer
-
-    if (isMaster()) then
-        ! Send appropriate 2D section to the other ranks
-        do i = 1, mpi_size - 1
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-
-            do k=1, kp
-                do c=1, jp
-                 do r=1, ip
-                    sendBuffer(r, c, k) = wa(startRow + r, startCol + c, k)
-                 end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, i, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-        end do
-    else
-        ! Receive appropriate 2D section from master
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, communicator, &
-                      status, ierror)
-        call checkMPIError()
-
-
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'recv_rank=',rank
-
-
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-        do k=1, kp
-            do c=1, jp
-             do r=1, ip
-                wa(r, c, k) = recvBuffer(r, c, k)
-             end do
-            end do
-        end do
-    end if
-end subroutine distributeifw
-
-
-subroutine distributeifusum(usuma, ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow, kp
-    real(kind=4), dimension(0:ipmax,0:jpmax,0:kp), intent(InOut) :: usuma
-    integer :: startRow, startCol, i, r, c, k
-    real(kind=4), dimension(ip, jp, kp) :: sendBuffer, recvBuffer
-
-    if (isMaster()) then
-        ! Send appropriate 2D section to the other ranks
-        do i = 1, mpi_size - 1
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-
-            do k=1, kp
-                do c=1, jp
-                 do r=1, ip
-                    sendBuffer(r, c, k) = usuma(startRow + r, startCol + c, k)
-                 end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, i, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-        end do
-    else
-        ! Receive appropriate 2D section from master
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, communicator, &
-                      status, ierror)
-        call checkMPIError()
-
-
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'recv_rank=',rank
-
-
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-        do k=1, kp
-            do c=1, jp
-             do r=1, ip
-                usuma(r, c, k) = recvBuffer(r, c, k)
-             end do
-            end do
-        end do
-    end if
-end subroutine distributeifusum
-
-
-subroutine distributeifp(pa, ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow, kp
-    real(kind=4), dimension(0:ipmax+2,0:jpmax+2,0:kp+1), intent(InOut) :: pa
-    integer :: startRow, startCol, i, r, c, k
-!    real(kind=4), dimension(0:1, -1:jp+1, 0:kp+1) :: sendBuffer, recvBuffer
-    real(kind=4), dimension(ip, jp, kp) :: sendBuffer, recvBuffer
-
-    if (isMaster()) then
-        ! Send appropriate 2D section to the other ranks
-        do i = 1, mpi_size - 1
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-
-            do k=1, kp
-                do c=1, jp
-                 do r=1, ip
-                    sendBuffer(r, c, k) = pa(startRow + r, startCol + c, k)
-                 end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, i, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-        end do
-    else
-        ! Receive appropriate 2D section from master
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, communicator, &
-                      status, ierror)
-        call checkMPIError()
-
-
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'recv_rank=',rank
-
-
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-        do k=1, kp
-            do c=1, jp
-             do r=1, ip
-                pa(r, c, k) = recvBuffer(r, c, k)
-             end do
-            end do
-        end do
-    end if
-end subroutine distributeifp
-
-
-subroutine distributeiff(fa, ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow, kp
-    real(kind=4), dimension(0:ipmax,0:jpmax,0:kp), intent(InOut) :: fa
-    integer :: startRow, startCol, i, r, c, k
-    real(kind=4), dimension(ip, jp, kp) :: sendBuffer, recvBuffer
-
-    if (isMaster()) then
-        ! Send appropriate 2D section to the other ranks
-        do i = 1, mpi_size - 1
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-
-            do k=1, kp
-                do c=1, jp
-                 do r=1, ip
-                    sendBuffer(r, c, k) = fa(startRow + r, startCol + c, k)
-                 end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, i, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-        end do
-    else
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, communicator, &
-                      status, ierror)
-        call checkMPIError()
-
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'recv_rank=',rank
-
-
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-        do k=1, kp
-            do c=1, jp
-             do r=1, ip
-                fa(r, c, k) = recvBuffer(r, c, k)
-             end do
-            end do
-        end do
-    end if
-end subroutine distributeiff
-
-
-subroutine distributeiffold(folda, ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow, kp
-    real(kind=4), dimension(ipmax,jpmax,kp), intent(InOut) :: folda
-    integer :: startRow, startCol, i, r, c, k
-    real(kind=4), dimension(ip, jp, kp) :: sendBuffer, recvBuffer
-
-    if (isMaster()) then
-        ! Send appropriate 2D section to the other ranks
-        do i = 1, mpi_size - 1
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-
-            do k=1, kp
-                do c=1, jp
-                 do r=1, ip
-                    sendBuffer(r, c, k) = folda(startRow + r, startCol + c, k)
-                 end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, i, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-        end do
-    else
-        ! Receive appropriate 2D section from master
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, communicator, &
-                      status, ierror)
-        call checkMPIError()
-
-
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'recv_rank=',rank
-
-
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-        do k=1, kp
-            do c=1, jp
-             do r=1, ip
-                folda(r, c, k) = recvBuffer(r, c, k)
-             end do
-            end do
-        end do
-    end if
-end subroutine distributeiffold
-
-
-subroutine distributeaveu(aveua, aveu,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow
-    real(kind=4), dimension(0:ipmax,0:jpmax,0:kp) , intent(InOut) :: aveua
-    real(kind=4), dimension(ip,jp,0:kp) , intent(In) :: aveu
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension(ip,jp, kp) :: sendBuffer, recvBuffer
-    if (.not.isMaster()) then
-
-            do k=1, kp
-                do c=1, jp
-                   do r=1, ip
-                    sendBuffer(r, c, k) = aveu(r, c, k)
-                   end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-        
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'send_rank=',rank
-
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-
-    else
-  
-        do i = 1, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, i,zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-        do k=1, kp
-             do c=1, jp
-               do r=1, ip
-                aveua(startRow +r, startCol + c, k) = recvBuffer(r, c, k)
-               end do
-            end do
-        end do
-
-       
-        end do
-       end if
-    
-            
-
-end subroutine distributeaveu
-
-
-subroutine distributeavew(avewa, avew,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow
-    real(kind=4), dimension(ipmax+1,jpmax,0:kp+2) , intent(InOut) :: avewa
-    real(kind=4), dimension(ip+1,jp,0:kp+2) , intent(In) :: avew
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension(ip,jp, kp) :: sendBuffer, recvBuffer
-    if (.not.isMaster()) then
-
-            do k=1, kp
-                do c=1, jp
-                   do r=1, ip
-                    sendBuffer(r, c, k) = avew(r, c, k)
-                   end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-         
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'send_rank=',rank
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-
-    else
-  
-        do i = 1, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, i,zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-        do k=1, kp
-             do c=1, jp
-               do r=1, ip
-                avewa(startRow +r, startCol + c, k) = recvBuffer(r, c, k)
-               end do
-            end do
-        end do
-   
-       
-        end do
-       end if
-    
-
-end subroutine distributeavew
-
-
-subroutine distributeaveuu(aveuua, aveuu,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, ipmax, jpmax, procPerRow
-    real(kind=4), dimension(0:ipmax,0:jpmax,0:kp) , intent(InOut) :: aveuua
-    real(kind=4), dimension(ip,jp,kp) , intent(In) :: aveuu
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension(ip,jp, kp) :: sendBuffer, recvBuffer
-    if (.not.isMaster()) then
-
-            do k=1, kp
-                do c=1, jp
-                   do r=1, ip
-                    sendBuffer(r, c, k) = aveuu(r, c, k)
-                   end do
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-         
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'send_rank=',rank
-
-
-            call MPI_Send(sendBuffer, (ip*jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-
-    else
-  
-        do i = 1, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (ip*jp*kp), MPI_REAL, i,zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-        do k=1, kp
-             do c=1, jp
-               do r=1, ip
-                aveuua(startRow +r, startCol + c, k) = recvBuffer(r, c, k)
-               end do
-            end do
-        end do
-   
-       
-        end do
-       end if
-    
-            
-
-end subroutine distributeaveuu
-
-
-
-subroutine distributebondoutu(ubonda, u,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, kp, ipmax, jpmax, procPerRow
-    real(kind=4), dimension(1,jpmax,kp) , intent(InOut) :: ubonda
-    real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: u
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension( 1, jp, kp) :: sendBuffer, recvBuffer
-
-    if (isBottomRow(procPerRow)) then
-
-            do k=1, kp
-                do c=1, jp
-                    sendBuffer(1, c, k) = u(ip, c, k)
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-         
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'send_rank=',rank
-
-
-
-            call MPI_Send(sendBuffer, (jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-    end if
-
-        if (isMaster()) then
-
-        do i = mpi_size - procPerRow, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (jp*kp), MPI_REAL, i,zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-        do k=1, kp
-             do c=1, jp
-                ubonda(1, startCol + c, k) = recvBuffer(1, c, k)
-            end do
-        end do
-
-       
-        end do
-       end if
- end subroutine distributebondoutu
-
-
-
-subroutine distributebondoutw(wbonda, w,ip, jp, kp, ipmax, jpmax, procPerRow)
-    integer, intent(in) :: ip, jp, kp,ipmax, jpmax, procPerRow
-    real(kind=4), dimension(1,jpmax,kp) , intent(InOut) :: wbonda
-    real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) , intent(In) :: w
-    integer :: startRow, startCol, i, r, c, k, rank,j
-    character(70) :: cha
-    real(kind=4), dimension( 1, jp, kp) :: sendBuffer, recvBuffer
-    if (isBottomRow(procPerRow)) then
-
-            do k=1, kp
-                do c=1, jp
-                    sendBuffer(1, c, k) = w(ip, c, k)
-                end do
-            end do
-            print*, 'GR: sendBuffer sum: ', sum(sendBuffer)
-         
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-!        write(*,*) 'send_rank=',rank
-
-
-
-            call MPI_Send(sendBuffer, (jp*kp), MPI_REAL, 0, zbmTag, &
-                          communicator, ierror)
-            call checkMPIError()
-
-
-    end if
-
-        if (isMaster()) then
-  
-        do i = mpi_size - procPerRow, mpi_size - 1
-
-        call MPI_Recv(recvBuffer, (jp*kp), MPI_REAL, i,zbmTag,communicator,&
-                      status, ierror)
-        call checkMPIError()
-
-!        call MPI_COMM_Rank(communicator, rank, ierror)
-!        call checkMPIError()
-        print*, 'GR: recvBuffer sum: ', sum(recvBuffer)
-
-
-            startRow = topLeftRowValue(i, procPerRow, ip)
-            startCol = topLeftColValue(i, procPerRow, jp)
-        write(*,*) 'startRow=',startRow,'startCol=',startCol
-
-        do k=1, kp
-             do c=1, jp
-               do r=1, ip
-                wbonda(1, startCol + c, k) = recvBuffer(1, c, k)
-               end do
-            end do
-        end do
-
-       
-        end do
-       end if
-
-  end subroutine distributebondoutw
 end module

diff -ruBbw MPI-LES/src/feedbf.f95 LES-WRF-MPI/LES/src/GMCF/Models/feedbf.f95
--- MPI-LES/src/feedbf.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/feedbf.f95	2015-06-22 16:04:30.000000000 +0100
@@ -2,8 +2,8 @@
 
 contains
 
-subroutine feedbf(km,jm,im,usum,u,bmask1,vsum,v,cmask1,wsum,w,dmask1,alpha,&
-                  dt,beta,fx,fy,fz,f,g,h)
+      subroutine feedbf(km,jm,im,usum,u,bmask1,vsum,v,cmask1,wsum,w,dmask1,alpha,dt,beta,fx,fy,fz,f, &
+      g,h)
     use common_sn ! create_new_include_statements() line 102
     real(kind=4), intent(In) :: alpha
     real(kind=4), intent(In) :: beta
@@ -26,6 +26,7 @@
     real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(InOut) :: vsum
     real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) , intent(In) :: w
     real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(InOut) :: wsum
+! 
 #ifdef WV_DEBUG
     print *, 'F95 UVWSUMSUM after bondv1:',sum(usum)+sum(vsum)+sum(wsum)
     print *, 'F95 USUMSUM after bondv1:',sum(usum)
@@ -31,7 +32,9 @@
     print *, 'F95 USUMSUM after bondv1:',sum(usum)
     print *, 'F95 VSUMSUM after bondv1:',sum(vsum)
     print *, 'F95 WSUMSUM after bondv1:',sum(wsum)
+
 #endif
+! 
     do k = 1,km
         do j = 1,jm
             do i = 1,im
@@ -72,7 +79,14 @@
     print *, 'F95 USUM after feedbf:', sum(u)
     print *, 'F95 VSUM after feedbf:', sum(v)
     print *, 'F95 WSUM after feedbf:', sum(w)
+
 #endif
+! 
+      return
 end subroutine feedbf
 
+
+
+
 end module module_feedbf
+
diff -ruBbw MPI-LES/src/feedbfm.f95 LES-WRF-MPI/LES/src/GMCF/Models/feedbfm.f95
--- MPI-LES/src/feedbfm.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/feedbfm.f95	2015-06-22 16:04:30.000000000 +0100
@@ -13,12 +13,9 @@
     integer, intent(In) :: im
     integer, intent(In) :: jm
     integer, intent(In) :: km
-    real(kind=4), dimension(0:kp+2) , intent(In) :: z2
+    real(kind=4), dimension(kp+2) , intent(In) :: z2
     real(kind=4), dimension(-1:ipmax+1,-1:jpmax+1) , intent(InOut) :: zbm
     integer :: i, j, k
-    real(kind=4), dimension(-1:3001,-1:751) :: dsm,dem
-
-
 !
 !    print *, 'Urban model'
 ! -------Urban model----------
@@ -32,52 +29,20 @@
             end do
         end do
     end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isMaster()) then
 #endif
         print*, 'zbm sum - file getting read'
         !      print *, 'open GIS/Tokyo_20mgrid.txt'
         ! WV: the problem with this is that this input file expects the grid to be 150 x 150, because otherwise zbm segfaults!
-!        open(70,file='GIS/LES_GIS_dsm.txt', form='formatted',status='unknown')
-!        do j = 1,250
-!            do i = 1,250
-!                read(70,*) zbm(i+25,j+25)
-!            end do
-!        end do
-!        close(70)
-
-
-
-
-      open(70,file='./GIS/DEM_LES_GIS.txt',form='formatted',status='unknown')
-
-      do j=1,750
-        do i=1,3000
-          read(70,*) dem(i,j)
+        open(70,file='GIS/Tokyo_20mgrid.txt', form='formatted',status='unknown')
+        do j = 100,1,-1
+            do i = 1,100
+                read(70,*) zbm(i+25,j+25) 
         end do
       end do
       close(70)
-
-      open(71,file='./GIS/DSM_LES_GIS.txt',form='formatted',status='unknown')
-
-      do j=1,750
-        do i=1,3000
-          read(71,*) dsm(i,j)
-        end do
-      end do
-      close(71)
-
-
-!this domain is using 11km(the north to south direction)  1km(the west to east direction) in Kyoto city
-      do j=1,250
-        do i=1,2750
-!if we use this setting for zbm, it can include our observation point, our observation point is (i,j)=(2788,152) in our observation point  
-          zbm(i+125,j+25)=dsm(i+250,j+138)-dem(i+250,j+138)
-        end do
-      end do
-
-
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     end if
     call distributeZBM(zbm, ip, jp, ipmax, jpmax, procPerRow)
 #endif
@@ -93,14 +58,6 @@
             end do
         end do
     end do
-
-    if (isMaster()) then
-      do k=1,km
-!       write(*,*) 'a=',amask1(100,100,k)
-!       write(*,*) 'zbm(i,j)=', zbm(100,100)
-        write(*,*) 'z2=',z2(k)
-      end do
-    end if
 ! -----------------------------------------------------------------------
 !print *, 'assign bcd masks'
     do k = 1,km
@@ -114,7 +71,7 @@
             end do
         end do
     end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     call exchangeRealHalos(amask1, procPerRow, neighbours, 1, 1, 1, 1)
     call exchangeRealHalos(bmask1, procPerRow, neighbours, 1, 1, 2, 1)
     call exchangeRealHalos(cmask1, procPerRow, neighbours, 2, 1, 1, 1)
Only in LES-WRF-MPI/LES/src/GMCF/Models/: fortran_helper.mod
Only in LES-WRF-MPI/LES/src/GMCF/Models/: fortran_helper.o
Only in LES-WRF-MPI/LES/src/GMCF/Models/: gmcfConfiguration.f95
diff -ruBbw MPI-LES/src/grid.f95 LES-WRF-MPI/LES/src/GMCF/Models/grid.f95
--- MPI-LES/src/grid.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/grid.f95	2015-06-22 16:04:30.000000000 +0100
@@ -12,8 +12,8 @@
         real(kind=4), dimension(0:jp) , intent(Out) :: dys
         real(kind=4), dimension(-1:kp+2) , intent(Out) :: dzn
         real(kind=4), dimension(-1:kp+2) , intent(Out) :: dzs
-        real(kind=4), dimension(0:kp+2) , intent(Out) :: z2
-#ifdef MPI
+        real(kind=4), dimension(kp+2) , intent(Out) :: z2
+#if defined(MPI) || defined(GMCF)
         real(kind=4), dimension(-1:(ip*procPerCol)+1) :: dx1Tot
         real(kind=4), dimension(0:(jp*procPerRow)+1) :: dy1Tot
         real(kind=4), dimension(0:ip*procPerCol) :: dxlTot
@@ -25,20 +25,20 @@
 ! --dx set; streamwise direction
 ! WV: so -1 and ip+1 are not set!!! I changed it analogous to dy1
 !      do i = 0,ip
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isMaster()) then
         do i=-1,(ip*procPerCol)+1
-            dx1Tot(i) = 4.
+            dx1Tot(i) = 20.
         end do
     end if
     call distribute1DRealRowWiseArray(dx1Tot,dx1, 2, 1, procPerRow)
 #else
       do i = -1,ip+1
-       dx1(i) = 4.
+       dx1(i) = 20.
       end do
 #endif
 
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isMaster()) then
         dxlTot(0) = 0.
         do i = 1, ip*procPerCol
@@ -56,20 +56,20 @@
 ! --dy set; spanwise direction
 !WV: let's set the *whole* array to this value!
       !do j = 0,jp
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isMaster()) then
         do j=0,(jp*procPerRow)+1
-            dy1Tot(j) = 4.
+            dy1Tot(j) = 20.
         end do
     end if
     call distribute1DRealColumnWiseArray(dy1Tot, dy1, 1, 1, procPerRow)
 #else
       do j = 0,jp+1
-       dy1(j) = 4.
+       dy1(j) = 20.
       end do
 #endif
 
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isMaster()) then
         dylTot(0) = 0.
         do j=1,(jp*procPerRow)
@@ -85,64 +85,23 @@
 #endif
 ! --dz set; vertical direction
 !WV: also define the first and last point in the array!
-!      do k = 0,1
-!        z2(k) = 2.5
-!        dzn(k) = 2.5
-!      end do
-!      do k = 2,15
-!        dzn(k) = dzn(k-1)*1.05
-!      end do
-!      do k = 16,44
-!        dzn(k) = 5.
-!      end do
-!      do k = 45,kp+1
-!        dzn(k) = dzn(k-1)*1.0459
-!      end do
-!      do k = 2,kp+2 ! WV: was kp+1
-!        z2(k) = z2(k-1)+dzn(k)
-!      end do
-      ! so z2(kp+2) is not set, why?
-
-!original
-!      do k=0,1
-!        z2(k)= 1.
-!        dzn(k)= 1.
-!        write(*,*) 'dzn=',dzn(k)
-!      end do
-
-
-        z2(0)= 1.
-        dzn(0)= 1.
-
-        z2(1)= 1.
-        dzn(1)= 1.
-
+      do k = 0,1
+        z2(k) = 2.5
+        dzn(k) = 2.5
+      end do      
       do k=2,15
-        dzn(k)=dzn(k-1)*1.1
-        write(*,*) 'dzn=',dzn(k)
+        dzn(k) = dzn(k-1)*1.05
       end do
       do k=16,44
-        dzn(k)=4.
+        dzn(k) = 5.
       end do
-      do k=45,58
-        dzn(k)=dzn(k-1)*1.1
+      do k = 45,kp+1
+        dzn(k) = dzn(k-1)*1.0459
       end do
-      do k=59,kp+1
-        dzn(k)=16.
+      do k = 2,kp+2 ! WV: was kp+1
+        z2(k) = z2(k-1)+dzn(k)
       enddo
-      do k=2,kp+2
-        z2(k)=z2(k-1)+dzn(k)  !Height
-      end do
-
-    if (isMaster()) then
-      do k=1,kp
-!       write(*,*) 'a=',amask1(100,100,k)
-!       write(*,*) 'zbm(i,j)=', zbm(100,100)
-        write(*,*) 'z2grid=',z2(k)
-      end do
-    end if
-
-
+      ! so z2(kp+2) is not set, why?
 ! --gaiten deno haba
       dzn(kp+1) = dzn(kp)
       !WV
Only in MPI-LES/src/: hist.txt
diff -ruBbw MPI-LES/src/ifdata.f95 LES-WRF-MPI/LES/src/GMCF/Models/ifdata.f95
--- MPI-LES/src/ifdata.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/ifdata.f95	2015-06-22 16:04:30.000000000 +0100
@@ -15,7 +15,7 @@
       subroutine zero_arrays(cov1,cov2,cov3,cov4,cov5,cov6,cov7,cov8,cov9, &
               dfu1, dfv1, dfw1, &
               diu1,diu2,diu3,diu4,diu5,diu6,diu7,diu8,diu9,  &
-!              f,g,h, &
+              f,g,h, &
               nou1,nou2,nou3,nou4,nou5,nou6,nou7,nou8,nou9 &
               )
       use common_sn
@@ -40,9 +40,9 @@
         real(kind=4), dimension(0:ip+2,0:jp+2,0:kp+2) , intent(Out) :: diu7
         real(kind=4), dimension(0:ip+2,0:jp+2,0:kp+2) , intent(Out) :: diu8
         real(kind=4), dimension(0:ip+2,0:jp+2,0:kp+2) , intent(Out) :: diu9
-!        real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(Out) :: f
-!        real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(Out) :: g
-!        real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(Out) :: h
+        real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(Out) :: f
+        real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(Out) :: g
+        real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(Out) :: h
         real(kind=4), dimension(-1:ip+2,0:jp+2,0:kp+2) , intent(Out) :: nou1
         real(kind=4), dimension(0:ip+2,0:jp+2,0:kp+2) , intent(Out) :: nou2
         real(kind=4), dimension(0:ip+2,0:jp+2,0:kp+2) , intent(Out) :: nou3
@@ -114,28 +114,28 @@
           end do
           end do
 
-!          do k = 0,kp
-!          do j = 0,jp
-!          do i = 0,ip
-!              f(i,j,k) = 0.0
-!              g(i,j,k) = 0.0
-!              h(i,j,k) = 0.0
-!          end do
-!          end do
-!          end do
+          do k = 0,kp
+          do j = 0,jp
+          do i = 0,ip
+              f(i,j,k) = 0.0
+              g(i,j,k) = 0.0
+              h(i,j,k) = 0.0
+          end do
+          end do
+          end do 
 
       end subroutine
 
       subroutine ifdata( &
-!#if ICAL == 1
-      data30,data31, fold,gold,hold,fghold, time, &
-!#endif
+#if ICAL == 1
+      data30,data31, fold,gold,hold,fghold, time &
+#endif
       n,u,im,jm,km,v,w,p,usum,vsum,wsum, &
       delx1,dx1,dy1,dzn,diu1,diu2,diu3,diu4,diu5,diu6,diu7,diu8,diu9,sm,f,g,h,z2,dt, &
       dxs,cov1,cov2,cov3,dfu1,vn,cov4,cov5,cov6,dfv1,cov7,cov8,cov9,dfw1,dzs,nou1,nou5,nou9,nou2, &
-      nou3,nou4,nou6,nou7,nou8,bmask1,cmask1,dmask1,alpha,beta,fx,fy,fz,amask1,zbm,ical)
+      nou3,nou4,nou6,nou7,nou8,bmask1,cmask1,dmask1,alpha,beta,fx,fy,fz,amask1,zbm)
       use common_sn ! create_new_include_statements() line 102
-!#if ICAL == 1
+#if ICAL == 1
         character(len=70), intent(In) :: data30
         character(len=70), intent(In) :: data31
         real(kind=4), dimension(ip,jp,kp) , intent(InOut) :: fghold
@@ -143,9 +143,7 @@
         real(kind=4), dimension(ip,jp,kp) , intent(InOut) :: gold
         real(kind=4), dimension(ip,jp,kp) , intent(InOut) :: hold
         real(kind=4), intent(InOut) :: time
-        integer, intent(In) :: ical
-
-!#endif
+#endif
         real(kind=4), intent(In) :: alpha
         real(kind=4), dimension(0:ip+1,0:jp+1,0:kp+1) , intent(Out) :: amask1
         real(kind=4), intent(In) :: beta
@@ -208,28 +206,8 @@
         real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(InOut) :: vsum
         real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) , intent(InOut) :: w
         real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(InOut) :: wsum
-        real(kind=4), dimension(0:kp+2) , intent(In) :: z2
+        real(kind=4), dimension(kp+2) , intent(In) :: z2
         real(kind=4), dimension(-1:ipmax+1,-1:jpmax+1) , intent(InOut) :: zbm
-!
-!input
-    real(kind=4),allocatable :: ua(:,:,:)
-    real(kind=4),allocatable :: va(:,:,:)
-    real(kind=4),allocatable :: wa(:,:,:)
-    real(kind=4),allocatable :: usuma(:,:,:)
-    real(kind=4),allocatable :: vsuma(:,:,:)
-    real(kind=4),allocatable :: wsuma(:,:,:)
-    real(kind=4),allocatable :: pa(:,:,:)
-    real(kind=4),allocatable :: fa(:,:,:)
-    real(kind=4),allocatable :: ga(:,:,:)
-    real(kind=4),allocatable :: ha(:,:,:)
-    real(kind=4),allocatable :: folda(:,:,:)
-    real(kind=4),allocatable :: golda(:,:,:)
-    real(kind=4),allocatable :: holda(:,:,:)
-
-        
-
-
-
 #if IADAM == 1
         character(len=70) :: data21dummy
         integer :: n1,n2
@@ -246,292 +224,62 @@
 !           =  1;continuous data read,start
 !           = 10;continuous data write
 !
-!#if ICAL == 1
-
-
-       if(ical == 1) then
-
- 
-        if (isMaster()) then
-
-        open(unit=30,file='data30048000.dat',form='unformatted',status='unknown')
+#if ICAL == 1
+!        if(ical == 1) then
+        open(unit=30,file=data30,form='unformatted',status='unknown')
         read(30) n,time
-        end if
- 
-        allocate(ua(0:ipmax+1,-1:jpmax+1,0:kp+1))
-         
-        if (isMaster()) then
-        read(30) (((ua(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeifu(ua, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         u(i,j,k)=ua(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(ua)
- 
-
-        allocate(va(0:ipmax+1,-1:jpmax+1,0:kp+1))               
-        if (isMaster()) then
-        read(30) (((va(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeifu(va, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         v(i,j,k)=va(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(va)
-
-
-        allocate(wa(0:ipmax+1,-1:jpmax+1,-1:kp+1))
-        if (isMaster()) then
-        read(30) (((wa(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeifw(wa, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         w(i,j,k)=wa(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(wa)
-
-
-        allocate(pa(0:ipmax+2,0:jpmax+2,0:kp+1))
-        if (isMaster()) then
-        read(30) (((pa(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeifp(pa, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         p(i,j,k)=pa(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(pa)
-
-
-        allocate(usuma(0:ipmax,0:jpmax,0:kp))
-        if (isMaster()) then
-        read(30) (((usuma(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeifusum(usuma, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         usum(i,j,k)=usuma(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(usuma)
-
-
-        allocate(vsuma(0:ipmax,0:jpmax,0:kp))
-        if (isMaster()) then
-        read(30) (((vsuma(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeifusum(vsuma, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         vsum(i,j,k)=vsuma(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(vsuma)
-
-
-        allocate(wsuma(0:ipmax,0:jpmax,0:kp))
-        if (isMaster()) then
-        read(30) (((wsuma(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeifusum(wsuma, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         wsum(i,j,k)=wsuma(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(wsuma)
-
-        if (isMaster()) then
+        read(30) (((u(i,j,k),i=1,im),j=1,jm),k=1,km)
+        read(30) (((v(i,j,k),i=1,im),j=1,jm),k=1,km)
+        read(30) (((w(i,j,k),i=1,im),j=1,jm),k=1,km)
+        read(30) (((p(i,j,k),i=1,im),j=1,jm),k=1,km)
+        read(30) (((usum(i,j,k),i=1,im),j=1,jm),k=1,km)
+        read(30) (((vsum(i,j,k),i=1,im),j=1,jm),k=1,km)
+        read(30) (((wsum(i,j,k),i=1,im),j=1,jm),k=1,km) 
         close(30)
-        end if
-
-
-!31
-        if (isMaster()) then
-
-        open(unit=31,file='data31048000.dat',form='unformatted',status='unknown')
-        end if
-
-        allocate(fa(0:ipmax,0:jpmax,0:kp))
-
-        if (isMaster()) then
-        read(31) (((fa(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeiff(fa, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         f(i,j,k)=fa(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(fa)
-
-        allocate(ga(0:ipmax,0:jpmax,0:kp))
-        if (isMaster()) then
-        read(31) (((ga(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeiff(ga, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         g(i,j,k)=ga(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(ga)
-
-
-        allocate(ha(0:ipmax,0:jpmax,0:kp))
-        if (isMaster()) then
-        read(31) (((ha(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeiff(ha, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         h(i,j,k)=ha(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(ha)
-
-
-        allocate(folda(ipmax,jpmax,kp))
-
-        if (isMaster()) then
-        read(31) (((folda(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeiffold(folda, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         fold(i,j,k)=folda(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(folda)
-
-
-        allocate(golda(ipmax,jpmax,kp))
-
-        if (isMaster()) then
-        read(31) (((golda(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeiffold(golda, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         gold(i,j,k)=golda(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(golda)
 
-
-        allocate(holda(ipmax,jpmax,kp))
-
-        if (isMaster()) then
-        read(31) (((holda(i,j,k),i=1,ipmax),j=1,jpmax),k=1,km)
-        end if
-
-        call distributeiffold(holda, ip, jp, kp, ipmax, jpmax, procPerRow)
-        do k=1,km
-        do j=1,jm
-        do i=1,im
-         hold(i,j,k)=holda(i,j,k)
-        end do
-        end do
-        end do
-        deallocate(holda)
-
-        if (isMaster()) then
+        open(unit=31,file=data31,form='unformatted',status='unknown')
+        read(31) (((fold(i,j,k),i=1,im),j=1,jm),k=1,km)
+        read(31) (((gold(i,j,k),i=1,im),j=1,jm),k=1,km)
+        read(31) (((hold(i,j,k),i=1,im),j=1,jm),k=1,km)
+        read(31) (((fghold(i,j,k),i=1,im),j=1,jm),k=1,km)
         close(31)
-        end if
-
-
-
-
-!#endif
-
-
-
-
-
-
+!        end if
+#endif
 ! WV: I added this routine to explicitly set all arrays to zero
 
         call zero_arrays( &
               cov1,cov2,cov3,cov4,cov5,cov6,cov7,cov8,cov9, &
               dfu1, dfv1, dfw1, &
               diu1,diu2,diu3,diu4,diu5,diu6,diu7,diu8,diu9,  &
-!              f,g,h, &
+              f,g,h, &
               nou1,nou2,nou3,nou4,nou5,nou6,nou7,nou8,nou9 &
          )
 
+        call bondv1(jm,u,z2,dzn,v,w,km,n,im,dt,dxs)
 
-     end if
-
-
-!        call bondv1(jm,u,z2,dzn,v,w,km,n,im,dt,dxs)
+        call boundp1(km,jm,p,im)
 
-!        call boundp1(km,jm,p,im)
-
-!        call boundp2(jm,im,p,km)
-!        call velfg(km,jm,im,dx1,cov1,cov2,cov3,dfu1,diu1,diu2,dy1,diu3,dzn,vn,f,cov4,cov5,cov6,dfv1, &
-!      diu4,diu5,diu6,g,cov7,cov8,cov9,dfw1,diu7,diu8,diu9,dzs,h,nou1,u,nou5,v,nou9,w,nou2,nou3, &
-!      nou4,nou6,nou7,nou8)
+        call boundp2(jm,im,p,km)
+        call velfg(km,jm,im,dx1,cov1,cov2,cov3,dfu1,diu1,diu2,dy1,diu3,dzn,vn,f,cov4,cov5,cov6,dfv1, &
+      diu4,diu5,diu6,g,cov7,cov8,cov9,dfw1,diu7,diu8,diu9,dzs,h,nou1,u,nou5,v,nou9,w,nou2,nou3, &
+      nou4,nou6,nou7,nou8)
 #if IFBF == 1
 !        if(ifbf == 1) then
-!        call feedbf(km,jm,im,usum,u,bmask1,vsum,v,cmask1,wsum,w,dmask1,alpha,dt,beta,fx,fy,fz,f,g, &
-!      h)
-!        call feedbfm(km,jm,im,amask1,bmask1,cmask1,dmask1,zbm,z2,dzn)
+        call feedbf(km,jm,im,usum,u,bmask1,vsum,v,cmask1,wsum,w,dmask1,alpha,dt,beta,fx,fy,fz,f,g, &
+      h)
+        call feedbfm(km,jm,im,amask1,bmask1,cmask1,dmask1,zbm,z2,dzn)
 !        endif
 #endif
-!        call les(km,delx1,dx1,dy1,dzn,jm,im,diu1,diu2,diu3,diu4,diu5,diu6,diu7,diu8,diu9,sm,f,g,h)
+        call les(km,delx1,dx1,dy1,dzn,jm,im,diu1,diu2,diu3,diu4,diu5,diu6,diu7,diu8,diu9,sm,f,g,h)
 
 ! --adam
 ! WV iadam is not defined!
 #if IADAM == 1
 ! WV        if(iadam.eq.1) then
-!            n1=1
-!            n2=2
-!            data21dummy=""
-!          call adam(n1,n2,data21dummy,fold,im,jm,km,gold,hold,fghold,f,g,h)
+            n1=1
+            n2=2
+            data21dummy=""
+          call adam(n1,n2,data21dummy,fold,im,jm,km,gold,hold,fghold,f,g,h)
 ! WV        end if
 #endif
 !
diff -ruBbw MPI-LES/src/les.f95 LES-WRF-MPI/LES/src/GMCF/Models/les.f95
--- MPI-LES/src/les.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/les.f95	2015-06-22 16:04:30.000000000 +0100
@@ -4,7 +4,7 @@
 contains
 
       subroutine les(km,delx1,dx1,dy1,dzn,jm,im,diu1,diu2,diu3,diu4,diu5,diu6,diu7,diu8,diu9,sm,f,g, &
-      h,uspd,vspd,dxs,dys)
+      h)
       use common_sn ! create_new_include_statements() line 102
         real(kind=4), dimension(kp) , intent(Out) :: delx1
         real(kind=4), dimension(-1:ip+2,0:jp+2,0:kp+2) , intent(In) :: diu1
@@ -26,11 +26,6 @@
         integer, intent(In) :: jm
         integer, intent(In) :: km
         real(kind=4), dimension(-1:ip+1,-1:jp+1,0:kp+1) , intent(Out) :: sm
-!wall function
-        real(kind=4), dimension(0:ip+1,0:jp+1) , intent(in) :: uspd
-        real(kind=4), dimension(0:ip+1,0:jp+1) , intent(in) :: vspd
-        real(kind=4), dimension(0:ip) , intent(in) :: dxs
-        real(kind=4), dimension(0:jp) , intent(in) :: dys
 !
 !
       cs0 = .1
@@ -80,7 +75,7 @@
     print *, 'F95 HSUM after boundsm:',sum(h)
 #endif
 ! --calculation of viscosity terms in momentum eq.(x-comp.)
-      do k = 2,km
+      do k = 1,km
       do j = 1,jm
       do i = 1,im
 ! --eddyviscosity on face
@@ -106,41 +101,15 @@
       visuz2 = (evsz2)* ( diu3(i  ,j  ,k+1)+diu7(i+1,j  ,k  ) )
       visuz1 = (evsz1)* ( diu3(i  ,j  ,k  )+diu7(i+1,j  ,k-1) )
 !
-      vfu = (visux2-visux1)/dxs(i) +(visuy2-visuy1)/dy1(j) +(visuz2-visuz1)/dzn(k)
+      vfu = (visux2-visux1)/dx1(i) +(visuy2-visuy1)/dy1(j) +(visuz2-visuz1)/dzn(k)
 !
       f(i,j,k) = (f(i,j,k)+vfu)
       end do
       end do
       end do
 
-!wall function
-
-      do j=1,jm
-      do i=1,im
-      evsx2=sm(i+1,j,1)
-      evsx1=sm(i,j,1)
-      evsy2=(dy1(j+1)*((dx1(i+1)*sm(i,j,1)+dx1(i)*sm(i+1,j,1))/(dx1(i)+dx1(i+1)))&
-      +dy1(j)*((dx1(i+1)*sm(i,j+1,1)+dx1(i)*sm(i+1,j+1,1))/(dx1(i)+dx1(i+1))))/(dy1(j)+dy1(j+1))
-      evsy1=(dy1(j+1)*((dx1(i+1)*sm(i,j-1,1)+dx1(i)*sm(i+1,j-1,1))/(dx1(i)+dx1(i+1)))&
-      +dy1(j)*((dx1(i+1)*sm(i,j,1)+dx1(i)*sm(i+1,j,1))/(dx1(i)+dx1(i+1))))/(dy1(j)+dy1(j+1))
-      evsz2=(dzn(2)*((dx1(i+1)*sm(i,j,1)+dx1(i)*sm(i+1,j,1))/(dx1(i)+dx1(i+1)))&
-      +dzn(1)*((dx1(i+1)*sm(i,j,2)+dx1(i)*sm(i+1,j,2))/(dx1(i)+dx1(i+1))))/(dzn(1)+dzn(2))
-      visux2=(evsx2)*2.*diu1(i+1,j  ,1  )
-      visux1=(evsx1)*2.*diu1(i  ,j,  1  )
-      visuy2=(evsy2)* ( diu2(i  ,j+1,1  )+diu4(i+1,j  ,1 ) )
-      visuy1=(evsy1)* ( diu2(i  ,j  ,1  )+diu4(i+1,j-1,1 ) )
-      visuz2=(evsz2)* ( diu3(i  ,j  ,2  )+diu7(i+1,j  ,1 ) )
-      visuz1=(0.4*uspd(i,j)/alog(0.5*dzn(1)/0.1))**2*uspd(i,j)
-!
-      vfu= (visux2-visux1)/dxs(i)+(visuy2-visuy1)/dy1(j)+(visuz2-visuz1)/dzn(1)+(visuy2-visuy1)/dy1(j)+(visuz2-visuz1)/dzn(1)
-!
-      F(i,j,1)=(F(i,j,1)+vfu)
-      end do
-      end do
-
-
 ! --calculation of viscosity terms in momentum eq.(y-comp.)
-      do k = 2,km
+      do k = 1,km
       do j = 1,jm
       do i = 1,im
 ! --eddyviscosity on face
@@ -166,42 +135,13 @@
       visvz2 = (evsz2)* ( diu6(i  ,j  ,k+1)+diu8(i  ,j+1,k  ) )
       visvz1 = (evsz1)* ( diu6(i  ,j  ,k  )+diu8(i  ,j+1,k-1) )
 !
-      vfv = (visvx2-visvx1)/dx1(i) +(visvy2-visvy1)/dys(j) +(visvz2-visvz1)/dzn(k)
+      vfv = (visvx2-visvx1)/dx1(i) +(visvy2-visvy1)/dy1(j) +(visvz2-visvz1)/dzn(k)
 !
       g(i,j,k) = (g(i,j,k)+vfv)
       end do
       end do
       end do
 
-!wall function
-
-      do j=1,jm
-      do i=1,im
-!c--eddyviscosity on face
-      evsy2=sm(i,j+1,1)
-      evsy1=sm(i,j,1)
-      evsx2=(dy1(j+1)*((dx1(i+1)*sm(i,j,1)+dx1(i)*sm(i+1,j,1))/(dx1(i)+dx1(i+1)))&
-      +dy1(j)*((dx1(i+1)*sm(i,j+1,1)+dx1(i)*sm(i+1,j+1,1))/(dx1(i)+dx1(i+1))))/(dy1(j)+dy1(j+1))
-      evsx1=(dy1(j+1)*((dx1(i)*sm(i-1,j,1)+dx1(i-1)*sm(i,j,1))/(dx1(i-1)+dx1(i)))&
-      +dy1(j)*((dx1(i)*sm(i-1,j+1,1)+dx1(i-1)*sm(i,j+1,1))/(dx1(i-1)+dx1(i))))/(dy1(j)+dy1(j+1))
-      evsz2=(dzn(2)*((dx1(i+1)*sm(i,j,1)+dx1(i)*sm(i+1,j,1))/(dx1(i)+dx1(i+1)))&
-      +dzn(1)*((dx1(i+1)*sm(i,j,2)+dx1(i)*sm(i+1,j,2))/(dx1(i)+dx1(i+1))))/(dzn(1)+dzn(2))
-!
-      visvx2=(evsx2)* ( diu2(i  ,j+1,1  )+diu4(i+1,j  ,1  ) )
-      visvx1=(evsx1)* ( diu2(i-1,j+1,1  )+diu4(i  ,j  ,1  ) )
-      visvy2=(evsy2)*2.*diu5(i  ,j+1,1  )
-      visvy1=(evsy1)*2.*diu5(i  ,j  ,1  )
-      visvz2=(evsz2)* ( diu6(i  ,j  ,2  )+diu8(i  ,j+1,1  ) )
-      visvz1=(0.4*vspd(i,j)/alog(0.5*dzn(1)/0.1))**2*vspd(i,j)
-!
-      vfv=(visvx2-visvx1)/dx1(i)+(visvy2-visvy1)/dys(j)+(visvz2-visvz1)/dzn(1)
-!
-      G(i,j,1)=(G(i,j,1)+vfv)
-      end do
-      end do
-
-
-
 ! --calculation of viscosity terms in momentum eq.(z-comp.)
       do k = 1,km
       do j = 1,jm
diff -ruBbw MPI-LES/src/main.f95 LES-WRF-MPI/LES/src/GMCF/Models/main.f95
--- MPI-LES/src/main.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/main.f95	2015-06-22 16:04:30.000000000 +0100
@@ -1,4 +1,8 @@
+#ifdef GMCF
+    subroutine program_les(sys, tile, model_id)
+#else
 program main
+#endif
     use module_init
     use module_grid
     use module_set
@@ -16,7 +20,6 @@
 #else
     use module_velnw
     use module_bondv1
-    use module_bondv1_data24
     use module_velFG
 #if IFBF == 1
     use module_feedbf
@@ -26,6 +29,11 @@
     use module_adam
 #endif
     use common_sn
+#ifdef GMCF
+    integer(8) , intent(In) :: sys
+    integer(8) , intent(In) :: tile
+    integer , intent(In) :: model_id
+#endif
     real(kind=4) :: alpha
     integer :: ianime
     integer :: ical
@@ -40,9 +48,6 @@
     real(kind=4) :: beta
     character(len=70) :: data10
     character(len=70) :: data11
-    character(len=70) :: data12
-    character(len=70) :: data13
-    character(len=70) :: data14
     character(len=70) :: data20
     character(len=70) :: data21
     character(len=70) :: data22
@@ -60,6 +65,106 @@
 #ifdef TIMINGS
     integer :: clock_rate
 #endif
+
+#ifdef GMCF
+    real(kind=4), dimension(:,:,:), allocatable :: amask1
+    real(kind=4), dimension(:,:,:), allocatable :: avel
+    real(kind=4), dimension(:,:,:), allocatable :: avep
+    real(kind=4), dimension(:,:,:), allocatable :: avesm
+    real(kind=4), dimension(:,:,:), allocatable :: avesmsm
+    real(kind=4), dimension(:,:), allocatable :: avesu
+    real(kind=4), dimension(:,:), allocatable :: avesuu
+    real(kind=4), dimension(:,:), allocatable :: avesv
+    real(kind=4), dimension(:,:), allocatable :: avesvv
+    real(kind=4), dimension(:,:), allocatable :: avesw
+    real(kind=4), dimension(:,:), allocatable :: avesww
+    real(kind=4), dimension(:,:,:), allocatable :: aveu
+    real(kind=4), dimension(:,:,:), allocatable :: aveuu
+    real(kind=4), dimension(:,:,:), allocatable :: avev
+    real(kind=4), dimension(:,:,:), allocatable :: avevv
+    real(kind=4), dimension(:,:,:), allocatable :: avew
+    real(kind=4), dimension(:,:,:), allocatable :: aveww
+    real(kind=4), dimension(:,:,:), allocatable :: bmask1
+    real(kind=4), dimension(:,:,:), allocatable :: cmask1
+    real(kind=4), dimension(:,:,:), allocatable :: cn1
+    real(kind=4), dimension(:), allocatable :: cn2l
+    real(kind=4), dimension(:), allocatable :: cn2s
+    real(kind=4), dimension(:), allocatable :: cn3l
+    real(kind=4), dimension(:), allocatable :: cn3s
+    real(kind=4), dimension(:), allocatable :: cn4l
+    real(kind=4), dimension(:), allocatable :: cn4s
+    real(kind=4), dimension(:,:,:), allocatable :: cov1
+    real(kind=4), dimension(:,:,:), allocatable :: cov2
+    real(kind=4), dimension(:,:,:), allocatable :: cov3
+    real(kind=4), dimension(:,:,:), allocatable :: cov4
+    real(kind=4), dimension(:,:,:), allocatable :: cov5
+    real(kind=4), dimension(:,:,:), allocatable :: cov6
+    real(kind=4), dimension(:,:,:), allocatable :: cov7
+    real(kind=4), dimension(:,:,:), allocatable :: cov8
+    real(kind=4), dimension(:,:,:), allocatable :: cov9
+    real(kind=4), dimension(:), allocatable :: delx1
+    real(kind=4), dimension(:,:,:), allocatable :: dfu1
+    real(kind=4), dimension(:,:,:), allocatable :: dfv1
+    real(kind=4), dimension(:,:,:), allocatable :: dfw1
+    real(kind=4), dimension(:,:,:), allocatable :: diu1
+    real(kind=4), dimension(:,:,:), allocatable :: diu2
+    real(kind=4), dimension(:,:,:), allocatable :: diu3
+    real(kind=4), dimension(:,:,:), allocatable :: diu4
+    real(kind=4), dimension(:,:,:), allocatable :: diu5
+    real(kind=4), dimension(:,:,:), allocatable :: diu6
+    real(kind=4), dimension(:,:,:), allocatable :: diu7
+    real(kind=4), dimension(:,:,:), allocatable :: diu8
+    real(kind=4), dimension(:,:,:), allocatable :: diu9
+    real(kind=4), dimension(:,:,:), allocatable :: dmask1
+    real(kind=4), dimension(:), allocatable :: dx1
+    real(kind=4), dimension(:), allocatable :: dxl
+    real(kind=4), dimension(:), allocatable :: dxs
+    real(kind=4), dimension(:), allocatable :: dy1
+    real(kind=4), dimension(:), allocatable :: dyl
+    real(kind=4), dimension(:), allocatable :: dys
+    real(kind=4), dimension(:), allocatable :: dzn
+    real(kind=4), dimension(:), allocatable :: dzs
+    real(kind=4), dimension(:,:,:), allocatable :: f
+#if ICAL == 1
+    real(kind=4), dimension(:,:,:), allocatable :: fghold
+#endif
+    real(kind=4), dimension(:,:,:), allocatable :: fold
+    real(kind=4), dimension(:,:,:), allocatable :: fx
+    real(kind=4), dimension(:,:,:), allocatable :: fy
+    real(kind=4), dimension(:,:,:), allocatable :: fz
+    real(kind=4), dimension(:,:,:), allocatable :: g
+    real(kind=4), dimension(:,:,:), allocatable :: gold
+    real(kind=4), dimension(:,:,:), allocatable :: h
+    real(kind=4), dimension(:,:,:), allocatable :: hold
+#ifndef _OPENCL_LES_WV
+    real(kind=4), dimension(:,:,:), allocatable :: fghold
+#endif
+    real(kind=4), dimension(:,:,:), allocatable :: nou1
+    real(kind=4), dimension(:,:,:), allocatable :: nou2
+    real(kind=4), dimension(:,:,:), allocatable :: nou3
+    real(kind=4), dimension(:,:,:), allocatable :: nou4
+    real(kind=4), dimension(:,:,:), allocatable :: nou5
+    real(kind=4), dimension(:,:,:), allocatable :: nou6
+    real(kind=4), dimension(:,:,:), allocatable :: nou7
+    real(kind=4), dimension(:,:,:), allocatable :: nou8
+    real(kind=4), dimension(:,:,:), allocatable :: nou9
+    real(kind=4), dimension(:,:,:), allocatable :: p
+    real(kind=4), dimension(:,:,:), allocatable :: rhs
+    real(kind=4), dimension(:,:,:), allocatable :: sm
+    real(kind=4), dimension(:,:,:), allocatable :: u
+    real(kind=4), dimension(:,:,:), allocatable :: usum
+    real(kind=4), dimension(:,:,:), allocatable :: uwfx
+    real(kind=4), dimension(:,:), allocatable :: uwfxs
+    real(kind=4), dimension(:,:,:), allocatable :: v
+    real(kind=4), dimension(:,:,:), allocatable :: vsum
+    real(kind=4), dimension(:,:,:), allocatable :: w
+    real(kind=4), dimension(:,:,:), allocatable :: wsum
+    real(kind=4), dimension(:), allocatable :: z2
+    real(kind=4), dimension(:,:), allocatable :: zbm
+#ifdef TIMINGS
+    integer(kind=4), dimension(:), allocatable :: timestamp
+#endif
+#else
     real(kind=4), dimension(0:ip+1,0:jp+1,0:kp+1)  :: amask1
     real(kind=4), dimension(ip,jp,kp)  :: avel
     real(kind=4), dimension(ip,jp,kp)  :: avep
@@ -71,11 +176,11 @@
     real(kind=4), dimension(ip,kp)  :: avesvv
     real(kind=4), dimension(ip,kp)  :: avesw
     real(kind=4), dimension(ip,kp)  :: avesww
-    real(kind=4), dimension(ip,jp,0:kp)  :: aveu
+    real(kind=4), dimension(ip,jp,kp)  :: aveu
     real(kind=4), dimension(ip,jp,kp)  :: aveuu
-    real(kind=4), dimension(ip,jp,0:kp)  :: avev
+    real(kind=4), dimension(ip,jp,kp)  :: avev
     real(kind=4), dimension(ip,jp,kp)  :: avevv
-    real(kind=4), dimension(ip+1,jp,0:kp+2)  :: avew
+    real(kind=4), dimension(ip,jp,kp)  :: avew
     real(kind=4), dimension(ip,jp,kp)  :: aveww
     real(kind=4), dimension(-1:ip+1,0:jp+1,0:kp+1)  :: bmask1
     real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1)  :: cmask1
@@ -152,47 +257,210 @@
     real(kind=4), dimension(0:ip,0:jp,0:kp)  :: vsum
     real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1)  :: w
     real(kind=4), dimension(0:ip,0:jp,0:kp)  :: wsum
-    real(kind=4), dimension(0:kp+2)  :: z2
+    real(kind=4), dimension(kp+2)  :: z2
     real(kind=4), dimension(-1:ipmax+1,-1:jpmax+1)  :: zbm
-!wall function
-    real(kind=4), dimension(0:ip+1,0:jp+1)  :: uspd
-    real(kind=4), dimension(0:ip+1,0:jp+1)  :: vspd
-!idata24
-    integer :: idata24
-!jdata24
-    integer :: jdata24
-
-!nspec
-    integer :: nspec
-
-
-    real(kind=4), dimension(1,1,36001,kp) :: ut_x1_2
-    real(kind=4), dimension(1,1,36001,kp) :: ut_x2_2
-    real(kind=4), dimension(1,1,36001,kp) :: vt_x1_2
-    real(kind=4), dimension(1,1,36001,kp) :: vt_x2_2
-    real(kind=4), dimension(1,1,36001,kp) :: wt_x1_2
-    real(kind=4), dimension(1,1,36001,kp) :: wt_x2_2
-
-
-    real(kind=4), dimension(1,kp,36001)  :: u_spany2
-    real(kind=4), dimension(1,kp,36001)  :: v_spany2
-    real(kind=4), dimension(1,kp,36001)  :: w_spany2
-    real(kind=4), dimension(1,kp,36001)  :: u_spany3
-    real(kind=4), dimension(1,kp,36001)  :: v_spany3
-    real(kind=4), dimension(1,kp,36001)  :: w_spany3
-
-    real(kind=4), dimension(19,kp,36001)  :: u_x1_19_spany2
-    real(kind=4), dimension(19,kp,36001)  :: v_x1_19_spany2
-    real(kind=4), dimension(19,kp,36001)  :: w_x1_19_spany2
-    real(kind=4), dimension(19,kp,36001)  :: u_x1_19_spany3
-    real(kind=4), dimension(19,kp,36001)  :: v_x1_19_spany3
-    real(kind=4), dimension(19,kp,36001)  :: w_x1_19_spany3
-
-
-
 #ifdef TIMINGS
     integer (kind=4), dimension(0:9) :: timestamp
 #endif
+#endif
+
+#ifdef GMCF
+    allocate(amask1((ip+1)-(0)+1,(jp+1)-(0)+1,(kp+1)-(0)+1))
+    call zero3DReal4Array(amask1)
+    allocate(avel((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(avel)
+    allocate(avep((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(avep)
+    allocate(avesm((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(avesm)
+    allocate(avesmsm((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(avesmsm)
+    allocate(avesu((ip)-(1)+1,(kp)-(1)+1))
+    call zero2DReal4Array(avesu)
+    allocate(avesuu((ip)-(1)+1,(kp)-(1)+1))
+    call zero2DReal4Array(avesuu)
+    allocate(avesv((ip)-(1)+1,(kp)-(1)+1))
+    call zero2DReal4Array(avesv)
+    allocate(avesvv((ip)-(1)+1,(kp)-(1)+1))
+    call zero2DReal4Array(avesvv)
+    allocate(avesw((ip)-(1)+1,(kp)-(1)+1))
+    call zero2DReal4Array(avesw)
+    allocate(avesww((ip)-(1)+1,(kp)-(1)+1))
+    call zero2DReal4Array(avesww)
+    allocate(aveu((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(aveu)
+    allocate(aveuu((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(aveuu)
+    allocate(avev((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(avev)
+    allocate(avevv((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(avevv)
+    allocate(avew((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(avew)
+    allocate(aveww((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(aveww)
+    allocate(bmask1((ip+1)-(-1)+1,(jp+1)-(0)+1,(kp+1)-(0)+1))
+    call zero3DReal4Array(bmask1)
+    allocate(cmask1((ip+1)-(0)+1,(jp+1)-(-1)+1,(kp+1)-(0)+1))
+    call zero3DReal4Array(cmask1)
+    allocate(cn1((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(cn1)
+    allocate(cn2l((ip)-(1)+1))
+    call zero1DReal4Array(cn2l)
+    allocate(cn2s((ip)-(1)+1))
+    call zero1DReal4Array(cn2s)
+    allocate(cn3l((jp)-(1)+1))
+    call zero1DReal4Array(cn3l)
+    allocate(cn3s((jp)-(1)+1))
+    call zero1DReal4Array(cn3s)
+    allocate(cn4l((kp)-(1)+1))
+    call zero1DReal4Array(cn4l)
+    allocate(cn4s((kp)-(1)+1))
+    call zero1DReal4Array(cn4s)
+    allocate(cov1((ip+2)-(-1)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(cov1)
+    allocate(cov2((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(cov2)
+    allocate(cov3((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(cov3)
+    allocate(cov4((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(cov4)
+    allocate(cov5((ip+2)-(-1)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(cov5)
+    allocate(cov6((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(cov6)
+    allocate(cov7((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(cov7)
+    allocate(cov8((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(cov8)
+    allocate(cov9((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(cov9)
+    allocate(delx1((kp)-(1)+1))
+    call zero1DReal4Array(delx1)
+    allocate(dfu1((ip)-(0)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(dfu1)
+    allocate(dfv1((ip)-(1)+1,(jp)-(0)+1,(kp)-(1)+1))
+    call zero3DReal4Array(dfv1)
+    allocate(dfw1((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(dfw1)
+    allocate(diu1((ip+2)-(-1)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(diu1)
+    allocate(diu2((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(diu2)
+    allocate(diu3((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(diu3)
+    allocate(diu4((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(diu4)
+    allocate(diu5((ip+2)-(-1)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(diu5)
+    allocate(diu6((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(diu6)
+    allocate(diu7((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(diu7)
+    allocate(diu8((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(diu8)
+    allocate(diu9((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(diu9)
+    allocate(dmask1((ip+1)-(0)+1,(jp+1)-(0)+1,(kp+1)-(0)+1))
+    call zero3DReal4Array(dmask1)
+    allocate(dx1((ip+1)-(-1)+1))
+    call zero1DReal4Array(dx1)
+    allocate(dxl((ip)-(0)+1))
+    call zero1DReal4Array(dxl)
+    allocate(dxs((ip)-(0)+1))
+    call zero1DReal4Array(dxs)
+    allocate(dy1((jp+1)-(0)+1))
+    call zero1DReal4Array(dy1)
+    allocate(dyl((jp)-(0)+1))
+    call zero1DReal4Array(dyl)
+    allocate(dys((jp)-(0)+1))
+    call zero1DReal4Array(dys)
+    allocate(dzn((kp+2)-(-1)+1))
+    call zero1DReal4Array(dzn)
+    allocate(dzs((kp+2)-(-1)+1))
+    call zero1DReal4Array(dzs)
+    allocate(f((ip)-(0)+1,(jp)-(0)+1,(kp)-(0)+1))
+    call zero3DReal4Array(f)
+#if ICAL==1
+    allocate(fghold((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(fghold)
+#endif
+    allocate(fold((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(fold)
+    allocate(fx((ip)-(0)+1,(jp)-(0)+1,(kp)-(0)+1))
+    call zero3DReal4Array(fx)
+    allocate(fy((ip)-(0)+1,(jp)-(0)+1,(kp)-(0)+1))
+    call zero3DReal4Array(fy)
+    allocate(fz((ip)-(0)+1,(jp)-(0)+1,(kp)-(0)+1))
+    call zero3DReal4Array(fz)
+    allocate(g((ip)-(0)+1,(jp)-(0)+1,(kp)-(0)+1))
+    call zero3DReal4Array(g)
+    allocate(gold((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(gold)
+    allocate(h((ip)-(0)+1,(jp)-(0)+1,(kp)-(0)+1))
+    call zero3DReal4Array(h)
+    allocate(hold((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(hold)
+#ifndef _OPENCL_LES_WV
+    allocate(fghold((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(fghold)
+#endif
+    allocate(nou1((ip+2)-(-1)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(nou1)
+    allocate(nou2((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(nou2)
+    allocate(nou3((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(nou3)
+    allocate(nou4((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(nou4)
+    allocate(nou5((ip+2)-(-1)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(nou5)
+    allocate(nou6((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(nou6)
+    allocate(nou7((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(nou7)
+    allocate(nou8((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(nou8)
+    allocate(nou9((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+2)-(0)+1))
+    call zero3DReal4Array(nou9)
+    allocate(p((ip+2)-(0)+1,(jp+2)-(0)+1,(kp+1)-(0)+1))
+    call zero3DReal4Array(p)
+    allocate(rhs((ip+1)-(0)+1,(jp+1)-(0)+1,(kp+1)-(0)+1))
+    call zero3DReal4Array(rhs)
+    allocate(sm((ip+1)-(-1)+1,(jp+1)-(-1)+1,(kp+1)-(0)+1))
+    call zero3DReal4Array(sm)
+    allocate(u((ip+1)-(0)+1,(jp+1)-(-1)+1,(kp+1)-(0)+1))
+    call zero3DReal4Array(u)
+    allocate(usum((ip)-(0)+1,(jp)-(0)+1,(kp)-(0)+1))
+    call zero3DReal4Array(usum)
+    allocate(uwfx((ip)-(1)+1,(jp)-(1)+1,(kp)-(1)+1))
+    call zero3DReal4Array(uwfx)
+    allocate(uwfxs((ip)-(1)+1,(kp)-(1)+1))
+    call zero2DReal4Array(uwfxs)
+    allocate(v((ip+1)-(0)+1,(jp+1)-(-1)+1,(kp+1)-(0)+1))
+    call zero3DReal4Array(v)
+    allocate(vsum((ip)-(0)+1,(jp)-(0)+1,(kp)-(0)+1))
+    call zero3DReal4Array(vsum)
+    allocate(w((ip+1)-(0)+1,(jp+1)-(-1)+1,(kp+1)-(-1)+1))
+    call zero3DReal4Array(w)
+    allocate(wsum((ip)-(0)+1,(jp)-(0)+1,(kp)-(0)+1))
+    call zero3DReal4Array(wsum)
+    allocate(z2((kp+2)-(1)+1))
+    call zero1DReal4Array(z2)
+    allocate(zbm((ipmax+1)-(-1)+1,(jpmax+1)-(-1)+1))
+    call zero2DReal4Array(zbm)
+#ifdef TIMINGS
+    allocate(timestamp((9)-(0)+1))
+    !call zero1DReal4Array(timestamp)
+#endif
+#endif
+
+! -----------------------------------------------------------------------
+!
+#ifdef GMCF
+        print*, 'Hello from model ', model_id
+        call initialise_gmcf(sys, tile, model_id, procPerRow, procPerCol)
+#endif
 #ifdef MPI
     call initialise_mpi()
     if (mpi_size .ne. procPerRow * procPerCol) then
@@ -206,32 +475,34 @@
 #ifdef USE_NETCDF_OUTPUT
     call init_netcdf_file()
 #endif
-    call set(data10,data11,data20,data21,data22,data23,data24,data25,data26,&
-             data27,data30,data31,im,jm,km,ifbf,ianime,ical,n0,n1,nmax,dt,ro,&
-             vn,alpha,beta,data12,data13,data14,idata24,nspec,jdata24)
+      call set(data10,data11,data20,data21,data22,data23,data24,data25,data26,data27,data30,data31, &
+      im,jm,km,ifbf,ianime,ical,n0,n1,nmax,dt,ro,vn,alpha,beta)
     call grid(dx1,dxl,dy1,dyl,z2,dzn,dzs,dxs,dys)
     call timdata()
-    call init(km,jm,im,u,v,w,p,cn2s,dxs,cn2l,cn3s,dys,cn3l,dzs,cn4s,cn4l,cn1,&
-              amask1,bmask1,cmask1,dmask1,zbm,z2,dzn)
-!    n0=200
+      call init(km,jm,im,u,v,w,p,cn2s,dxs,cn2l,cn3s,dys,cn3l,dzs,cn4s,cn4l,cn1,amask1,bmask1, &
+      cmask1,dmask1,zbm,z2,dzn)
+      n=n0
     call ifdata( &
-!#if ICAL == 1
-                data30,data31, fold,gold,hold,fghold, time, &
-!#endif
-                n,u,im,jm,km,v,w,p,usum,vsum,wsum,delx1,dx1,dy1,dzn,diu1,diu2,&
-                diu3,diu4,diu5,diu6,diu7,diu8,diu9,sm,f,g,h,z2,dt,dxs,cov1, &
-                cov2,cov3,dfu1,vn,cov4,cov5,cov6,dfv1,cov7,cov8,cov9,dfw1,dzs,&
-                nou1,nou5,nou9,nou2,nou3,nou4,nou6,nou7,nou8,bmask1,cmask1,&
-                dmask1,alpha,beta,fx,fy,fz,amask1,zbm,ical)
-!     n=n0
+#if ICAL == 1
+      data30,data31, fold,gold,hold,fghold, time &
+#endif
+      n,u,im,jm,km,v,w,p,usum,vsum,wsum, &
+      delx1,dx1,dy1,dzn,diu1,diu2,diu3,diu4,diu5,diu6,diu7,diu8,diu9,sm,f,g,h,z2,dt,dxs,cov1, &
+      cov2,cov3,dfu1,vn,cov4,cov5,cov6,dfv1,cov7,cov8,cov9,dfw1,dzs,nou1,nou5,nou9,nou2,nou3,nou4, &
+      nou6,nou7,nou8,bmask1,cmask1,dmask1,alpha,beta,fx,fy,fz,amask1,zbm)
 
 #ifdef _OPENCL_LES_WV
-    call initialise_LES_kernel(p,u,v,w,usum,vsum,wsum,f,g,h,fold,gold,hold, &
-                               diu1, diu2, diu3, diu4, diu5, diu6, diu7, diu8, &
-                               diu9, amask1, bmask1, cmask1, dmask1,cn1, cn2l, &
-                               cn2s, cn3l, cn3s, cn4l, cn4s,rhs, sm, dxs, dys, &
-                               dzs, dx1, dy1, dzn, z2,dt, im, jm, km)
+      call initialise_LES_kernel( &
+            p,u,v,w,usum,vsum,wsum,f,g,h,fold,gold,hold, &
+            diu1, diu2, diu3, diu4, diu5, diu6, diu7, diu8, diu9, &
+            amask1, bmask1, cmask1, dmask1, &
+            cn1, cn2l, cn2s, cn3l, cn3s, cn4l, cn4s, &
+            rhs, sm, dxs, dys, dzs, dx1, dy1, dzn, z2, &
+            dt, im, jm, km &
+              )
 #endif
+
+
 #ifdef VERBOSE
 #ifdef _OPENCL_LES_WV
     print *,'MAIN: calling OpenCL run_LES_kernel for ', nmax-n0+1, ' time steps, domain = ',im,'x',jm,'x',km
@@ -241,19 +512,23 @@
 #endif
 ! --main loop
 #ifdef TIMINGS
-!    nmax=201
+    nmax=201
     call system_clock(timestamp(8), clock_rate)
 #endif
     do n = n0,nmax
         time = float(n-1)*dt
 ! -------calculate turbulent flow--------c
 #ifdef _OPENCL_LES_WV
-        call run_LES_kernel(n, nmax)
+      call run_LES_kernel ( &
+            n, nmax &
+            )
 #else
 ! -------calculate turbulent flow--------c
 #ifdef TIMINGS
         print *, 'run_LES_reference: time step = ',n
 #endif
+        ! ========================================================================================================================================================
+        ! ========================================================================================================================================================
 #ifdef TIMINGS
         call system_clock(timestamp(0), clock_rate)
 #endif
@@ -261,30 +536,24 @@
 #ifdef TIMINGS
         call system_clock(timestamp(1), clock_rate)
 #endif
-     if(jdata24.eq.0) then
         call bondv1(jm,u,z2,dzn,v,w,km,n,im,dt,dxs)
-     else
-        call bondv1_data24(jm,u,z2,dzn,v,w,km,n,im,dt,dxs)
-     end if
 #ifdef TIMINGS
         call system_clock(timestamp(2), clock_rate)
 #endif
-        call velfg(km,jm,im,dx1,cov1,cov2,cov3,dfu1,diu1,diu2,dy1,diu3,dzn, &
-                   vn,f,cov4,cov5,cov6,dfv1,diu4,diu5,diu6,g,cov7,cov8,cov9, &
-                   dfw1,diu7,diu8,diu9,dzs,h,nou1,u,nou5,v,nou9,w,nou2,nou3, &
-                   nou4,nou6,nou7,nou8,uspd,vspd)
+        call velfg(km,jm,im,dx1,cov1,cov2,cov3,dfu1,diu1,diu2,dy1,diu3,dzn,vn,f,cov4,cov5,cov6,dfv1, &
+      diu4,diu5,diu6,g,cov7,cov8,cov9,dfw1,diu7,diu8,diu9,dzs,h,nou1,u,nou5,v,nou9,w,nou2,nou3, &
+      nou4,nou6,nou7,nou8)
 #ifdef TIMINGS
         call system_clock(timestamp(3), clock_rate)
 #endif
 #if IFBF == 1
-        call feedbf(km,jm,im,usum,u,bmask1,vsum,v,cmask1,wsum,w,dmask1,alpha, &
-                    dt,beta,fx,fy,fz,f,g,h)
+        call feedbf(km,jm,im,usum,u,bmask1,vsum,v,cmask1,wsum,w,dmask1,alpha,dt,beta,fx,fy,fz,f,g, &
+      h)
 #endif
 #ifdef TIMINGS
         call system_clock(timestamp(4), clock_rate)
 #endif
-        call les(km,delx1,dx1,dy1,dzn,jm,im,diu1,diu2,diu3,diu4,diu5,diu6, &
-                 diu7,diu8,diu9,sm,f,g,h,uspd,vspd,dxs,dys)
+        call les(km,delx1,dx1,dy1,dzn,jm,im,diu1,diu2,diu3,diu4,diu5,diu6,diu7,diu8,diu9,sm,f,g,h)
 #ifdef TIMINGS
         call system_clock(timestamp(5), clock_rate)
 #endif
@@ -292,15 +561,15 @@
 #ifdef TIMINGS
         call system_clock(timestamp(6), clock_rate)
 #endif
-        call press(km,jm,im,rhs,u,dx1,v,dy1,w,dzn,f,g,h,dt,cn1,cn2l,p,cn2s, &
-                   cn3l,cn3s,cn4l,cn4s,n, nmax,data20,usum,vsum,wsum)
+        call press(km,jm,im,rhs,u,dx1,v,dy1,w,dzn,f,g,h,dt,cn1,cn2l,p,cn2s,cn3l,cn3s,cn4l,cn4s,n, &
+      nmax,data20,usum,vsum,wsum)
 #ifdef TIMINGS
         call system_clock(timestamp(7), clock_rate)
         do i=1, 7
-            print '("Time for state ",i2," = ",f6.3," s")',i, &
-                  (timestamp(i)-timestamp(i-1))/ real(clock_rate)
+            print '("Time for state ",i2," = ",f6.3," s")',i,(timestamp(i)-timestamp(i-1))/ real(clock_rate)
         end do
 #endif
+
 #endif
 ! -------data output ---------------------c
 ! WV: This is clearly broken, as the dimensions for u/v/w are 150x150x90
@@ -307,36 +576,37 @@
 #ifdef TIMSERIS_FIXED
         call timseris(n,dt,u,v,w)
 #endif
+        call aveflow(n,n1,km,jm,im,aveu,avev,avew,avep,avel,aveuu,avevv,aveww,avesm,avesmsm,uwfx, &
+      avesu,avesv,avesw,avesuu,avesvv,avesww,u,v,w,p,sm,nmax,uwfxs,data10,time,data11)
 #if IANIME == 1
-        call anime(n,n0,nmax,km,jm,im,dxl,dx1,dyl,dy1,z2,data22,data23,u,w,v,&
-                   amask1,zbm)
-
-        if (idata24.eq.1) then
-        call anime_bond(n,n0,nmax,km,jm,im,dxl,dx1,dyl,dy1,z2,data22,data23,u,w,v,amask1,zbm)
-        end if
+        call anime(n,n0,nmax,km,jm,im,dxl,dx1,dyl,dy1,z2,data22,data23,u,w,v,amask1)
 #endif
-        call ifdata_out(n,n0,n1,nmax,time,km,jm,im,u,w,v,p,usum,vsum,wsum,f,g,h,fold,gold,hold)
-
-        call aveflow(n,n1,km,jm,im,aveu,avev,avew,avep,avel,aveuu,avevv,aveww, &
-                     avesm,avesmsm,uwfx,avesu,avesv,avesw,avesuu,avesvv, &
-                     avesww,u,v,w,p,sm,nmax,uwfxs,data10,time,data11,data13,data14,amask1)
-
-        call timestep_out_all_k(n,n0,n1,nmax,km,jm,im,z2,data22,data23,u,w,v,amask1&
-,ut_x1_2,vt_x1_2,wt_x1_2,ut_x2_2,vt_x2_2,wt_x2_2,nspec&
-,u_spany2,v_spany2,w_spany2,u_spany3,v_spany3,w_spany3&
-,u_x1_19_spany2,v_x1_19_spany2,w_x1_19_spany2,u_x1_19_spany3,v_x1_19_spany3,w_x1_19_spany3)
-
-
+!
         end do
 #ifdef USE_NETCDF_OUTPUT
     call close_netcdf_file()
 #endif
 #ifdef TIMINGS
     call system_clock(timestamp(9))
-    print *,"Total time:" ,(timestamp(9)-timestamp(8))/real(clock_rate), &
-          "s for ",nmax-n0,"iterations"
+    print *,"Total time:" ,(timestamp(9)-timestamp(8))/real(clock_rate),"s for ",nmax-n0,"iterations"
+#ifdef GMCF
+    call flush(6)
+    call sleep(5)
+    call flush(6)
 #endif
+#endif
+
+#ifdef GMCF_API
+      call finalise_gmcf(model_id)
+#else
 #ifdef MPI
     call finalise_mpi()
 #endif
+#endif
+#ifdef GMCF
+end subroutine program_les
+#else
 end program
+#endif
+
+
diff -ruBbw MPI-LES/src/module_LES_write_netcdf.f95 LES-WRF-MPI/LES/src/GMCF/Models/module_LES_write_netcdf.f95
--- MPI-LES/src/module_LES_write_netcdf.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/module_LES_write_netcdf.f95	2015-06-22 16:04:30.000000000 +0100
@@ -19,7 +19,7 @@
   integer, parameter :: NDIMS = 4
   integer, parameter :: NTIMESTEPS=20 ! FIXME: should be taken from global macro
   ! For p only: 0:ip+2,0:jp+2,0:kp+1
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     integer, parameter :: NLVLS_P_UV = kp+2
     integer, parameter :: NLATS_P_UVW = (jp*procPerCol)+3
     integer, parameter :: NLONS_P = (ip*procPerRow)+3
@@ -27,7 +27,7 @@
   integer, parameter :: NLVLS_P_UV = kp+2, NLATS_P_UVW = jp+3, NLONS_P = ip+3
 #endif
   ! For u,v
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     integer, parameter :: NLONS_UVW = (ip*procPerRow)+2
 #else
   integer, parameter :: NLONS_UVW = ip+2
@@ -35,7 +35,7 @@
   ! For w
   integer, parameter :: NLVLS_W = kp+3 ! GR: fine as is for MPI since depth (kp) isn't split up
   ! For usum/vsum/wsum
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
   integer, parameter :: NLVLS_UVWSUM = kp+1
   integer, parameter :: NLATS_UVWSUM = (jp*procPerCol)+1
   integer, parameter :: NLONS_UVWSUM = (ip*procPerRow)+1
@@ -120,7 +120,7 @@
 subroutine init_netcdf_file()
       ! Loop indices
       integer :: lat, lon,t
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isMaster()) then
 #endif
      ! Create the file.
@@ -335,7 +335,7 @@
 
 
 !      print *, 'ncid init: ',ncid,'pres_varid: ',pres_varid
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     end if
 #endif
 end subroutine init_netcdf_file
@@ -349,7 +349,7 @@
     real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(In) :: vsum
     real(kind=4), dimension(0:ip,0:jp,0:kp) , intent(In) :: wsum
     integer, intent(In) :: n
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     real(kind=4), dimension(0:(ip*procPerCol)+2,0:(jp*procPerRow)+2,0:kp+1) :: pTot
     real(kind=4), dimension(0:(ip*procPerCol)+1,-1:(jp*procPerRow)+1,0:kp+1) :: uTot
     real(kind=4), dimension(0:(ip*procPerCol)+1,-1:(jp*procPerRow)+1,0:kp+1) :: vTot
@@ -365,7 +365,7 @@
     call collect3DReal4Array(vsum, vsumTot, 1, 0, 1, 0, ip, jp, kp, procPerRow)
     call collect3DReal4Array(wsum, wsumTot, 1, 0, 1, 0, ip, jp, kp, procPerRow)
 #endif
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isMaster()) then
         ! Write varTot rather than var to the netCDF files
         ! The start and count arrays will tell the netCDF library where to
@@ -378,12 +378,8 @@
         start(4) = n
         print *, 'ncid: ',ncid,'pres_varid: ',pres_varid
 
-        write(*,*) 'test1'
-
         call check( nf90_put_var(ncid, pres_varid, pTot,  start, count) )
 
-        write(*,*) 'test2'
-
         call check( nf90_put_var(ncid_p, pres_varid, pTot,  start, count_p) )
 
         print *, 'ncid_u: ',ncid_u,'vel_x_varid_u: ',vel_x_varid_u
@@ -406,12 +402,8 @@
     start(4) = n
     print *, 'ncid: ',ncid,'pres_varid: ',pres_varid
 
-!    write(*,*) 'test1'
-
     call check( nf90_put_var(ncid, pres_varid, p,  start, count) )
 
-!    write(*,*) 'test2'
-
     call check( nf90_put_var(ncid_p, pres_varid, p,  start, count_p) )
 
     print *, 'ncid_u: ',ncid_u,'vel_x_varid_u: ',vel_x_varid_u
@@ -426,7 +418,7 @@
 end subroutine write_to_netcdf_file
 
 subroutine close_netcdf_file()
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isMaster()) then
 #endif
   ! Close the file. This causes netCDF to flush all buffers and make
@@ -455,7 +447,7 @@
 #ifdef VERBOSE
         print *,"*** SUCCESS writing file ", FILE_NAME_UVWSUM
 #endif
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     end if
 #endif
 end subroutine close_netcdf_file
diff -ruBbw MPI-LES/src/params_common_sn.f95 LES-WRF-MPI/LES/src/GMCF/Models/params_common_sn.f95
--- MPI-LES/src/params_common_sn.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/params_common_sn.f95	2015-06-22 16:04:30.000000000 +0100
@@ -1,5 +1,5 @@
 module params_common_sn
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     use communication_helper
     integer, parameter :: procPerRow = PROC_PER_ROW, procPerCol = PROC_PER_COL, dimensions = 2
     integer :: dimensionSizes(dimensions)
@@ -9,16 +9,30 @@
     data dimensionSizes /procPerCol,procPerRow/, periodicDimensions /.false.,.false./, &
     reorder /.false./
 #endif
-    integer, parameter :: ipmax = 3000, jpmax = 300
+#ifdef EXPANDING_AREA
+    integer, parameter :: ipmax = 150*PROC_PER_COL
+    integer, parameter :: jpmax = 150*PROC_PER_ROW
+#else
+    integer, parameter :: ipmax = 150, jpmax = 150
+    !integer, parameter :: ipmax = 254, jpmax = 253
+#endif
 #ifndef TEST_SMALL_DOMAIN
-#ifdef MPI
-    integer, parameter :: ip = 3000/PROC_PER_COL ! rows per process
-    integer, parameter :: jp = 300/PROC_PER_ROW ! columns per process
-    integer, parameter :: kp=105
+#if defined(MPI) || defined(GMCF)
+#ifdef EXPANDING_AREA
+    integer, parameter :: ip = 150
+    integer, parameter :: jp = 150
+    integer, parameter :: kp=90
+#else
+    integer, parameter :: ip = 150/PROC_PER_COL ! rows per process
+    integer, parameter :: jp = 150/PROC_PER_ROW ! columns per process
+    integer, parameter :: kp=90
+#endif
 #else
-    integer, parameter :: ip = 300, jp = 300, kp = 105
+    integer, parameter :: ip = 150, jp = 150, kp = 90
 #endif
+    !integer, parameter :: ip = 254, jp = 253, kp = 94
 #else
-    integer, parameter :: ip = 25, jp = 25, kp = 105
+    integer, parameter :: ip = 25, jp = 25, kp = 90
 #endif
 end module params_common_sn
+
diff -ruBbw MPI-LES/src/press.f95 LES-WRF-MPI/LES/src/GMCF/Models/press.f95
--- MPI-LES/src/press.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/press.f95	2015-06-22 16:04:30.000000000 +0100
@@ -70,7 +70,7 @@
             end do
         end do
     end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     call getGlobalSumOf(rhsav)
     call getGlobalSumOf(area)
 #endif
@@ -113,7 +113,7 @@
         end if
 #endif
 #endif
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
         call getGlobalSumOf(sor)
 #endif
         if (sor < pjuge) then
@@ -132,7 +132,7 @@
         end do
     end do
 !
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     call getGlobalSumOf(pav)
     call getGlobalSumOf(pco)
 #endif
@@ -200,10 +200,10 @@
                 'vel at centre: ', &
                 u(ip/2,jp/2,kp/2),v(ip/2,jp/2,kp/2),w(ip/2,jp/2,kp/2)
 #ifdef USE_NETCDF_OUTPUT
-!        call write_to_netcdf_file(p,u,v,w,usum,vsum,wsum,nn)
+        call write_to_netcdf_file(p,u,v,w,usum,vsum,wsum,nn)
 #endif
 #ifndef NO_IO
-#ifndef MPI
+#if !defined(MPI) && !defined(GMCF)
         open(unit=20,file=data20,form='unformatted',status='unknown')
         write(20) (((u(i,j,k),i=1,im),j=1,jm),k=1,km)
         write(20) (((v(i,j,k),i=1,im),j=1,jm),k=1,km)
diff -ruBbw MPI-LES/src/set.f95 LES-WRF-MPI/LES/src/GMCF/Models/set.f95
--- MPI-LES/src/set.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/set.f95	2015-06-22 16:04:30.000000000 +0100
@@ -3,15 +3,12 @@
 contains
 
       subroutine set(data10,data11,data20,data21,data22,data23,data24,data25,data26,data27,data30, &
-      data31,im,jm,km,ifbf,ianime,ical,n0,n1,nmax,dt,ro,vn,alpha,beta,data12,data13,data14,idata24,nspec,jdata24)
+      data31,im,jm,km,ifbf,ianime,ical,n0,n1,nmax,dt,ro,vn,alpha,beta)
       use common_sn ! create_new_include_statements() line 102
         real(kind=4), intent(Out) :: alpha
         real(kind=4), intent(Out) :: beta
         character(len=70), intent(InOut) :: data10
         character(len=70), intent(InOut) :: data11
-        character(len=70), intent(InOut) :: data12
-        character(len=70), intent(InOut) :: data13
-        character(len=70), intent(InOut) :: data14
         character(len=70), intent(InOut) :: data20
         character(len=70), intent(InOut) :: data21
         character(len=70), intent(InOut) :: data22
@@ -34,18 +31,10 @@
         integer, intent(Out) :: nmax
         real(kind=4), intent(Out) :: ro
         real(kind=4), intent(Out) :: vn
-!idata24
-        integer, intent(Out) :: idata24
-!jdata24
-        integer, intent(Out) :: jdata24
-
 !
 !
       data10 = './data/data10'
       data11 = './data/data11'
-      data12 = './data/data12'
-      data13 = './data/data13'
-      data14 = './data/data14'      
       data20 = './data/data20'
       data21 = './data/data21'
       data22 = './data/data22'
@@ -80,13 +69,11 @@
 !           = 1; continuous computation
       ical = 0
       n0 = 1
-      n1 = 1
+      n1 = 10001
 ! --setnmax
-      nmax = 10
-! --for sepctrum, nspec = nmax-n1+1
-      nspec = 10
+      nmax = 20000
 ! --time step
-      dt = 0.05
+      dt = 0.2
 ! --physical property set
       ro = 1.1763
       vn = 15.83*10.**(-6.)
@@ -99,10 +86,6 @@
       write(6,*) 'IBM parameter, dt=' ,((-beta-(beta*beta-2.*alpha)**(0.5))/alpha),dt
       stop
       endif
-!--make_data24
-      idata24 = 0
-!--use_data24
-      jdata24 = 0
 ! =======================================
       return
       end subroutine set

diff -ruBbw MPI-LES/src/vel2.f95 LES-WRF-MPI/LES/src/GMCF/Models/vel2.f95
--- MPI-LES/src/vel2.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/vel2.f95	2015-06-22 16:04:30.000000000 +0100
@@ -2,7 +3,7 @@
 contains
 
       subroutine vel2(km,jm,im,nou1,u,diu1,dx1,nou5,v,diu5,dy1,nou9,w,diu9,dzn,cov1,cov5,cov9,nou2, &
-      diu2,cov2,nou3,diu3,dzs,cov3,nou4,diu4,cov4,nou6,diu6,cov6,nou7,diu7,cov7,nou8,diu8,cov8,uspd,vspd)
+      diu2,cov2,nou3,diu3,dzs,cov3,nou4,diu4,cov4,nou6,diu6,cov6,nou7,diu7,cov7,nou8,diu8,cov8)
       use common_sn ! create_new_include_statements() line 102
         real(kind=4), dimension(-1:ip+2,0:jp+2,0:kp+2) , intent(Out) :: cov1
         real(kind=4), dimension(0:ip+2,0:jp+2,0:kp+2) , intent(Out) :: cov2
@@ -42,34 +43,7 @@
         real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: v
         real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) , intent(In) :: w
 !
-!wall function
-        real(kind=4), dimension(0:ip+1,0:jp+1) , intent(out) :: uspd
-        real(kind=4), dimension(0:ip+1,0:jp+1) , intent(out) :: vspd
-!
       integer, parameter  :: u0 = 0
-
-        
-
-
-      do j=1,jm
-        do i=1,im
-         uspd(i,j)=(u(i,j,1)**2+((0.5*(v(i,j-1,1)+v(i,j,1))*dx1(i+1)&
-     +0.5*(v(i+1,j-1,1)+v(i+1,j,1))*dx1(i))/(dx1(i)+dx1(i+1)))**2)**0.5
-        end do
-        end do
-        do j=1,jm
-        do i=1,im
-         vspd(i,j)=(v(i,j,1)**2+((0.5*(u(i-1,j,1)+u(i,j,1))*dy1(j+1)&
-     +0.5*(u(i-1,j+1,1)+u(i,j+1,1))*dy1(j))/(dy1(j)+dy1(j+1)))**2)**0.5
-        end do
-        end do
-
-       if (isMaster()) then
-        write(6,*) 'CHK_uspd=',uspd(im/2,jm/2),vspd(im/2,jm/2)
-       end if
-
-
-
 !
       do k = 1,km
       do j = 1,jm
@@ -116,7 +90,7 @@
     print*, 'GR: SUM(cov2) = ', sum(cov2)
 #endif
 !
-      do k = 2,km+1
+      do k = 1,km+1
       do j = 1,jm
       do i = 1,im
         nou3(i,j,k) = (dx1(i+1)*w(i,j,k-1)+dx1(i)*w(i+1,j,k-1)) /(dx1(i)+dx1(i+1))
@@ -126,21 +100,6 @@
       end do
       end do
 !
-!      do j=1,jm
-!      do i=1,im
-!       diu3(i,j,1)=0.45/0.4/(0.5*dzn(1))*uspd(i,j)
-!      end do
-!      end do
-
-      do j=1,jm
-      do i=1,im
-       nou3(i,j,1) = 0.5*(dx1(i+1)*w(i,j,1)+dx1(i)*w(i+1,j,1))/(dx1(i)+dx1(i+1))
-       diu3(i,j,1)=uspd(i,j)*0.4/alog(0.5*dzn(1)/0.1)/(0.5*dzn(1))/0.4*u(i,j,1)/uspd(i,j)
-       cov3(i,j,1) = nou3(i,j,1)*diu3(i,j,1)
-      end do
-      end do
-
-
       do k = 1,km
       do j = 1,jm
       do i = 1,im
@@ -151,7 +110,7 @@
       end do
       end do
 !
-      do k = 2,km+1
+      do k = 1,km+1
       do j = 1,jm
       do i = 1,im
         nou6(i,j,k) = (dy1(j+1)*w(i,j,k-1)+dy1(j)*w(i,j+1,k-1)) /(dy1(j)+dy1(j+1))
@@ -161,21 +120,6 @@
       end do
       end do
 !
-!      do j=1,jm
-!      do i=1,im
-!       diu6(i,j,1)=0.45/0.4/(0.5*dzn(1))*vspd(i,j)
-!      end do
-!      end do
-
-      do j=1,jm
-      do i=1,im
-       nou6(i,j,1) = 0.5*(dy1(j+1)*w(i,j,1)+dy1(j)*w(i,j+1,1))/(dy1(j)+dy1(j+1))
-       diu6(i,j,1)=vspd(i,j)*0.4/alog(0.5*dzn(1)/0.1)/(0.5*dzn(1))/0.4*v(i,j,1)/vspd(i,j)
-       cov6(i,j,1) = nou6(i,j,1)*diu6(i,j,1)
-      end do
-      end do
-
-
       do k = 1,km-1
       do j = 1,jm
       do i = 1,im
@@ -196,7 +140,7 @@
       end do
       end do
 ! ====================================
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isBottomRow(procPerRow)) then
 #endif
       do k = 1,km
@@ -206,10 +150,10 @@
         cov1(im+1,j,k) = cov1(im,j,k)
       end do
       end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     end if
 #endif
-#if !defined(MPI) || (PROC_PER_ROW==1)
+#if !defined(MPI) && !defined(GMCF) || (PROC_PER_ROW==1)
       do k = 1,km
       do i = 1,im
         nou2(i,0,k) = nou2(i,jm,k)
@@ -228,7 +172,7 @@
     call sideflowLeftRight(diu2, procPerRow, 2, jp+2, 1, 2, 1, 2)
     call sideflowLeftRight(cov2, procPerRow, 2, jp+2, 1, 2, 1, 2)
 #endif
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isBottomRow(procPerRow)) then
 #endif
       do k = 1,km
@@ -238,10 +182,10 @@
         cov4(im+1,j,k) = cov4(im,j,k)
       end do
       end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     end if
 #endif
-#if !defined(MPI) || (PROC_PER_ROW==1)
+#if !defined(MPI) && !defined(GMCF) || (PROC_PER_ROW==1)
       do k = 1,km
       do i = 1,im
         nou5(i,0,k) = nou5(i,jm,k)
@@ -260,7 +204,7 @@
     call sideflowLeftRight(diu5, procPerRow, 3, jp+3, 2, 2, 1, 2)
     call sideflowLeftRight(cov5, procPerRow, 3, jp+3, 2, 2, 1, 2)
 #endif
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isBottomRow(procPerRow)) then
 #endif
       do k = 1,km-1
@@ -270,10 +214,10 @@
         cov7(im+1,j,k) = cov7(im,j,k)
       end do
       end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     end if
 #endif
-#if !defined(MPI) || (PROC_PER_ROW==1)
+#if !defined(MPI) && !defined(GMCF) || (PROC_PER_ROW==1)
       do k = 1,km-1
       do i = 1,im
         nou8(i,0,k) = nou8(i,jm,k)
@@ -293,7 +237,7 @@
     call sideflowLeftRight(cov8, procPerRow, 2, jp+2, 1, 2, 1, 3)
 #endif
 ! --les
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     if (isBottomRow(procPerRow)) then
 #endif
       do k = 1,km+1
@@ -302,10 +246,10 @@
         diu3(im+1,j,k) = diu3(im,j,k)
       end do
       end do
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     end if
 #endif
-#if !defined(MPI) || (PROC_PER_ROW==1)
+#if !defined(MPI) && !defined(GMCF) || (PROC_PER_ROW==1)
       do k = 1,km+1
       do i = 1,im+1
         diu4(i,0,k) = diu4(i,jm,k)
@@ -317,7 +261,7 @@
     call sideflowRightLeft(diu6, procPerRow, jp+1, 1, 1, 1, 1, 1)
 #endif
 
-#ifdef MPI
+#if defined(MPI) || defined(GMCF)
     call exchangeRealHalos(nou1, procPerRow, neighbours, 1, 2, 2, 2)
     call exchangeRealHalos(diu1, procPerRow, neighbours, 1, 2, 2, 2)
     call exchangeRealHalos(cov1, procPerRow, neighbours, 1, 2, 2, 2)
@@ -347,16 +291,6 @@
     call exchangeRealHalos(cov9, procPerRow, neighbours, 1, 2, 1, 2)
 #endif
 
-!uspd,vspd
-        do j=1,jm
-        do i=1,im
-         uspd(i,j)=u(i,j,1)/uspd(i,j)
-         vspd(i,j)=v(i,j,1)/vspd(i,j)
-        end do
-        end do
-
-
-
 #ifdef WV_DEBUG
     print *, 'F95 DIU SUMS:',sum(diu1),sum(diu2),sum(diu3),sum(diu4),sum(diu5),sum(diu6),sum(diu7),sum(diu8),sum(diu9)
 #endif
diff -ruBbw MPI-LES/src/velFG.f95 LES-WRF-MPI/LES/src/GMCF/Models/velFG.f95
--- MPI-LES/src/velFG.f95	2015-12-16 11:13:17.000000000 +0000
+++ LES-WRF-MPI/LES/src/GMCF/Models/velFG.f95	2015-06-22 16:04:30.000000000 +0100
@@ -5,7 +5,7 @@
 
       subroutine velfg(km,jm,im,dx1,cov1,cov2,cov3,dfu1,diu1,diu2,dy1,diu3,dzn,vn,f,cov4,cov5,cov6, &
       dfv1,diu4,diu5,diu6,g,cov7,cov8,cov9,dfw1,diu7,diu8,diu9,dzs,h,nou1,u,nou5,v,nou9,w,nou2, &
-      nou3,nou4,nou6,nou7,nou8,uspd,vspd)
+      nou3,nou4,nou6,nou7,nou8)
       use common_sn ! create_new_include_statements() line 102
         real(kind=4), dimension(-1:ip+2,0:jp+2,0:kp+2) , intent(Out) :: cov1
         real(kind=4), dimension(0:ip+2,0:jp+2,0:kp+2) , intent(Out) :: cov2
@@ -51,15 +51,10 @@
         real(kind=4), dimension(0:ip+1,-1:jp+1,0:kp+1) , intent(In) :: v
         real(kind=4), intent(In) :: vn
         real(kind=4), dimension(0:ip+1,-1:jp+1,-1:kp+1) , intent(In) :: w
-
-!wall function
-        real(kind=4), dimension(0:ip+1,0:jp+1) , intent(out) :: uspd
-        real(kind=4), dimension(0:ip+1,0:jp+1) , intent(out) :: vspd
- 
 !
 !
       call vel2(km,jm,im,nou1,u,diu1,dx1,nou5,v,diu5,dy1,nou9,w,diu9,dzn,cov1,cov5,cov9,nou2,diu2, &
-           cov2,nou3,diu3,dzs,cov3,nou4,diu4,cov4,nou6,diu6,cov6,nou7,diu7,cov7,nou8,diu8,cov8,uspd,vspd)
+           cov2,nou3,diu3,dzs,cov3,nou4,diu4,cov4,nou6,diu6,cov6,nou7,diu7,cov7,nou8,diu8,cov8)
 ! --u velocity
       do k = 1,km
       do j = 1,jm
