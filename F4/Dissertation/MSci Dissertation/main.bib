@misc{Vanderbauwhede2012,
author = {Vanderbauwhede, Wim},
booktitle = {GitHub repository},
title = {{OpenCLIntegration}},
url = {https://github.com/wimvanderbauwhede/OpenCLIntegration},
year = {2012}
}
@article{Nabi2015,
abstract = {We present the TyTra-IR, a new intermediate language intended as a compilation target for high-level language compilers and a front-end for HDL code generators. We develop the requirements of this new language based on the design-space of FPGAs that it should be able to express and the estimation-space in which each configuration from the design-space should be mappable in an automated design flow. We use a simple kernel to illustrate multiple configurations using the semantics of TyTra-IR. The key novelty of this work is the cost model for resource-costs and throughput for different configurations of interest for a particular kernel. Through the realistic example of a Successive Over-Relaxation kernel implemented both in TyTra-IR and HDL, we demonstrate both the expressiveness of the IR and the accuracy of our cost model.},
archivePrefix = {arXiv},
arxivId = {1504.04579},
author = {Nabi, Syed Waqar and Vanderbauwhede, Wim},
eprint = {1504.04579},
file = {:home/james/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nabi, Vanderbauwhede - 2015 - An Intermediate Language and Estimator for Automated Design Space Exploration on FPGAs.pdf:pdf},
journal = {International symposium on Highly Efficient Accelerators and Reconfigurable Technologies},
mendeley-groups = {PRRCS},
month = {apr},
title = {{An Intermediate Language and Estimator for Automated Design Space Exploration on FPGAs}},
url = {http://arxiv.org/abs/1504.04579},
year = {2015}
}
@inproceedings{Nabi2019,
address = {Rio de Janeiro},
author = {Nabi, Syed Waqar and Vanderbauwhede, Wim},
booktitle = {33rd IEEE International Parallel and Distributed Processing Symposium, Reconfigurable Architectures Workshop (RAW 2019)},
mendeley-groups = {Level 5 Proj},
month = {may},
title = {{Smart-Cache: Optimising Memory Accesses for Arbitrary Boundaries and Stencils on FPGAs}},
url = {http://eprints.gla.ac.uk/182352/},
year = {2019}
}
@inproceedings{Prasanna2006,
abstract = {Recently, several state of the art high end platforms have incorporated FPGAs for application acceleration. This talk explores optimizations for accelerating linear algebra computations on such systems. We develop algorithmic optimizations for such systems and demonstrate the suitability of FPGAs for floating point intensive computations. We discuss the design of a BLAS library for such systems and develop a highly optimized reduction circuit for such architectures. Using the reduction circuit, we demonstrate superior performance for sparse matrix computations. The performance of FPGAs is also compared against those of state-of-the-art embedded processors, general purpose processors, and DSPs for floating point intensive applications.},
author = {Prasanna, V.K.},
booktitle = {Sixth Mexican International Conference on Computer Science (ENC'05)},
doi = {10.1109/ENC.2005.23},
file = {:home/james/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sundararajan - 2010 - High Performance Computing Using FPGAs.pdf:pdf},
isbn = {0-7695-2454-0},
mendeley-groups = {Level 5 Proj},
pages = {xvi--xvi},
publisher = {IEEE},
title = {{High Performance Computing using Reconfigurable Hardware}},
url = {www.xilinx.com http://ieeexplore.ieee.org/document/1592193/},
year = {2006}
}
@inproceedings{Dimond2011,
abstract = {Field Programmable Gate Arrays (FPGAs) are conventionally considered as 'glue-logic'. However, modern FPGAs are extremely competitive compared to state-of-the-art CPUs for commercial HPC workloads, such as those found in Oil and Gas and Finance. For example, an FPGA accelerated system can be 31-37 times faster than an equivalently sized conventional machine, and consume 1/39 of the power. The key to achieving the best performance in FPGA accelerators, while maintaining correctness, is optimization of arithmetic units and data types to suit the range/precision at each point in the computation. The flexibility of the FPGA to implement non-standard arithmetic, combined with a data-flow programming model that instantiates a separate unit for each arithmetic operator in the code provides a wide design space. As such, FPGA computing offers significant opportunity for arithmetic research into 'large scale' HPC applications, where there is an opportunity to move away from standard IEEE formats, either to improve precision compared to the CPU version or to increase speed.},
author = {Dimond, Rob and Racani{\`{e}}re, S{\'{e}}bastien and Pell, Oliver},
booktitle = {Proceedings - Symposium on Computer Arithmetic},
doi = {10.1109/ARITH.2011.34},
isbn = {9780769543185},
keywords = {Acceleration,FPGA},
mendeley-groups = {Level 5 Proj},
month = {jul},
pages = {191--192},
publisher = {IEEE},
title = {{Accelerating large-scale HPC applications using FPGAs}},
url = {http://ieeexplore.ieee.org/document/5992126/},
year = {2011}
}
@book{Vanderbauwhede2014,
abstract = {Computer based simulation software having a basis in numerical methods play a major role in research in the area of natural and physical sciences. These tools allow scientists to attempt problems that are too large to solve using analytical methods. But even these tools can fail to give solutions due to computational or storage limits. However, as the performance of computer hardware gets better and better, the computational limits can be also addressed. One such area of work is that of magnetic field modeling, which plays a crucial role in various fields of research, especially those related to nanotechnology. Due to remarkable advancements made in this field, magnetic modelling has developed new found interest, and rightly so. The most significant impact of this interest is perhaps felt in increasing areal densities for data storage devices which is projected to reach almost atomic scales. Computational limits, and subsequently their solutions based on hardware delivering high performance, are therefore a key component in research in this field. The scale of length and time plays a crucial role in observing magnetic phenomena, and as these scales are reduced, new behaviours can be observed. Coarser scales may be beneficial if modeling larger systems, but when working with sub-$\mu$m scales, a finer scale has to be selected. Doing so will project the proper magnetic behaviour of the materials, but will come with its share of problems. These will be addressed in this thesis. Simulations are usually configured before being started. The configuration is performed using scripting based methods which need to reflect the proper environmental conditions. For example, simulating multiple bodies with varying orientations, non-uniform geometries, bodies consisting of multiple layers with each layer having different properties, etc. will all need different configuration methods. A performance based solution would need to be optimized for each type of simulation. This may require re-structuring of different components of a simulator. This thesis is devoted to addressing such problems listed above with a focus on performance based solutions. The scope of the work has been limited to magnetostatic field calculations in particular because they consume the most time in the overall simulation. The scope has also been confined to regular structured rectangular meshes which are popular in major micromagnetic simulation software. Using regular meshes, magnetostatic field calculations can exploit a performance boost by using Fast Fourier Transforms. Therefore, fast FFT libraries using open standards will also be addressed in this thesis. In particular, this thesis will be based on the development process of open standards for magnetic field modeling. The major contribution in this regard includes an OpenCL specific FFT library for GPU's and a GPU based magnetostatic field solver which is used as an extension to the OOMMF simulator. The thesis covers some novel numerical techniques that have been developed to target particular simulation configurations to obtain maximum performance},
address = {New York, NY},
author = {Vanderbauwhede, Wim and Benkrid, Khaled},
booktitle = {High-Performance Computing Using FPGAs},
doi = {10.1007/978-1-4614-1791-0},
editor = {Vanderbauwhede, Wim and Benkrid, Khaled},
isbn = {9781461417910},
mendeley-groups = {Level 5 Proj},
pages = {1--803},
publisher = {Springer New York},
title = {{High-performance computing using FPGAs}},
url = {http://link.springer.com/10.1007/978-1-4614-1791-0},
volume = {9781461417},
year = {2014}
}
@article{Momeni2016,
author = {Momeni, Amir and Tabkhi, Hamed and Ukidave, Yash and Schirner, Gunar and Kaeli, David},
doi = {10.1145/2927964.2927974},
file = {:home/james/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Momeni et al. - 2016 - Exploring the Efficiency of the OpenCL Pipe Semantic on an FPGA(3).pdf:pdf},
issn = {01635964},
journal = {ACM SIGARCH Computer Architecture News},
mendeley-groups = {Level 5 Proj},
month = {apr},
number = {4},
pages = {52--57},
publisher = {ACM},
title = {{Exploring the Efficiency of the OpenCL Pipe Semantic on an FPGA}},
url = {http://dl.acm.org/citation.cfm?doid=2927964.2927974},
volume = {43},
year = {2016}
}
@inproceedings{Fifield2016,
address = {New York, New York, USA},
author = {Fifield, Jeff and Keryell, Ronan and Ratigner, Herv{\'{e}} and Styles, Henry and Wu, Jim},
booktitle = {Proceedings of the 4th International Workshop on OpenCL - IWOCL '16},
doi = {10.1145/2909437.2909447},
file = {:home/james/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fifield et al. - 2016 - Optimizing OpenCL applications on Xilinx FPGA.pdf:pdf},
isbn = {9781450343381},
keywords = {FPGA,OpenCL,Optimizations},
mendeley-groups = {Level 5 Proj},
pages = {1--2},
publisher = {ACM Press},
title = {{Optimizing OpenCL applications on Xilinx FPGA}},
url = {http://dl.acm.org/citation.cfm?doid=2909437.2909447},
year = {2016}
}
@inproceedings{Fu2011,
address = {New York, New York, USA},
author = {Fu, Haohuan and Clapp, Robert G.},
booktitle = {Proceedings of the 19th ACM/SIGDA international symposium on Field programmable gate arrays - FPGA '11},
doi = {10.1145/1950413.1950429},
file = {::},
isbn = {9781450305549},
keywords = {field programmable gate arrays (fpga),reverse time migration (rtm)},
mendeley-groups = {Level 5 Proj},
pages = {65},
publisher = {ACM Press},
title = {{Eliminating the memory bottleneck}},
url = {http://portal.acm.org/citation.cfm?doid=1950413.1950429},
year = {2011}
}
@article{Waidyasooriya2017,
abstract = {Stencil computation is widely used in scientific computations and many accelerators based on multicore CPUs and GPUs have been proposed. Stencil computation has a small operational intensity so that a large external memory bandwidth is usually required for high performance. FPGAs have the potential to solve this problem by utilizing large internal memory efficiently. However, a very large design, testing and debugging time is required to implement an FPGA architecture successfully. To solve this problem, we propose an FPGA-platform using C-like programming language called open computing language (OpenCL). We also propose an optimization methodology to find the optimal architecture for a given application using the proposed FPFA-platform. According to the experimental results, we achieved 119 - 237 Gflop/s of processing power and higher processing speed compared to conventional GPU and multicore CPU implementations.},
author = {Waidyasooriya, Hasitha Muthumala and Takei, Yasuhiro and Tatsumi, Shunsuke and Hariyama, Masanori},
doi = {10.1109/TPDS.2016.2614981},
issn = {10459219},
journal = {IEEE Transactions on Parallel and Distributed Systems},
keywords = {FDTD,OpenCL for FPGA,high performance computing,stencil computation},
mendeley-groups = {Level 5 Proj},
month = {may},
number = {5},
pages = {1390--1402},
title = {{OpenCL-based FPGA-platform for stencil computation and its optimization methodology}},
url = {http://ieeexplore.ieee.org/document/7582502/},
volume = {28},
year = {2017}
}
@inproceedings{Holewinski2012,
abstract = {Stencil computations arise in many scientific computing do-mains, and often represent time-critical portions of applica-tions. There is significant interest in offloading these com-putations to high-performance devices such as GPU acceler-ators, but these architectures offer challenges for developers and compilers alike. Stencil computations in particular re-quire careful attention to off-chip memory access and the balancing of work among compute units in GPU devices. In this paper, we present a code generation scheme for stencil computations on GPU accelerators, which optimizes the code by trading an increase in the computational work-load for a decrease in the required global memory band-width. We develop compiler algorithms for automatic gen-eration of efficient, time-tiled stencil code for GPU accel-erators from a high-level description of the stencil opera-tion. We show that the code generation scheme can achieve high performance on a range of GPU architectures, includ-ing both nVidia and AMD devices.},
address = {New York, New York, USA},
author = {Holewinski, Justin and Pouchet, Louis-No{\"{e}}l and Sadayappan, P.},
booktitle = {Proceedings of the 26th ACM international conference on Supercomputing - ICS '12},
doi = {10.1145/2304576.2304619},
file = {::},
isbn = {9781450313162},
keywords = {gpu,opencl,overlapped tiling,stencil},
mendeley-groups = {Level 5 Proj},
pages = {311},
publisher = {ACM Press},
title = {{High-performance code generation for stencil computations on GPU architectures}},
url = {http://dl.acm.org/citation.cfm?doid=2304576.2304619},
year = {2012}
}
@book{Datta2008,
abstract = {Title from IEEE summary page (IEEE Xplore, viewed on Oct. 5, 2009). "Date: 15-21 Nov. 2008."},
author = {Datta, Kaushik and Murphy, Mark and Volkov, Vasily and Williams, Samuel and Carter, Jonathan and Oliker, Leonid and Patterson, David and Shalf, John and Yelick, Katherine},
booktitle = {Proceedings of the 2008 ACM/IEEE conference on Supercomputing},
file = {::},
isbn = {9781424428359},
mendeley-groups = {Level 5 Proj},
pages = {4},
publisher = {IEEE},
title = {{High Performance Computing, Networking, Storage and Analysis, 2008. SC 2008. International Conference for : date, 15-21 Nov. 2008.}},
url = {https://dl.acm.org/citation.cfm?id=1413375},
year = {2008}
}
@inproceedings{Micikevicius2009,
address = {New York, New York, USA},
author = {Micikevicius, Paulius and Paulius},
booktitle = {Proceedings of 2nd Workshop on General Purpose Processing on Graphics Processing Units - GPGPU-2},
doi = {10.1145/1513895.1513905},
file = {::},
isbn = {9781605585178},
keywords = {CUDA,GPU,finite difference,parallel algorithms},
mendeley-groups = {Level 5 Proj},
pages = {79--84},
publisher = {ACM Press},
title = {{3D finite difference computation on GPUs using CUDA}},
url = {http://portal.acm.org/citation.cfm?doid=1513895.1513905},
year = {2009}
}
@article{Sano2014,
abstract = {Stencil computation is one of the important kernels in scientific computations. However, sustained performance is limited owing to restriction on memory bandwidth, especially on multi-core microprocessors and graphics processing units (GPUs) because of their small operational intensity. In this paper, we present a custom computing machine (CCM), called a scalable streaming array (SSA), for high-performance stencil computations with multiple field-programmable gate arrays (FPGAs). We design SSA based on a domainspecific programmable concept, where CCMs are programmable with the minimum functionality required for an algorithm domain. We employ a deep pipelining approach over successive iterations to achieve linear scalability for multiple devices with a constant memory bandwidth. Prototype implementation using nine FPGAs demonstrates good agreement with a performance model, and achieves 260 and 236 GFlop/s for 2D and 3D Jacobi computation, which are 87.4{\%} and 83.9{\%} of the peak, respectively, with a memory bandwidth of only 2.0 GB/s. We also evaluate the performance of SSA for state-of-the-art FPGAs.},
author = {Sano, Kentaro and Hatsuda, Yoshiaki and Yamamoto, Satoru},
doi = {10.1109/TPDS.2013.51},
file = {::},
isbn = {1045-9219},
issn = {10459219},
journal = {IEEE Transactions on Parallel and Distributed Systems},
keywords = {FPGA,Scalable streaming-array,custom computing machine,high-performance computation,stencil computation},
mendeley-groups = {Level 5 Proj},
month = {mar},
number = {3},
pages = {695--705},
title = {{Multi-FPGA accelerator for scalable stencil computation with constant memory bandwidth}},
url = {http://ieeexplore.ieee.org/document/6470606/},
volume = {25},
year = {2014}
}
@article{Davidson2016,
author = {Davidson, Gavin},
file = {::},
journal = {University of Glasgow, MSci Dissertation},
mendeley-groups = {Level 5 Proj},
number = {April},
title = {{Domain-Specific Automatic Parallelisation of Scientific Code}},
year = {2016}
}
@article{Watanabe2003,
abstract = {A newly developed, linear baroclinic model (LBM) and its application to the tropical ENSO teleconnection is described. The model, based on primitive equations linearized about the observed, zonally varying basic state in northern winter, involves linear schemes for the cumulus convection, and surface sensible and latent heat fluxes, referred to as the moist LBM. This enables us to solve a steady-state response of the coupled dynamical–convective system to a given SST anomaly, which is fairly different from the conventional dry LBM. Linear representation of the convection is acceptable for a realistic range of SST anomalies, reproducing well the Rossby wave train computed in the conventional LBM forced by a tropical heating. The moist LBM is used to examine the formation mechanisms of an anomalous low-level anticyclone near the Philippines that links El Ni{\~{n}}o with the Asian winter monsoon. Given that the conventional LBM simulates the Philippine Sea anticyclone as a Rossby response to the anomalous diabatic cooling associated with the weakened convection over the Maritime Continent, causes of the convective suppression are examined. Moist LBM experiments forced by observed El Ni{\~{n}}o SST anomalies indicate that a basinwide warming of the Indian Ocean, in addition to SST anomalies in the Pacific, has a considerable impact in weakening the convection over the Maritime Continent through a modulation of the Walker circulation. Observational analysis supports this idea and further suggests that the lagged Indian Ocean response to El Ni{\~{n}}o contributes to determining when the Philippine Sea anticyclone is developed. The moist LBM identified a positive wind–evaporation feedback at work between the Philippine anticyclone and the western Pacific SST anomaly, which might also contribute.},
author = {Watanabe, Masahiro and Jin, Fei Fei},
doi = {10.1175/1520-0442(2003)16<1121:AMLBMC>2.0.CO;2},
file = {::},
isbn = {1520-0442},
issn = {08948755},
journal = {Journal of Climate},
mendeley-groups = {Level 5 Proj},
month = {apr},
number = {8},
pages = {1121--1139},
title = {{A moist linear baroclinic model: Coupled dynamical-convective response to El Ni{\~{n}}o}},
url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0442{\%}282003{\%}2916{\%}3C1121{\%}3AAMLBMC{\%}3E2.0.CO{\%}3B2},
volume = {16},
year = {2003}
}
@article{Burgers2002,
abstract = {The question is addressed whether using unbalanced updates in ocean-data assimilation schemes for seasonal forecasting systems can result in a relatively poor simulation of zonal currents. An assimilation scheme, where temperature observations are used for updating only the density field, is compared to a scheme where updates of density field and zonal velocities are related by geostrophic balance. This is done for an equatorial linear shallow-water model. It is found that equatorial zonal velocities can be detoriated if velocity is not updated in the assimilation procedure. Adding balanced updates to the zonal velocity is shown to be a simple remedy for the shallow-water model. Next, optimal interpolation (OI) schemes with balanced updates of the zonal velocity are implemented in two ocean general circulation models. First tests indicate a beneficial impact on equatorial upper-ocean zonal currents.},
author = {Burgers, G and Malmaseda, M A and Vossepoel, F C and van Oldenborgh, G J and van Leeuwen, P J},
doi = {10.1175/1520-0485-32.9.2509},
file = {::},
isbn = {1520-0485},
issn = {0022-3670},
journal = {J. Phys. Oceanogr.},
mendeley-groups = {Level 5 Proj},
month = {sep},
number = {9},
pages = {2509--2519},
title = {{Balanced Ocean-Data Assimilation near the Equator}},
url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0485(2002)032{\%}3C2509:BODANT{\%}3E2.0.CO;2},
volume = {32},
year = {2002}
}
@article{Brioude2013,
abstract = {The Lagrangian particle dispersion model FLEX-PART was originally (in its first release in 1998) designed for calculating the long-range and mesoscale dispersion of air pollutants from point sources, such as after an accident in a nuclear power plant. In the meantime FLEXPART has evolved into a comprehensive tool for atmospheric transport modeling and analysis. Its application fields were extended from air pollution studies to other topics where atmospheric transport plays a role (e.g., exchange between the strato-sphere and troposphere, or the global water cycle). It has evolved into a true community model that is now being used by at least 35 groups from 14 different countries and is seeing both operational and research applications. The last citable manuscript for FLEXPART is: (Stohl et al., 2005) 1 Updates since FLEXPART version 8.0 In this version 8.2 of FLEXPART the representation of phys-ical processes was improved as well as a number of technical changes and bugfixes implemented. In addition, the program is now released under a GNU GPL license. For the first time, detailed installation instructions are provided to help users getting started with running FLEXPART. A short section on the new Python routines pflexpart for reading FLEXPART output data has been included as well.},
author = {Brioude, J. and Arnold, D. and Stohl, A. and Cassiani, M. and Morton, D. and Seibert, P. and Angevine, W. and Evan, S. and Dingwell, A. and Fast, J. D. and Easter, R. C. and Pisso, I. and Burkhart, J. and Wotawa, G.},
doi = {10.5194/gmd-6-1889-2013},
file = {:home/james/Downloads/Brioude{\_}2013-gmd.pdf:pdf},
isbn = {1991-9603},
issn = {1991959X},
journal = {Geoscientific Model Development},
mendeley-groups = {Level 5 Proj,PRRCS},
month = {nov},
number = {6},
pages = {1889--1904},
title = {{The Lagrangian particle dispersion model FLEXPART-WRF version 3.1}},
url = {https://www.geosci-model-dev.net/6/1889/2013/},
volume = {6},
year = {2013}
}
@misc{Fortran2000,
author = {{Fortran 2000}},
mendeley-groups = {Level 5 Proj},
title = {{NIST Fortran 77 test suite}},
url = {http://www.fortran-2000.com/ArnaudRecipes/fcvs21{\_}f95.html},
urldate = {2018-11-06}
}
@misc{NISTITL,
author = {{NIST ITL}},
mendeley-groups = {Level 5 Proj},
title = {{Fortran Available Test Suites}},
url = {https://www.itl.nist.gov/div897/ctg/fortran{\_}form.htm},
urldate = {2018-11-06}
}
@misc{Xilinx,
author = {Xilinx},
mendeley-groups = {Level 5 Proj},
title = {{Xilinx - Adaptable. Intelligent.}},
url = {https://www.xilinx.com/},
urldate = {2018-11-04}
}
@misc{Library,
author = {Bradley, Thomas},
mendeley-groups = {Level 5 Proj},
title = {{High-Productivity Development: Thrust Parallel Algorithms Library}},
url = {https://thrust.github.io/},
urldate = {2018-11-04}
}
@misc{OpenMP,
author = {OpenMP},
mendeley-groups = {Level 5 Proj},
title = {{Home - OpenMP}},
url = {https://www.openmp.org/},
urldate = {2018-11-04}
}
@inproceedings{Lbhner2001,
abstract = {This paper summarizes the major improvements and developments that have taken place during the last year for FEFLO, a general-purpose CFD code based on adaptive, unstructured grids. All aspects of a comprehensive simulation pipeline: pre-processing, gridding, field solvers and post-processing saw important advances, and are treated. The advent of machines with millions of cores focused a lot of the developments on distributed memory aspects of field solvers and multiphysics modules. Parallel grid generation, particles and flow, parallel interpolation, parallel domain splitting and repartitioning for multiphysics were all considered. Furthermore, timings on Xeon and AMD chips led to the realization that memory transfers play a considerable role as compared to floating point operations, something previous chip generations did not exhibit. This led to a thorough analysis of numerical algorithms with subsequent re-writing. This in-depth analysis determined that at present achievable speeds are limited by the communication between processors (MPI). Even as the number of cores/domains can increase to several hundred thousand, due to communication overheads the wall clock time it takes to update a flowfield is bounded. We expect that as more users get access to hundreds of thousands of cores and the domain size per core starts shrinking, they will also encounter this 'minimum timestep barrier'. {\textcopyright} 2013 by Author.},
address = {Reston, Virigina},
author = {Lbhner, Rainald and Yang, Chi and Cebral, Juan and Soto, Orlando and Camelli, Fernando and Baum, Joseph D and Luo, Hong and Sharov, Dmitri},
booktitle = {39th AIAA Aerospace Sciences Meeting and Exhibit},
doi = {10.2514/6.2001-592},
file = {::},
isbn = {9781624101816},
mendeley-groups = {Level 5 Proj},
month = {jan},
number = {January},
publisher = {American Institute of Aeronautics and Astronautics},
title = {{Advances in FEFLO}},
url = {http://arc.aiaa.org/doi/10.2514/6.2001-592},
year = {2001}
}
@misc{NVIDIACorporation,
author = {{NVIDIA Corporation}},
mendeley-groups = {Level 5 Proj,PRRCS},
title = {{CUDA FORTRAN | NVIDIA Developer}},
url = {https://developer.nvidia.com/cuda-fortran},
urldate = {2018-11-04}
}
@article{Norman2015,
abstract = {The porting of a key kernel in the tracer advection routines of the Community Atmosphere Model - Spectral Element (CAM-SE) to use Graphics Processing Units (GPUs) using OpenACC is considered in comparison to an existing CUDA FORTRAN port. The development of the OpenACC kernel for GPUs was substantially simpler than that of the CUDA port. Also, OpenACC performance was about 1.5× slower than the optimized CUDA version. Particular focus is given to compiler maturity regarding OpenACC implementation for modern FORTRAN, and it is found that the Cray implementation is currently more mature than the PGI implementation. Still, for the case that ran successfully on PGI, the PGI OpenACC runtime was slightly faster than Cray. The results show encouraging performance for OpenACC implementation compared to CUDA while also exposing some issues that may be necessary before the implementations are suitable for porting all of CAM-SE. Most notable are that GPU shared memory should be used by future OpenACC implementations and that derived type support should be expanded.},
author = {Norman, Matthew and Larkin, Jeffrey and Vose, Aaron and Evans, Katherine},
doi = {10.1016/j.jocs.2015.04.022},
file = {::},
issn = {18777503},
journal = {Journal of Computational Science},
keywords = {CUDA,Climate,GPU,HPC,OpenACC},
mendeley-groups = {Level 5 Proj},
month = {jul},
pages = {1--6},
publisher = {Elsevier},
title = {{A case study of CUDA FORTRAN and OpenACC for an atmospheric climate kernel}},
url = {https://www.sciencedirect.com/science/article/pii/S1877750315000605},
volume = {9},
year = {2015}
}
@inproceedings{Oancea2012,
abstract = {This paper presents a real-world pricing kernel for financial derivatives and evaluates the language and compiler tool chain that would allow expressive, hardware-neutral algorithm implementation and efficient execution on graphics-processing units (GPU). The language issues refer to preserving algorithmic invariants, e.g., inherent parallelism made explicit by map-reduce-scan functional combinators. Efficient execution is achieved by manually; applying a series of generally-applicable compiler transformations that allows the generated-OpenCL code to yield speedups as high as 70x and 540x on a commodity mobile and desktop GPU, respectively. Apart from the concrete speed-ups attained, our contributions are twofold: First, from a language perspective;, we illustrate that even state-of-the-art auto-parallelization techniques are incapable of discovering all the requisite data parallelism when rendering the functional code in Fortran-style imperative array processing form. Second, from a performance perspective;, we study which compiler transformations are necessary to map the high-level functional code to hand-optimized OpenCL code for GPU execution. We discover a rich optimization space with nontrivial trade-offs and cost models. Memory reuse in map-reduce patterns, strength reduction, branch divergence optimization, and memory access coalescing, exhibit significant impact individually. When combined, they enable essentially full utilization of all GPU cores. Functional programming has played a crucial double role in our case study: Capturing the naturally data-parallel structure of the pricing algorithm in a transparent, reusable and entirely hardware-independent fashion; and supporting the correctness of the subsequent compiler transformations to a hardware-oriented target language by a rich class of universally valid equational properties. Given the observed difficulty of automatically parallelizing imperative sequential code and the inherent labor of porting hardware-oriented and -optimized programs, our case study suggests that functional programming technology can facilitate high-level; expression of leading-edge performant portable; high-performance systems for massively parallel hardware architectures. {\textcopyright} 2012 ACM.},
address = {New York, New York, USA},
author = {Oancea, Cosmin E. and Andreetta, Christian and Berthold, Jost and Frisch, Alain and Henglein, Fritz},
booktitle = {Proceedings of the 1st ACM SIGPLAN workshop on Functional high-performance computing - FHPC '12},
doi = {10.1145/2364474.2364484},
file = {::},
isbn = {9781450315777},
keywords = {autoparallelization,functional language,memory coalescing,reduction,strength,tiling},
mendeley-groups = {Level 5 Proj},
number = {Section 2},
pages = {61},
publisher = {ACM Press},
title = {{Financial software on GPUs}},
url = {http://dl.acm.org/citation.cfm?doid=2364474.2364484},
year = {2012}
}
@article{Corrigan2012,
abstract = {A typical large-scale CFD code based on adaptive, edge-based finite-element formulations for the solu- tion of compressible and incompressible flow is taken as a test bed to port such codes to graphics hardware (graphics processing units,GPUs) using semi-automatic techniques. In previouswork, a GPU version of this code was presented, in which, for many run configurations, all mesh-sized loops required throughout time stepping were ported. This approach simultaneously achieves the fine-grained parallelism required to fully exploit the capabilities of many-core GPUs, completely avoids the crippling bottleneck of GPU–CPU data transfer, and uses a transposed memory layout to meet the distinct memory access requirements posed by GPUs. The present work describes the next step of this porting effort, namely to integrate GPU-based, fine- grained parallelism with Message-Passing-Interface-based, coarse-grained parallelism, in order to achieve a code capable of running on multi-GPU clusters. This is carried out in a semi-automated fashion: the exist- ing Fortran–Message Passing Interface code is preserved, with the translator inserting data transfer calls as required. Performance benchmarks indicate up to a factor of 2 performance advantage of the NVIDIA Tesla M2050 GPU (Santa Clara, CA, USA) over the six-core Intel Xeon X5670 CPU (Santa Clara, CA, USA), for certain run configurations. In addition, good scalability is observed when running across multiple GPUs. The approach should be of general interest, as how best to run on GPUs is being presently considered for many so-called legacy codes.},
archivePrefix = {arXiv},
arxivId = {DOI: 10.1002/fld.1},
author = {Corrigan, Andrew and L{\"{o}}hner, Rainald},
doi = {10.1002/fld.2664},
eprint = {fld.1},
file = {:home/james/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Corrigan, L{\"{o}}hner - 2012 - Semi-automatic porting of a large-scale CFD code to multi-graphics processing unit clusters.pdf:pdf},
isbn = {02712091 10970363},
issn = {02712091},
journal = {International Journal for Numerical Methods in Fluids},
keywords = {CFD,GPUs,Supercomputing hardware},
mendeley-groups = {Level 5 Proj},
month = {may},
number = {11},
pages = {1786--1796},
pmid = {18628456},
primaryClass = {DOI: 10.1002},
publisher = {Wiley-Blackwell},
title = {{Semi-automatic porting of a large-scale CFD code to multi-graphics processing unit clusters}},
url = {http://doi.wiley.com/10.1002/fld.2560},
volume = {69},
year = {2012}
}
@article{VanderbauwhedeNabi2018,
abstract = {There is a large body of legacy scientific code written in languages like Fortran that is not optimised to get the best performance out of heterogeneous acceleration devices like GPUs and FPGAs, and manually porting such code into parallel languages frameworks like OpenCL requires considerable effort. We are working towards developing a turn-key, self-optimising compiler for accelerating scientific applications, that can automatically transform legacy code into a solution for heterogeneous targets. In this paper we focus on FPGAs as the acceleration devices, and carry out our discussion in the context of the OpenCL programming framework. We show a route to automatic creation of kernels which are optimised for execution in a "streaming" fashion, which gives optimal performance on FPGAs. We use a 2D shallow-water model as an illustration; specifically we show how the use of $\backslash$emph{\{}channels{\}} to communicate directly between peer kernels and the use of on-chip memory to create stencil buffers can lead to significant performance improvements. Our results show better FPGA performance against a baseline CPU implementation, and better energy-efficiency against both CPU and GPU implementations.},
archivePrefix = {arXiv},
arxivId = {1901.00416},
author = {Vanderbauwhede, Wim and Nabi, Syed Waqar},
eprint = {1901.00416},
file = {:home/james/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vanderbauwhede, Nabi - 2018 - Towards Automatic Transformation of Legacy Scientific Code into OpenCL for Optimal Performance on FPGAs(2).pdf:pdf},
keywords = {accelerators,compiler,figure 1,fpga,gpu,high-performance computing,literature mentions of different,opencl,puting,revisions of fortran,sciencedirect,scientific com-,using google scholar and},
mendeley-groups = {PRRCS},
month = {dec},
pages = {1--9},
title = {{Towards Automatic Transformation of Legacy Scientific Code into OpenCL for Optimal Performance on FPGAs}},
url = {http://arxiv.org/abs/1901.00416},
year = {2018}
}

@misc{IntelCorporation,
author = {{Intel Corporation}},
mendeley-groups = {Level 5 Proj},
title = {{FPGA Design Software - Intel{\textregistered} Quartus{\textregistered} Prime}},
url = {https://www.intel.com/content/www/us/en/software/programmable/quartus-prime/overview.html},
urldate = {2018-10-31}
}
@article{Nakayama2011,
abstract = {This paper describes aerodynamic roughness properties for turbulent flows over various building arrays that represent realistic urban surface geometries. First, building morphological characteristics such as roughness density $\gamma$f and building height variability Vh, defined respectively as the ratio of total frontal area of roughness elements to the total surface area and the ratio of standard deviation in building height to the average building height of the study site, were investigated. Next, large-eddy simulations (LESs) of turbulent flows over building arrays were performed with various surface geometries characterized by a wide range of values for both $\gamma$f and Vh, based on this building morphological analysis. Third, aerodynamic roughness parameters such as roughness length z0 and drag coefficient Cd were evaluated for the central Tokyo area from the values of lf and Vh using the LES results. The values of z0 and Cd as a function of both lf and Vh were comparable to those found in earlier studies. The values of z0 and Cd evaluated by a conventional method using only $\gamma$f were underestimated, particularly for densely built-up areas. This indicates that the present approach to estimating aerodynamic roughness parameters, taking account of both roughness density and building height variability, is more appropriate than conventional approaches when applied to actual urban areas. The roughness aerodynamic parameters as a function of lf and Vh obtained from the LES results will be useful in incorporating urban effects into weather forecasting models. {\textcopyright} 2011 American Meteorological Society.},
author = {Nakayama, Hiromasa and Takemi, Tetsuya and Nagai, Haruyasu},
doi = {10.1175/2011JAMC2567.1},
file = {::},
issn = {15588424},
journal = {Journal of Applied Meteorology and Climatology},
keywords = {Large eddy simulations,Turbulence},
mendeley-groups = {Level 5 Proj,PRRCS},
month = {aug},
number = {8},
pages = {1692--1712},
title = {{LES analysis of the aerodynamic surface properties for turbulent flows over building arrays with various geometries}},
url = {http://journals.ametsoc.org/doi/abs/10.1175/2011JAMC2567.1},
volume = {50},
year = {2011}
}
@incollection{Hall2009,
abstract = {Offers an introduction to computer-based modelling of oceanic processes. This title contains over twenty practical exercises, using freely available Open-Source software, and covers a range of topics from long surface waves, geostrophic flows, through to the general wind-driven circulation including western boundary currents and mesoscale eddies. Requirements -- Motivation -- Basics of Geophysical Fluid Dynamics -- Long Waves in a Channel -- 2D Shallow-Water Modelling -- Rotational Effects.},
author = {K{\"{a}}mpf, Jochen},
booktitle = {Ocean Modelling for Beginners},
doi = {10.1002/fld.992.Froude},
isbn = {9783642008207},
mendeley-groups = {Level 5 Proj},
pages = {136--139},
publisher = {Springer-Verlag},
title = {{07{\_}Bibliography}},
url = {https://www.researchgate.net/publication/261174088{\_}Ocean{\_}Modelling{\_}for{\_}Beginners{\_}-{\_}Using{\_}Open-Source{\_}Software},
volume = {17},
year = {2009}
}
@inproceedings{Overbey2005,
abstract = {Not since the advent of the integrated development environment has a development tool had the impact on programmer productivity that refactoring tools have had for object-oriented developers. However, at the present time, such tools do not exist for high-performance languages such as C and Fortran; moreover, refactorings specific to high-performance and parallel computing have not yet been adequately examined. We observe that many common refactorings for object-oriented systems have clear analogs in procedural Fortran. The Fortran language itself and the introduction of object orientation in Fortran 2003 give rise to several additional refactorings. Moreover, we conjecture that many hand optimizations common in supercomputer programming can be automated by a refactoring engine but deferred until build time in order to preserve the maintainability of the original code base. Finally, we introduce Photran, an integrated development environment that will be used to implement these transformations, and discuss the impact of such a tool on legacy code reengineering.This work is being funded by IBM under the PERCS project.},
address = {New York, New York, USA},
author = {Overbey, Jeffrey and Xanthos, Spiros and Johnson, Ralph and Foote, Brian},
booktitle = {Proceedings of the second international workshop on Software engineering for high performance computing system applications  - SE-HPCS '05},
doi = {10.1145/1145319.1145331},
file = {:home/james/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Overbey et al. - 2005 - Refactorings for Fortran and high-performance computing.pdf:pdf},
isbn = {1595931171},
issn = {02705257},
keywords = {Fortran programming,refactoring},
mendeley-groups = {Level 5 Proj,PRRCS},
pages = {37},
publisher = {ACM Press},
title = {{Refactorings for Fortran and high-performance computing}},
url = {http://portal.acm.org/citation.cfm?doid=1145319.1145331},
year = {2005}
}
@inproceedings{Orchard2013,
abstract = {Many of the computer models used in scientific research have been developed in Fortran over many years. This evo- lutionary process means these models often use deprecated language features and idioms that impede software main- tenance, understandability, extension, and verification. To mitigate this, we built CamFort, an open-source automatic refactoring tool for upgrading Fortran source code. We de- scribe functionality in CamFort for removing equivalence statements and common blocks, and for introducing struc- tured data types, and give examples of how these transfor- mations can benefit codebase robustness.},
address = {New York, New York, USA},
author = {Orchard, Dominic and Rice, Andrew},
booktitle = {Proceedings of the 2013 ACM workshop on Workshop on refactoring tools - WRT '13},
doi = {10.1145/2541348.2541356},
file = {:home/james/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Orchard, Rice - 2013 - Upgrading fortran source code using automatic refactoring.pdf:pdf},
isbn = {9781450326049},
keywords = {computational science,fortran,haskell,language evolution,refactoring},
mendeley-groups = {Level 5 Proj,PRRCS},
pages = {29--32},
publisher = {ACM Press},
title = {{Upgrading fortran source code using automatic refactoring}},
url = {http://dl.acm.org/citation.cfm?doid=2541348.2541356},
year = {2013}
}
@inproceedings{Wang2017,
abstract = {Iterative stencil algorithms find applications in a wide range of domains. FPGAs have long been adopted for computa-tion acceleration due to its advantages of dedicated hard-ware design. Hence, FPGAs are a compelling alternative for executing iterative stencil algorithms. However, efficient implementation of iterative stencil algorithms on FPGAs is very challenging due to the data dependencies between iter-ations and elements in the stencil algorithms, programming hurdle of FPGAs, and large design space. In this paper, we present a comprehensive framework that synthesizes iterative stencil algorithms on FPGAs efficiently. We leverage the OpenCL-to-FPGA toolchain to generate accelerator automatically and perform design space explo-ration at the high level. We propose to bridge the neigh-boring tiles through pipe and enable data sharing among them to improve computation efficiency. Then, we extend the equal tile size design to a heterogeneous design with dif-ferent tile size to balance the computation among different tiles. We also develop analytical performance models to ex-plore the complex design space. Experiments using a wide range of stencil applications demonstrate that on average our heterogeneous implementations achieve 1.65X performance speedup but with less hardware resource compared to the state-of-the-art.},
address = {New York, New York, USA},
author = {Wang, Shuo and Liang, Yun},
booktitle = {Proceedings of the 54th Annual Design Automation Conference 2017},
doi = {10.1145/3061639.3062185},
file = {:home/james/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Liang - 2017 - A Comprehensive Framework for Synthesizing Stencil Algorithms on FPGAs using OpenCL Model.pdf:pdf},
isbn = {9781450349277},
issn = {0738100X},
mendeley-groups = {Level 5 Proj},
pages = {28:1----28:6},
publisher = {ACM Press},
title = {{A Comprehensive Framework for Synthesizing Stencil Algorithms on FPGAs Using OpenCL Model}},
url = {http://doi.acm.org/10.1145/3061639.3062185},
year = {2017}
}
@article{Momeni2016,
author = {Momeni, Amir and Tabkhi, Hamed and Ukidave, Yash and Schirner, Gunar and Kaeli, David},
doi = {10.1145/2927964.2927974},
file = {:home/james/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Momeni et al. - 2016 - Exploring the Efficiency of the OpenCL Pipe Semantic on an FPGA.pdf:pdf},
issn = {0163-5964},
journal = {SIGARCH Comput. Archit. News},
mendeley-groups = {Level 5 Proj},
month = {apr},
number = {4},
pages = {52--57},
publisher = {ACM},
title = {{Exploring the Efficiency of the OpenCL Pipe Semantic on an FPGA}},
url = {http://doi.acm.org/10.1145/2927964.2927974},
volume = {43},
year = {2016}
}
@article{VanderbauwhedeDavidson2018,
abstract = {Massively parallel accelerators such as GPGPUs, manycores and FPGAs represent a powerful and affordable tool for scientists who look to speed up simulations of complex systems. However, porting code to such devices requires a detailed understanding of heterogeneous programming tools and effective strategies for parallelization. In this paper we present a source to source compilation approach with whole-program analysis to automatically transform single-threaded FORTRAN 77 legacy code into OpenCL-accelerated programs with parallelized kernels. The main contributions of our work are: (1) whole-source refactoring to allow any subroutine in the code to be offloaded to an accelerator. (2) Minimization of the data transfer between the host and the accelerator by eliminating redundant transfers. (3) Pragmatic auto-parallelization of the code to be offloaded to the accelerator by identification of parallelizable maps and reductions. We have validated the code transformation performance of the compiler on the NIST FORTRAN 78 test suite and several real-world codes: the Large Eddy Simulator for Urban Flows, a high-resolution turbulent flow model; the shallow water component of the ocean model Gmodel; the Linear Baroclinic Model, an atmospheric climate model and Flexpart-WRF, a particle dispersion simulator. The automatic parallelization component has been tested on as 2-D Shallow Water model (2DSW) and on the Large Eddy Simulator for Urban Flows (UFLES) and produces a complete OpenCL-enabled code base. The fully OpenCL-accelerated versions of the 2DSW and the UFLES are resp. 9x and 20x faster on GPU than the original code on CPU, in both cases this is the same performance as manually ported code.},
archivePrefix = {arXiv},
arxivId = {1711.04471},
author = {Vanderbauwhede, Wim and Davidson, Gavin},
doi = {10.1016/j.compfluid.2018.06.005},
eprint = {1711.04471},
file = {:home/james/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vanderbauwhede, Davidson - 2018 - Domain-specific acceleration and auto-parallelization of legacy scientific code in FORTRAN 77 using so.pdf:pdf},
issn = {00457930},
journal = {Computers and Fluids},
keywords = {Acceleration,Auto-parallelization,Fortran,GPGPU,OpenCL,Source-to-source compilation},
mendeley-groups = {Level 5 Proj,PRRCS},
month = {sep},
pages = {1--5},
publisher = {Pergamon},
title = {{Domain-specific acceleration and auto-parallelization of legacy scientific code in FORTRAN 77 using source-to-source compilation}},
url = {https://www.sciencedirect.com/science/article/pii/S0045793018302950},
volume = {173},
year = {2018}
}
